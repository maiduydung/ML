{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-heaven",
   "metadata": {},
   "source": [
    "## Use daily infected only\n",
    "### GRU and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funded-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "threatened-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 2)\n",
      "Date        datetime64[ns]\n",
      "Infected           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Infected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Infected\n",
       "0 2020-01-16       1.0\n",
       "1 2020-01-17       0.0\n",
       "2 2020-01-18       0.0\n",
       "3 2020-01-19       0.0\n",
       "4 2020-01-20       0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../seir/cov_datasets/pcr_positive_daily_Sep18.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "separated-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df['Infected'][:500].values.astype(int)\n",
    "test_set = df['Infected'][500:].values.astype(int)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set.reshape(len(training_set), 1))\n",
    "testing_set_scaled = sc.fit_transform(test_set.reshape(len(test_set), 1))\n",
    "\n",
    "\n",
    "# Creating a data structure with 5 time-steps and 2 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "located-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n",
      "(111, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_set_scaled.shape)\n",
    "print(testing_set_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "needed-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "611-594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq(sequence, n_steps_in, n_steps_out):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + n_steps_in\n",
    "        steps_out_idx = end_idx + n_steps_out\n",
    "        \n",
    "        #check if we reach end of arr or not\n",
    "        if (steps_out_idx > len(sequence)):\n",
    "            break\n",
    "        seq_x = sequence[i:end_idx]\n",
    "        seq_y = sequence[end_idx:steps_out_idx]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 14\n",
    "n_steps_out = 4\n",
    "\n",
    "X_train , y_train = split_seq(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test , y_test = split_seq(testing_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minor-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 14, 1) (483, 4, 1)\n",
      "(94, 14, 1) (94, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabulous-general",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train.shape[1],X_train.shape[2])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-belle",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "skilled-platform",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0387  \n",
      "Epoch 00001: val_loss improved from inf to 0.06329, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0387 - val_loss: 0.0633\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Epoch 00002: val_loss improved from 0.06329 to 0.05088, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0453 - val_loss: 0.0509\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 00003: val_loss did not improve from 0.05088\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0224 - val_loss: 0.0597\n",
      "Epoch 4/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0230   \n",
      "Epoch 00004: val_loss did not improve from 0.05088\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0354 - val_loss: 0.0711\n",
      "Epoch 5/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0109\n",
      "Epoch 00005: val_loss improved from 0.05088 to 0.04292, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0121 - val_loss: 0.0429\n",
      "Epoch 6/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00006: val_loss did not improve from 0.04292\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0467\n",
      "Epoch 7/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00007: val_loss did not improve from 0.04292\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0432\n",
      "Epoch 8/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0090   \n",
      "Epoch 00008: val_loss did not improve from 0.04292\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.0429\n",
      "Epoch 9/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0091  \n",
      "Epoch 00009: val_loss improved from 0.04292 to 0.04169, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 0.0109 - val_loss: 0.0417\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0110   \n",
      "Epoch 00010: val_loss improved from 0.04169 to 0.04125, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0110 - val_loss: 0.0413\n",
      "Epoch 11/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0089   \n",
      "Epoch 00011: val_loss improved from 0.04125 to 0.04096, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0108 - val_loss: 0.0410\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0110  \n",
      "Epoch 00012: val_loss improved from 0.04096 to 0.04075, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0110 - val_loss: 0.0407\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0112  \n",
      "Epoch 00013: val_loss improved from 0.04075 to 0.04038, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0112 - val_loss: 0.0404\n",
      "Epoch 14/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0116  \n",
      "Epoch 00014: val_loss did not improve from 0.04038\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0117 - val_loss: 0.0416\n",
      "Epoch 15/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0092   \n",
      "Epoch 00015: val_loss improved from 0.04038 to 0.04008, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0118 - val_loss: 0.0401\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0115  \n",
      "Epoch 00016: val_loss did not improve from 0.04008\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0115 - val_loss: 0.0425\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0113  \n",
      "Epoch 00017: val_loss improved from 0.04008 to 0.03959, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0113 - val_loss: 0.0396\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0110 \n",
      "Epoch 00018: val_loss did not improve from 0.03959\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0110 - val_loss: 0.0422\n",
      "Epoch 19/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0087   \n",
      "Epoch 00019: val_loss improved from 0.03959 to 0.03879, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0111 - val_loss: 0.0388\n",
      "Epoch 20/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0114  \n",
      "Epoch 00020: val_loss did not improve from 0.03879\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0417\n",
      "Epoch 21/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0091   \n",
      "Epoch 00021: val_loss improved from 0.03879 to 0.03878, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0113 - val_loss: 0.0388\n",
      "Epoch 22/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0116  \n",
      "Epoch 00022: val_loss did not improve from 0.03878\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0116 - val_loss: 0.0410\n",
      "Epoch 23/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0088   \n",
      "Epoch 00023: val_loss did not improve from 0.03878\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0111 - val_loss: 0.0390\n",
      "Epoch 24/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0086   \n",
      "Epoch 00024: val_loss did not improve from 0.03878\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0107 - val_loss: 0.0397\n",
      "Epoch 25/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0082   \n",
      "Epoch 00025: val_loss improved from 0.03878 to 0.03833, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0101 - val_loss: 0.0383\n",
      "Epoch 26/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0100  \n",
      "Epoch 00026: val_loss did not improve from 0.03833\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0100 - val_loss: 0.0383\n",
      "Epoch 27/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0081   \n",
      "Epoch 00027: val_loss improved from 0.03833 to 0.03796, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0099 - val_loss: 0.0380\n",
      "Epoch 28/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0099  \n",
      "Epoch 00028: val_loss improved from 0.03796 to 0.03735, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0099 - val_loss: 0.0374\n",
      "Epoch 29/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0098  \n",
      "Epoch 00029: val_loss did not improve from 0.03735\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0374\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0097  \n",
      "Epoch 00030: val_loss improved from 0.03735 to 0.03626, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0097 - val_loss: 0.0363\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0096  \n",
      "Epoch 00031: val_loss did not improve from 0.03626\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0369\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0096  \n",
      "Epoch 00032: val_loss improved from 0.03626 to 0.03462, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0096 - val_loss: 0.0346\n",
      "Epoch 33/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0084  \n",
      "Epoch 00033: val_loss did not improve from 0.03462\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0372\n",
      "Epoch 34/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0075  \n",
      "Epoch 00034: val_loss improved from 0.03462 to 0.03199, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.0096 - val_loss: 0.0320\n",
      "Epoch 35/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0108  \n",
      "Epoch 00035: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0108 - val_loss: 0.0411\n",
      "Epoch 36/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00036: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0126 - val_loss: 0.0327\n",
      "Epoch 37/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00037: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0137 - val_loss: 0.0495\n",
      "Epoch 38/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0123\n",
      "Epoch 00038: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.0412\n",
      "Epoch 39/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0125\n",
      "Epoch 00039: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0135 - val_loss: 0.0393\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0098  \n",
      "Epoch 00040: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0353\n",
      "Epoch 41/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0079  \n",
      "Epoch 00041: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0094 - val_loss: 0.0365\n",
      "Epoch 42/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0092 \n",
      "Epoch 00042: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0350\n",
      "Epoch 43/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0077  \n",
      "Epoch 00043: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0090 - val_loss: 0.0351\n",
      "Epoch 44/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0074  \n",
      "Epoch 00044: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0338\n",
      "Epoch 45/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0073   \n",
      "Epoch 00045: val_loss did not improve from 0.03199\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0339\n",
      "Epoch 46/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0068    \n",
      "Epoch 00046: val_loss improved from 0.03199 to 0.03184, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0087 - val_loss: 0.0318\n",
      "Epoch 47/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0088  \n",
      "Epoch 00047: val_loss did not improve from 0.03184\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0088 - val_loss: 0.0335\n",
      "Epoch 48/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0069    \n",
      "Epoch 00048: val_loss improved from 0.03184 to 0.02915, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0090 - val_loss: 0.0292\n",
      "Epoch 49/1000\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 0.0108   \n",
      "Epoch 00049: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0109 - val_loss: 0.0373\n",
      "Epoch 50/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0102   \n",
      "Epoch 00050: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0145 - val_loss: 0.0355\n",
      "Epoch 51/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00051: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0120 - val_loss: 0.0402\n",
      "Epoch 52/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00052: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0134 - val_loss: 0.0382\n",
      "Epoch 53/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00053: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0102 - val_loss: 0.0345\n",
      "Epoch 54/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0071   \n",
      "Epoch 00054: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0087 - val_loss: 0.0332\n",
      "Epoch 55/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0070   \n",
      "Epoch 00055: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0084 - val_loss: 0.0329\n",
      "Epoch 56/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0066    \n",
      "Epoch 00056: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0082 - val_loss: 0.0319\n",
      "Epoch 57/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0066    \n",
      "Epoch 00057: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0310\n",
      "Epoch 58/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0063    \n",
      "Epoch 00058: val_loss did not improve from 0.02915\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0297\n",
      "Epoch 59/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0064    \n",
      "Epoch 00059: val_loss improved from 0.02915 to 0.02872, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0076 - val_loss: 0.0287\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0075   \n",
      "Epoch 00060: val_loss improved from 0.02872 to 0.02617, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0075 - val_loss: 0.0262\n",
      "Epoch 61/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0072    \n",
      "Epoch 00061: val_loss did not improve from 0.02617\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0294\n",
      "Epoch 62/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0063    \n",
      "Epoch 00062: val_loss improved from 0.02617 to 0.02499, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0250\n",
      "Epoch 63/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0102   \n",
      "Epoch 00063: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0108 - val_loss: 0.0326\n",
      "Epoch 64/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0102   \n",
      "Epoch 00064: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0149 - val_loss: 0.0353\n",
      "Epoch 65/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0098\n",
      "Epoch 00065: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0354\n",
      "Epoch 66/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0075  \n",
      "Epoch 00066: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0337\n",
      "Epoch 67/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00067: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0090 - val_loss: 0.0321\n",
      "Epoch 68/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0066   \n",
      "Epoch 00068: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0292\n",
      "Epoch 69/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0062   \n",
      "Epoch 00069: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0290\n",
      "Epoch 70/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0059    \n",
      "Epoch 00070: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0269\n",
      "Epoch 71/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0057    \n",
      "Epoch 00071: val_loss did not improve from 0.02499\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0255\n",
      "Epoch 72/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0053    \n",
      "Epoch 00072: val_loss improved from 0.02499 to 0.02293, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0067 - val_loss: 0.0229\n",
      "Epoch 73/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0056    \n",
      "Epoch 00073: val_loss did not improve from 0.02293\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0233\n",
      "Epoch 74/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0050    \n",
      "Epoch 00074: val_loss improved from 0.02293 to 0.01940, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0064 - val_loss: 0.0194\n",
      "Epoch 75/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0069   \n",
      "Epoch 00075: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0079 - val_loss: 0.0260\n",
      "Epoch 76/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0058   \n",
      "Epoch 00076: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0075 - val_loss: 0.0217\n",
      "Epoch 77/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00077: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0257\n",
      "Epoch 78/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0065   \n",
      "Epoch 00078: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0224\n",
      "Epoch 79/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0095\n",
      "Epoch 00079: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0105 - val_loss: 0.0286\n",
      "Epoch 80/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0134  \n",
      "Epoch 00080: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0133 - val_loss: 0.0318\n",
      "Epoch 81/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0089\n",
      "Epoch 00081: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0089 - val_loss: 0.0302\n",
      "Epoch 82/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0083\n",
      "Epoch 00082: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0267\n",
      "Epoch 83/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00083: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0253\n",
      "Epoch 84/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0052    \n",
      "Epoch 00084: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0225\n",
      "Epoch 85/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0052    \n",
      "Epoch 00085: val_loss did not improve from 0.01940\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0212\n",
      "Epoch 86/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0046    \n",
      "Epoch 00086: val_loss improved from 0.01940 to 0.01863, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0186\n",
      "Epoch 87/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0053    \n",
      "Epoch 00087: val_loss did not improve from 0.01863\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0189\n",
      "Epoch 88/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0050    \n",
      "Epoch 00088: val_loss improved from 0.01863 to 0.01750, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0068 - val_loss: 0.0175\n",
      "Epoch 89/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0083   \n",
      "Epoch 00089: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0083 - val_loss: 0.0212\n",
      "Epoch 90/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0074    \n",
      "Epoch 00090: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0108 - val_loss: 0.0256\n",
      "Epoch 91/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0071\n",
      "Epoch 00091: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0245\n",
      "Epoch 92/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0058\n",
      "Epoch 00092: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0080 - val_loss: 0.0243\n",
      "Epoch 93/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00093: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0220\n",
      "Epoch 94/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047    \n",
      "Epoch 00094: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0201\n",
      "Epoch 95/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0049   \n",
      "Epoch 00095: val_loss did not improve from 0.01750\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0189\n",
      "Epoch 96/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044    \n",
      "Epoch 00096: val_loss improved from 0.01750 to 0.01672, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0167\n",
      "Epoch 97/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0058   \n",
      "Epoch 00097: val_loss improved from 0.01672 to 0.01630, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0058 - val_loss: 0.0163\n",
      "Epoch 98/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0060   \n",
      "Epoch 00098: val_loss improved from 0.01630 to 0.01510, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0060 - val_loss: 0.0151\n",
      "Epoch 99/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0060   \n",
      "Epoch 00099: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0068 - val_loss: 0.0171\n",
      "Epoch 100/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0058   \n",
      "Epoch 00100: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0083 - val_loss: 0.0190\n",
      "Epoch 101/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0065   \n",
      "Epoch 00101: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0201\n",
      "Epoch 102/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0055   \n",
      "Epoch 00102: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0079 - val_loss: 0.0219\n",
      "Epoch 103/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00103: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0200\n",
      "Epoch 104/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00104: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0185\n",
      "Epoch 105/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00105: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0171\n",
      "Epoch 106/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042    \n",
      "Epoch 00106: val_loss did not improve from 0.01510\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0152\n",
      "Epoch 107/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043    \n",
      "Epoch 00107: val_loss improved from 0.01510 to 0.01449, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0054 - val_loss: 0.0145\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0054   \n",
      "Epoch 00108: val_loss improved from 0.01449 to 0.01329, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0133\n",
      "Epoch 109/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0057   \n",
      "Epoch 00109: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0140\n",
      "Epoch 110/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047    \n",
      "Epoch 00110: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0140\n",
      "Epoch 111/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0058    \n",
      "Epoch 00111: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0162\n",
      "Epoch 112/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0054    \n",
      "Epoch 00112: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0078 - val_loss: 0.0186\n",
      "Epoch 113/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00113: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0186\n",
      "Epoch 114/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00114: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0183\n",
      "Epoch 115/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00115: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0167\n",
      "Epoch 116/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042    \n",
      "Epoch 00116: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0150\n",
      "Epoch 117/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00117: val_loss did not improve from 0.01329\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0139\n",
      "Epoch 118/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00118: val_loss improved from 0.01329 to 0.01262, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0051 - val_loss: 0.0126\n",
      "Epoch 119/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0040    \n",
      "Epoch 00119: val_loss improved from 0.01262 to 0.01244, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 120/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0053   \n",
      "Epoch 00120: val_loss improved from 0.01244 to 0.01183, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0053 - val_loss: 0.0118\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0057   \n",
      "Epoch 00121: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0057 - val_loss: 0.0131\n",
      "Epoch 122/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0066   \n",
      "Epoch 00122: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0066 - val_loss: 0.0139\n",
      "Epoch 123/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0063  \n",
      "Epoch 00123: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0064 - val_loss: 0.0158\n",
      "Epoch 124/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0069  \n",
      "Epoch 00124: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0069 - val_loss: 0.0174\n",
      "Epoch 125/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00125: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0061 - val_loss: 0.0166\n",
      "Epoch 126/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00126: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0058 - val_loss: 0.0157\n",
      "Epoch 127/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00127: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.0142\n",
      "Epoch 128/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00128: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0128\n",
      "Epoch 129/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0049   \n",
      "Epoch 00129: val_loss did not improve from 0.01183\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 130/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0049   \n",
      "Epoch 00130: val_loss improved from 0.01183 to 0.01125, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0049 - val_loss: 0.0112\n",
      "Epoch 131/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0050   \n",
      "Epoch 00131: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 132/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00132: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0116\n",
      "Epoch 133/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0057  \n",
      "Epoch 00133: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0057 - val_loss: 0.0133\n",
      "Epoch 134/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0048    \n",
      "Epoch 00134: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0065 - val_loss: 0.0145\n",
      "Epoch 135/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00135: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0155\n",
      "Epoch 136/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045    \n",
      "Epoch 00136: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0156\n",
      "Epoch 137/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00137: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0144\n",
      "Epoch 138/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0052   \n",
      "Epoch 00138: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0132\n",
      "Epoch 139/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0049   \n",
      "Epoch 00139: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 140/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00140: val_loss did not improve from 0.01125\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0113\n",
      "Epoch 141/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00141: val_loss improved from 0.01125 to 0.01111, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0048 - val_loss: 0.0111\n",
      "Epoch 142/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00142: val_loss improved from 0.01111 to 0.01103, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0051 - val_loss: 0.0110\n",
      "Epoch 143/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0052   \n",
      "Epoch 00143: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0121\n",
      "Epoch 144/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044    \n",
      "Epoch 00144: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 145/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0046   \n",
      "Epoch 00145: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0057 - val_loss: 0.0141\n",
      "Epoch 146/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0045   \n",
      "Epoch 00146: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0145\n",
      "Epoch 147/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00147: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0140\n",
      "Epoch 148/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00148: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0130\n",
      "Epoch 149/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00149: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 150/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00150: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0112\n",
      "Epoch 151/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00151: val_loss did not improve from 0.01103\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0111\n",
      "Epoch 152/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00152: val_loss improved from 0.01103 to 0.01099, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0049 - val_loss: 0.0110\n",
      "Epoch 153/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0040    \n",
      "Epoch 00153: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0120\n",
      "Epoch 154/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00154: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0122\n",
      "Epoch 155/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00155: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0136\n",
      "Epoch 156/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00156: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0056 - val_loss: 0.0134\n",
      "Epoch 157/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00157: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0133\n",
      "Epoch 158/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00158: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 159/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00159: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0118\n",
      "Epoch 160/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00160: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0112\n",
      "Epoch 161/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00161: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0114\n",
      "Epoch 162/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00162: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0114\n",
      "Epoch 163/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00163: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0123\n",
      "Epoch 164/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00164: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0053 - val_loss: 0.0123\n",
      "Epoch 165/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00165: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0131\n",
      "Epoch 166/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00166: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0124\n",
      "Epoch 167/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00167: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0126\n",
      "Epoch 168/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00168: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0116\n",
      "Epoch 169/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00169: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 170/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00170: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0048 - val_loss: 0.0113\n",
      "Epoch 171/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00171: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0123\n",
      "Epoch 172/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0050   \n",
      "Epoch 00172: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 173/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00173: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0128\n",
      "Epoch 174/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00174: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 175/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00175: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0052 - val_loss: 0.0126\n",
      "Epoch 176/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00176: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0050 - val_loss: 0.0116\n",
      "Epoch 177/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00177: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0121\n",
      "Epoch 178/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00178: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0116\n",
      "Epoch 179/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00179: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0123\n",
      "Epoch 180/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00180: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0053 - val_loss: 0.0118\n",
      "Epoch 181/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00181: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0128\n",
      "Epoch 182/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0054   \n",
      "Epoch 00182: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0054 - val_loss: 0.0119\n",
      "Epoch 183/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0053\n",
      "Epoch 00183: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0053 - val_loss: 0.0130\n",
      "Epoch 184/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00184: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0052 - val_loss: 0.0115\n",
      "Epoch 185/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00185: val_loss did not improve from 0.01099\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0051 - val_loss: 0.0123\n",
      "Epoch 186/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00186: val_loss improved from 0.01099 to 0.01063, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0106\n",
      "Epoch 187/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00187: val_loss did not improve from 0.01063\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0117\n",
      "Epoch 188/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00188: val_loss improved from 0.01063 to 0.01045, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0046 - val_loss: 0.0104\n",
      "Epoch 189/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00189: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0047 - val_loss: 0.0118\n",
      "Epoch 190/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00190: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0108\n",
      "Epoch 191/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00191: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0121\n",
      "Epoch 192/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00192: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0121\n",
      "Epoch 193/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00193: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0055 - val_loss: 0.0131\n",
      "Epoch 194/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045    \n",
      "Epoch 00194: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0125\n",
      "Epoch 195/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00195: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0128\n",
      "Epoch 196/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00196: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0109\n",
      "Epoch 197/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00197: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0123\n",
      "Epoch 198/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00198: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0124\n",
      "Epoch 199/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00199: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0122\n",
      "Epoch 200/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00200: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0107\n",
      "Epoch 201/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00201: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0118\n",
      "Epoch 202/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00202: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0109\n",
      "Epoch 203/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00203: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0115\n",
      "Epoch 204/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00204: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0116\n",
      "Epoch 205/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00205: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0049 - val_loss: 0.0123\n",
      "Epoch 206/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0052   \n",
      "Epoch 00206: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0120\n",
      "Epoch 207/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00207: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0117\n",
      "Epoch 208/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00208: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 209/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00209: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0131\n",
      "Epoch 210/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041    \n",
      "Epoch 00210: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0120\n",
      "Epoch 211/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00211: val_loss did not improve from 0.01045\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0119\n",
      "Epoch 212/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00212: val_loss improved from 0.01045 to 0.01010, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0045 - val_loss: 0.0101\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00213: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0124\n",
      "Epoch 214/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0043   \n",
      "Epoch 00214: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0043 - val_loss: 0.0103\n",
      "Epoch 215/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032   \n",
      "Epoch 00215: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0043 - val_loss: 0.0117\n",
      "Epoch 216/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00216: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0041 - val_loss: 0.0106\n",
      "Epoch 217/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00217: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0041 - val_loss: 0.0116\n",
      "Epoch 218/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00218: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0040 - val_loss: 0.0108\n",
      "Epoch 219/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00219: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0116\n",
      "Epoch 220/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00220: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0113\n",
      "Epoch 221/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031    \n",
      "Epoch 00221: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0119\n",
      "Epoch 222/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00222: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0136\n",
      "Epoch 223/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00223: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0121\n",
      "Epoch 224/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0050    \n",
      "Epoch 00224: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.0131\n",
      "Epoch 225/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00225: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.0160\n",
      "Epoch 226/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0053\n",
      "Epoch 00226: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0053 - val_loss: 0.0114\n",
      "Epoch 227/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0046\n",
      "Epoch 00227: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0131\n",
      "Epoch 228/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0048   \n",
      "Epoch 00228: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0119\n",
      "Epoch 229/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00229: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 230/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00230: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0123\n",
      "Epoch 231/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00231: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0127\n",
      "Epoch 232/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0044   \n",
      "Epoch 00232: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0044 - val_loss: 0.0115\n",
      "Epoch 233/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0044   \n",
      "Epoch 00233: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0124\n",
      "Epoch 234/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0044   \n",
      "Epoch 00234: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0044 - val_loss: 0.0123\n",
      "Epoch 235/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00235: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0130\n",
      "Epoch 236/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00236: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0135\n",
      "Epoch 237/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00237: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0122\n",
      "Epoch 238/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00238: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0130\n",
      "Epoch 239/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00239: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0137\n",
      "Epoch 240/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00240: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0116\n",
      "Epoch 241/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00241: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0048 - val_loss: 0.0134\n",
      "Epoch 242/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00242: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0115\n",
      "Epoch 243/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00243: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0046 - val_loss: 0.0136\n",
      "Epoch 244/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00244: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0043 - val_loss: 0.0116\n",
      "Epoch 245/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00245: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0044 - val_loss: 0.0135\n",
      "Epoch 246/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00246: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0122\n",
      "Epoch 247/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00247: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0041 - val_loss: 0.0129\n",
      "Epoch 248/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00248: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0141\n",
      "Epoch 249/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00249: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0125\n",
      "Epoch 250/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00250: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0042 - val_loss: 0.0130\n",
      "Epoch 251/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00251: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0134\n",
      "Epoch 252/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00252: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0135\n",
      "Epoch 253/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00253: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0046 - val_loss: 0.0136\n",
      "Epoch 254/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00254: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0128\n",
      "Epoch 255/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00255: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0140\n",
      "Epoch 256/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00256: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0140\n",
      "Epoch 257/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00257: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0139\n",
      "Epoch 258/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00258: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0130\n",
      "Epoch 259/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00259: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0141\n",
      "Epoch 260/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00260: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0124\n",
      "Epoch 261/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033\n",
      "Epoch 00261: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0139\n",
      "Epoch 262/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00262: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0121\n",
      "Epoch 263/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00263: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0144\n",
      "Epoch 264/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00264: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0111\n",
      "Epoch 265/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00265: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0149\n",
      "Epoch 266/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00266: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0119\n",
      "Epoch 267/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00267: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0107\n",
      "Epoch 268/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00268: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 269/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00269: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0120\n",
      "Epoch 270/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00270: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0131\n",
      "Epoch 271/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00271: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0121\n",
      "Epoch 272/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00272: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0136\n",
      "Epoch 273/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00273: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 274/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00274: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0143\n",
      "Epoch 275/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00275: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0114\n",
      "Epoch 276/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00276: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0144\n",
      "Epoch 277/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    - ETA: 0s - loss: 3.6122e-0\n",
      "Epoch 00277: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0117\n",
      "Epoch 278/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00278: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0122\n",
      "Epoch 279/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00279: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0139\n",
      "Epoch 280/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00280: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0121\n",
      "Epoch 281/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00281: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0148\n",
      "Epoch 282/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00282: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0120\n",
      "Epoch 283/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00283: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0138\n",
      "Epoch 284/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00284: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0117\n",
      "Epoch 285/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00285: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0132\n",
      "Epoch 286/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00286: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0126\n",
      "Epoch 287/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00287: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0124\n",
      "Epoch 288/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00288: val_loss did not improve from 0.01010\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0132\n",
      "Epoch 289/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00289: val_loss improved from 0.01010 to 0.00974, saving model to LSTM_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0097\n",
      "Epoch 290/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0038   \n",
      "Epoch 00290: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0038 - val_loss: 0.0135\n",
      "Epoch 291/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00291: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0117\n",
      "Epoch 292/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00292: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0125\n",
      "Epoch 293/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00293: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0126\n",
      "Epoch 294/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00294: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0123\n",
      "Epoch 295/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00295: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0131\n",
      "Epoch 296/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00296: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0117\n",
      "Epoch 297/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00297: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0137\n",
      "Epoch 298/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00298: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0115\n",
      "Epoch 299/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00299: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0037 - val_loss: 0.0140\n",
      "Epoch 300/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00300: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0119\n",
      "Epoch 301/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00301: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0138\n",
      "Epoch 302/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00302: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0119\n",
      "Epoch 303/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00303: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0139\n",
      "Epoch 304/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00304: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0138\n",
      "Epoch 305/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047    \n",
      "Epoch 00305: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0136\n",
      "Epoch 306/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00306: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 307/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00307: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0044 - val_loss: 0.0139\n",
      "Epoch 308/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00308: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0042 - val_loss: 0.0127\n",
      "Epoch 309/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00309: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0120\n",
      "Epoch 310/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0030   \n",
      "Epoch 00310: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0130\n",
      "Epoch 311/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00311: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0133\n",
      "Epoch 312/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00312: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0132\n",
      "Epoch 313/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0029   \n",
      "Epoch 00313: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0135\n",
      "Epoch 314/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00314: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0136\n",
      "Epoch 315/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00315: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0130\n",
      "Epoch 316/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00316: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0143\n",
      "Epoch 317/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00317: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0125\n",
      "Epoch 318/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00318: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0134\n",
      "Epoch 319/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00319: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0139\n",
      "Epoch 320/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00320: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0131\n",
      "Epoch 321/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00321: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0128\n",
      "Epoch 322/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00322: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0115\n",
      "Epoch 323/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00323: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0129\n",
      "Epoch 324/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00324: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0127\n",
      "Epoch 325/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00325: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0149\n",
      "Epoch 326/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0048    \n",
      "Epoch 00326: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0054 - val_loss: 0.0125\n",
      "Epoch 327/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0056\n",
      "Epoch 00327: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0061 - val_loss: 0.0160\n",
      "Epoch 328/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043    \n",
      "Epoch 00328: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0052 - val_loss: 0.0160\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00329: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0155\n",
      "Epoch 330/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031    \n",
      "Epoch 00330: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0140\n",
      "Epoch 331/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039   \n",
      "Epoch 00331: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0137\n",
      "Epoch 332/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031    \n",
      "Epoch 00332: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0127\n",
      "Epoch 333/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00333: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0138\n",
      "Epoch 334/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00334: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0151\n",
      "Epoch 335/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00335: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0134\n",
      "Epoch 336/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00336: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0145\n",
      "Epoch 337/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00337: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0137\n",
      "Epoch 338/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00338: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0142\n",
      "Epoch 339/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00339: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0133\n",
      "Epoch 340/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031   \n",
      "Epoch 00340: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0133\n",
      "Epoch 341/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00341: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0131\n",
      "Epoch 342/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00342: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.0146\n",
      "Epoch 343/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00343: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0126\n",
      "Epoch 344/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00344: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0132\n",
      "Epoch 345/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00345: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0141\n",
      "Epoch 346/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00346: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0126\n",
      "Epoch 347/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00347: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0147\n",
      "Epoch 348/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00348: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0136\n",
      "Epoch 349/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00349: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0126\n",
      "Epoch 350/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00350: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0035 - val_loss: 0.0151\n",
      "Epoch 351/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00351: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0122\n",
      "Epoch 352/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00352: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0142\n",
      "Epoch 353/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00353: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0127\n",
      "Epoch 354/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00354: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0141\n",
      "Epoch 355/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00355: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0136\n",
      "Epoch 356/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00356: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0126\n",
      "Epoch 357/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0030   \n",
      "Epoch 00357: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0151\n",
      "Epoch 358/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00358: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0119\n",
      "Epoch 359/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00359: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0034 - val_loss: 0.0156\n",
      "Epoch 360/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00360: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0154\n",
      "Epoch 361/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00361: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0148\n",
      "Epoch 362/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00362: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0151\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00363: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.0132\n",
      "Epoch 364/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00364: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0128\n",
      "Epoch 365/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00365: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0146\n",
      "Epoch 366/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00366: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0128\n",
      "Epoch 367/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00367: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0147\n",
      "Epoch 368/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00368: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0128\n",
      "Epoch 369/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00369: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0146\n",
      "Epoch 370/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00370: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0127\n",
      "Epoch 371/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00371: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0143\n",
      "Epoch 372/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00372: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 373/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00373: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0138\n",
      "Epoch 374/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00374: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0123\n",
      "Epoch 375/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00375: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0131\n",
      "Epoch 376/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00376: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0132\n",
      "Epoch 377/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00377: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0134\n",
      "Epoch 378/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00378: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0127\n",
      "Epoch 379/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00379: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 380/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00380: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0138\n",
      "Epoch 381/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00381: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0129\n",
      "Epoch 382/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00382: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0149\n",
      "Epoch 383/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00383: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0147\n",
      "Epoch 384/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00384: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0150\n",
      "Epoch 385/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00385: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0145\n",
      "Epoch 386/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00386: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0139\n",
      "Epoch 387/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00387: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0133\n",
      "Epoch 388/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00388: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0128\n",
      "Epoch 389/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00389: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0131\n",
      "Epoch 390/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00390: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0018 - val_loss: 0.0123\n",
      "Epoch 391/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00391: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0130\n",
      "Epoch 392/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014    - ETA: 0s - loss: 3.3826e-\n",
      "Epoch 00392: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 393/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00393: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0129\n",
      "Epoch 394/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00394: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0133\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0020   \n",
      "Epoch 00395: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0020 - val_loss: 0.0133\n",
      "Epoch 396/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0020   \n",
      "Epoch 00396: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0141\n",
      "Epoch 397/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00397: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.0022 - val_loss: 0.0139\n",
      "Epoch 398/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00398: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0137\n",
      "Epoch 399/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00399: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0144\n",
      "Epoch 400/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00400: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0132\n",
      "Epoch 401/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00401: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0143\n",
      "Epoch 402/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00402: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0129\n",
      "Epoch 403/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00403: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0138\n",
      "Epoch 404/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00404: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0128\n",
      "Epoch 405/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00405: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0135\n",
      "Epoch 406/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8224e-04\n",
      "Epoch 00406: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0128\n",
      "Epoch 407/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00407: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0132\n",
      "Epoch 408/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00408: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0129\n",
      "Epoch 409/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00409: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0130\n",
      "Epoch 410/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00410: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0129\n",
      "Epoch 411/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00411: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0131\n",
      "Epoch 412/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0950e-04\n",
      "Epoch 00412: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0128\n",
      "Epoch 413/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00413: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0133\n",
      "Epoch 414/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00414: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 415/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00415: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0134\n",
      "Epoch 416/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00416: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 417/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00417: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0134\n",
      "Epoch 418/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00418: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0128\n",
      "Epoch 419/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0031   \n",
      "Epoch 00419: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0134\n",
      "Epoch 420/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00420: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0134\n",
      "Epoch 421/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00421: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0139\n",
      "Epoch 422/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00422: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0123\n",
      "Epoch 423/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00423: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0126\n",
      "Epoch 424/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9815e-04\n",
      "Epoch 00424: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0122\n",
      "Epoch 425/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00425: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 426/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00426: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 427/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7140e-04\n",
      "Epoch 00427: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0123\n",
      "Epoch 428/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9415e-04\n",
      "Epoch 00428: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0127\n",
      "Epoch 429/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.1827e-04\n",
      "Epoch 00429: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0126\n",
      "Epoch 430/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00430: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0131\n",
      "Epoch 431/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00431: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0134\n",
      "Epoch 432/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00432: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0132\n",
      "Epoch 433/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00433: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0137\n",
      "Epoch 434/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00434: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0137\n",
      "Epoch 435/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00435: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0132\n",
      "Epoch 436/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00436: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0138\n",
      "Epoch 437/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00437: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0128\n",
      "Epoch 438/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00438: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0135\n",
      "Epoch 439/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2690e-04\n",
      "Epoch 00439: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 440/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00440: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0128\n",
      "Epoch 441/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7405e-04\n",
      "Epoch 00441: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0128\n",
      "Epoch 442/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00442: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0124\n",
      "Epoch 443/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7090e-04\n",
      "Epoch 00443: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0127\n",
      "Epoch 444/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9721e-04\n",
      "Epoch 00444: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0123\n",
      "Epoch 445/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7629e-04\n",
      "Epoch 00445: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0122\n",
      "Epoch 446/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4933e-04\n",
      "Epoch 00446: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 447/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5872e-04\n",
      "Epoch 00447: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0120\n",
      "Epoch 448/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2895e-04\n",
      "Epoch 00448: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.9077e-04 - val_loss: 0.0126\n",
      "Epoch 449/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1275e-04\n",
      "Epoch 00449: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2122e-04 - val_loss: 0.0120\n",
      "Epoch 450/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6269e-04\n",
      "Epoch 00450: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0125e-04 - val_loss: 0.0125\n",
      "Epoch 451/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3868e-04\n",
      "Epoch 00451: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.2690e-04 - val_loss: 0.0123\n",
      "Epoch 452/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6948e-04\n",
      "Epoch 00452: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.3753e-04 - val_loss: 0.0122\n",
      "Epoch 453/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7716e-04\n",
      "Epoch 00453: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 454/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9450e-04\n",
      "Epoch 00454: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0121\n",
      "Epoch 455/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00455: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0128\n",
      "Epoch 456/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00456: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0124\n",
      "Epoch 457/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00457: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0127\n",
      "Epoch 458/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00458: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0139\n",
      "Epoch 459/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00459: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0134\n",
      "Epoch 460/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00460: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0123\n",
      "Epoch 461/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00461: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0128\n",
      "Epoch 462/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00462: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0135\n",
      "Epoch 463/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00463: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0136\n",
      "Epoch 464/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00464: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 465/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00465: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0107\n",
      "Epoch 466/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00466: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0130\n",
      "Epoch 467/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9470e-04\n",
      "Epoch 00467: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0127\n",
      "Epoch 468/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1101e-04\n",
      "Epoch 00468: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.2576e-04 - val_loss: 0.0118\n",
      "Epoch 469/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7134e-04\n",
      "Epoch 00469: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0125\n",
      "Epoch 470/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8392e-04\n",
      "Epoch 00470: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7865e-04 - val_loss: 0.0119\n",
      "Epoch 471/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3159e-04\n",
      "Epoch 00471: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.8066e-04 - val_loss: 0.0125\n",
      "Epoch 472/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7006e-04\n",
      "Epoch 00472: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6879e-04 - val_loss: 0.0120\n",
      "Epoch 473/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3881e-04\n",
      "Epoch 00473: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.9115e-04 - val_loss: 0.0125\n",
      "Epoch 474/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9210e-04\n",
      "Epoch 00474: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.0353e-04 - val_loss: 0.0121\n",
      "Epoch 475/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9670e-04\n",
      "Epoch 00475: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0126\n",
      "Epoch 476/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6138e-04\n",
      "Epoch 00476: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.8580e-04 - val_loss: 0.0122\n",
      "Epoch 477/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00477: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 478/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8388e-04\n",
      "Epoch 00478: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 479/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00479: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0126\n",
      "Epoch 480/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9949e-04\n",
      "Epoch 00480: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0126\n",
      "Epoch 481/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00481: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 482/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9682e-04\n",
      "Epoch 00482: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0126\n",
      "Epoch 483/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00483: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0127\n",
      "Epoch 484/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4895e-04\n",
      "Epoch 00484: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.4424e-04 - val_loss: 0.0125\n",
      "Epoch 485/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2711e-04\n",
      "Epoch 00485: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0126\n",
      "Epoch 486/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1908e-04\n",
      "Epoch 00486: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3660e-04 - val_loss: 0.0124\n",
      "Epoch 487/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5094e-04\n",
      "Epoch 00487: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0126\n",
      "Epoch 488/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9623e-04\n",
      "Epoch 00488: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 489/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00489: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 490/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00490: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0126\n",
      "Epoch 491/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00491: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0112\n",
      "Epoch 492/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7980e-04\n",
      "Epoch 00492: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0137\n",
      "Epoch 493/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00493: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0124\n",
      "Epoch 494/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3557e-04\n",
      "Epoch 00494: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.9756e-04 - val_loss: 0.0115\n",
      "Epoch 495/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7104e-04\n",
      "Epoch 00495: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0127\n",
      "Epoch 496/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0601e-04\n",
      "Epoch 00496: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.8500e-04 - val_loss: 0.0123\n",
      "Epoch 497/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2607e-04\n",
      "Epoch 00497: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 498/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1786e-04\n",
      "Epoch 00498: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1748e-04 - val_loss: 0.0125\n",
      "Epoch 499/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5806e-04\n",
      "Epoch 00499: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0124\n",
      "Epoch 500/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3605e-04\n",
      "Epoch 00500: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5233e-04 - val_loss: 0.0127\n",
      "Epoch 501/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8921e-04\n",
      "Epoch 00501: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 502/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8475e-04\n",
      "Epoch 00502: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.9926e-04 - val_loss: 0.0126\n",
      "Epoch 503/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00503: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0128\n",
      "Epoch 504/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3993e-04\n",
      "Epoch 00504: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0125\n",
      "Epoch 505/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00505: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0129\n",
      "Epoch 506/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1290e-04\n",
      "Epoch 00506: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0127\n",
      "Epoch 507/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00507: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0127\n",
      "Epoch 508/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3899e-04\n",
      "Epoch 00508: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5135e-04 - val_loss: 0.0128\n",
      "Epoch 509/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9616e-04\n",
      "Epoch 00509: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0124\n",
      "Epoch 510/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9287e-04\n",
      "Epoch 00510: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7829e-04 - val_loss: 0.0128\n",
      "Epoch 511/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1820e-04\n",
      "Epoch 00511: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.4390e-04 - val_loss: 0.0124\n",
      "Epoch 512/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0325e-04\n",
      "Epoch 00512: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.8628e-04 - val_loss: 0.0128\n",
      "Epoch 513/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5110e-04\n",
      "Epoch 00513: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0123\n",
      "Epoch 514/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5925e-04\n",
      "Epoch 00514: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5427e-04 - val_loss: 0.0127\n",
      "Epoch 515/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5434e-04\n",
      "Epoch 00515: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0123\n",
      "Epoch 516/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3335e-04\n",
      "Epoch 00516: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8751e-04 - val_loss: 0.0124\n",
      "Epoch 517/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2354e-04\n",
      "Epoch 00517: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.3717e-04 - val_loss: 0.0125\n",
      "Epoch 518/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7088e-04\n",
      "Epoch 00518: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.2229e-04 - val_loss: 0.0121\n",
      "Epoch 519/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.2492e-0 - ETA: 0s - loss: 9.0667e-04\n",
      "Epoch 00519: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.0332e-04 - val_loss: 0.0127\n",
      "Epoch 520/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3019e-04\n",
      "Epoch 00520: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.8782e-04 - val_loss: 0.0121\n",
      "Epoch 521/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8978e-04\n",
      "Epoch 00521: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7705e-04 - val_loss: 0.0127\n",
      "Epoch 522/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0879e-04\n",
      "Epoch 00522: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.8769e-04 - val_loss: 0.0122\n",
      "Epoch 523/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0040e-04\n",
      "Epoch 00523: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.0648e-04 - val_loss: 0.0127\n",
      "Epoch 524/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3678e-04\n",
      "Epoch 00524: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8215e-04 - val_loss: 0.0123\n",
      "Epoch 525/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8419e-04\n",
      "Epoch 00525: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0128\n",
      "Epoch 526/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0834e-04\n",
      "Epoch 00526: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0124\n",
      "Epoch 527/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7977e-04\n",
      "Epoch 00527: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0127\n",
      "Epoch 528/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7599e-04\n",
      "Epoch 00528: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0123\n",
      "Epoch 529/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00529: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0112\n",
      "Epoch 530/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00530: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0016 - val_loss: 0.0124\n",
      "Epoch 531/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00531: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0134\n",
      "Epoch 532/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00532: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0104\n",
      "Epoch 533/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00533: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0112\n",
      "Epoch 534/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5934e-04\n",
      "Epoch 00534: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 535/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5461e-04\n",
      "Epoch 00535: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.6831e-04 - val_loss: 0.0116\n",
      "Epoch 536/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9971e-04\n",
      "Epoch 00536: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7945e-04 - val_loss: 0.0116\n",
      "Epoch 537/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6484e-04\n",
      "Epoch 00537: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0505e-04 - val_loss: 0.0114\n",
      "Epoch 538/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1993e-04\n",
      "Epoch 00538: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4025e-04 - val_loss: 0.0115\n",
      "Epoch 539/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6616e-04\n",
      "Epoch 00539: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0649e-04 - val_loss: 0.0115\n",
      "Epoch 540/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5643e-04\n",
      "Epoch 00540: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7664e-04 - val_loss: 0.0118\n",
      "Epoch 541/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0320e-04\n",
      "Epoch 00541: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.7003e-04 - val_loss: 0.0117\n",
      "Epoch 542/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2103e-04\n",
      "Epoch 00542: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2551e-04 - val_loss: 0.0119\n",
      "Epoch 543/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4110e-04\n",
      "Epoch 00543: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.5827e-04 - val_loss: 0.0121\n",
      "Epoch 544/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00544: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0122\n",
      "Epoch 545/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9109e-04\n",
      "Epoch 00545: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0127\n",
      "Epoch 546/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00546: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0121\n",
      "Epoch 547/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2565e-04\n",
      "Epoch 00547: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0129\n",
      "Epoch 548/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6269e-04\n",
      "Epoch 00548: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0120\n",
      "Epoch 549/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9592e-04\n",
      "Epoch 00549: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1073e-04 - val_loss: 0.0127\n",
      "Epoch 550/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1079e-04\n",
      "Epoch 00550: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0720e-04 - val_loss: 0.0118\n",
      "Epoch 551/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0676e-04\n",
      "Epoch 00551: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7791e-04 - val_loss: 0.0125\n",
      "Epoch 552/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.9682e-04\n",
      "Epoch 00552: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.9425e-04 - val_loss: 0.0119\n",
      "Epoch 553/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.9942e-04\n",
      "Epoch 00553: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 7.0788e-04 - val_loss: 0.0123\n",
      "Epoch 554/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6179e-04\n",
      "Epoch 00554: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.4349e-04 - val_loss: 0.0118\n",
      "Epoch 555/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3781e-04\n",
      "Epoch 00555: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.7254e-04 - val_loss: 0.0122\n",
      "Epoch 556/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3329e-04\n",
      "Epoch 00556: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.1546e-04 - val_loss: 0.0119\n",
      "Epoch 557/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.6395e-04\n",
      "Epoch 00557: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.6122e-04 - val_loss: 0.0121\n",
      "Epoch 558/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.0989e-04\n",
      "Epoch 00558: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.0989e-04 - val_loss: 0.0119\n",
      "Epoch 559/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3575e-04\n",
      "Epoch 00559: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6899e-04 - val_loss: 0.0121\n",
      "Epoch 560/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4169e-04\n",
      "Epoch 00560: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2959e-04 - val_loss: 0.0120\n",
      "Epoch 561/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6065e-04\n",
      "Epoch 00561: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.0622e-04 - val_loss: 0.0120\n",
      "Epoch 562/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7755e-04\n",
      "Epoch 00562: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7242e-04 - val_loss: 0.0120\n",
      "Epoch 563/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9706e-04\n",
      "Epoch 00563: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5758e-04 - val_loss: 0.0120\n",
      "Epoch 564/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2471e-04\n",
      "Epoch 00564: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.2662e-04 - val_loss: 0.0121\n",
      "Epoch 565/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.2638e-04\n",
      "Epoch 00565: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.9670e-04 - val_loss: 0.0120\n",
      "Epoch 566/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6250e-04\n",
      "Epoch 00566: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6826e-04 - val_loss: 0.0122\n",
      "Epoch 567/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3575e-04\n",
      "Epoch 00567: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.1218e-04 - val_loss: 0.0120\n",
      "Epoch 568/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7479e-04\n",
      "Epoch 00568: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7596e-04 - val_loss: 0.0122\n",
      "Epoch 569/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1952e-04\n",
      "Epoch 00569: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.8928e-04 - val_loss: 0.0121\n",
      "Epoch 570/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5727e-04\n",
      "Epoch 00570: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.4407e-04 - val_loss: 0.0121\n",
      "Epoch 571/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9323e-04\n",
      "Epoch 00571: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5094e-04 - val_loss: 0.0121\n",
      "Epoch 572/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4597e-04\n",
      "Epoch 00572: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.2187e-04 - val_loss: 0.0121\n",
      "Epoch 573/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8598e-04\n",
      "Epoch 00573: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4515e-04 - val_loss: 0.0122\n",
      "Epoch 574/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7996e-04\n",
      "Epoch 00574: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.5194e-04 - val_loss: 0.0122\n",
      "Epoch 575/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1523e-04\n",
      "Epoch 00575: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.9782e-04 - val_loss: 0.0122\n",
      "Epoch 576/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6693e-04\n",
      "Epoch 00576: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.4395e-04 - val_loss: 0.0124\n",
      "Epoch 577/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7496e-04\n",
      "Epoch 00577: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0369e-04 - val_loss: 0.0123\n",
      "Epoch 578/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2798e-04\n",
      "Epoch 00578: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0125\n",
      "Epoch 579/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7485e-04\n",
      "Epoch 00579: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1779e-04 - val_loss: 0.0124\n",
      "Epoch 580/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6905e-04\n",
      "Epoch 00580: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5626e-04 - val_loss: 0.0123\n",
      "Epoch 581/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0373e-04\n",
      "Epoch 00581: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.0546e-04 - val_loss: 0.0124\n",
      "Epoch 582/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.1248e-04\n",
      "Epoch 00582: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.2402e-04 - val_loss: 0.0121\n",
      "Epoch 583/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5832e-04\n",
      "Epoch 00583: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.1228e-04 - val_loss: 0.0123\n",
      "Epoch 584/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4862e-04\n",
      "Epoch 00584: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2038e-04 - val_loss: 0.0119\n",
      "Epoch 585/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3322e-04\n",
      "Epoch 00585: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6196e-04 - val_loss: 0.0122\n",
      "Epoch 586/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9441e-04\n",
      "Epoch 00586: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8403e-04 - val_loss: 0.0118\n",
      "Epoch 587/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1470e-04\n",
      "Epoch 00587: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5527e-04 - val_loss: 0.0123\n",
      "Epoch 588/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7403e-04\n",
      "Epoch 00588: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8822e-04 - val_loss: 0.0117\n",
      "Epoch 589/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1328e-04\n",
      "Epoch 00589: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7908e-04 - val_loss: 0.0123\n",
      "Epoch 590/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9717e-04\n",
      "Epoch 00590: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.1555e-04 - val_loss: 0.0117\n",
      "Epoch 591/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4999e-04\n",
      "Epoch 00591: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0324e-04 - val_loss: 0.0122\n",
      "Epoch 592/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8004e-04\n",
      "Epoch 00592: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.8078e-04 - val_loss: 0.0119\n",
      "Epoch 593/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0549e-04\n",
      "Epoch 00593: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4513e-04 - val_loss: 0.0120\n",
      "Epoch 594/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7373e-04\n",
      "Epoch 00594: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.5617e-04 - val_loss: 0.0122\n",
      "Epoch 595/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5968e-04\n",
      "Epoch 00595: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.1438e-04 - val_loss: 0.0117\n",
      "Epoch 596/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8681e-04\n",
      "Epoch 00596: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2809e-04 - val_loss: 0.0127\n",
      "Epoch 597/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9635e-04\n",
      "Epoch 00597: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.3775e-04 - val_loss: 0.0120\n",
      "Epoch 598/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7560e-04\n",
      "Epoch 00598: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.9849e-04 - val_loss: 0.0125\n",
      "Epoch 599/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5721e-04\n",
      "Epoch 00599: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3069e-04 - val_loss: 0.0124\n",
      "Epoch 600/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8146e-04\n",
      "Epoch 00600: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0118\n",
      "Epoch 601/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6531e-04\n",
      "Epoch 00601: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.7926e-04 - val_loss: 0.0127\n",
      "Epoch 602/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6904e-04\n",
      "Epoch 00602: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0119\n",
      "Epoch 603/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0586e-04\n",
      "Epoch 00603: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0126\n",
      "Epoch 604/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00604: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0130\n",
      "Epoch 605/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6447e-04\n",
      "Epoch 00605: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.8978e-04 - val_loss: 0.0128\n",
      "Epoch 606/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00606: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 607/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8352e-04\n",
      "Epoch 00607: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.6135e-04 - val_loss: 0.0129\n",
      "Epoch 608/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0947e-04\n",
      "Epoch 00608: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7925e-04 - val_loss: 0.0116\n",
      "Epoch 609/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4822e-04\n",
      "Epoch 00609: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.9687e-04 - val_loss: 0.0126\n",
      "Epoch 610/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1038e-04\n",
      "Epoch 00610: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5428e-04 - val_loss: 0.0119\n",
      "Epoch 611/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3745e-04\n",
      "Epoch 00611: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7758e-04 - val_loss: 0.0123\n",
      "Epoch 612/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2092e-04\n",
      "Epoch 00612: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4934e-04 - val_loss: 0.0122\n",
      "Epoch 613/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2736e-04\n",
      "Epoch 00613: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5849e-04 - val_loss: 0.0121\n",
      "Epoch 614/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0278e-04\n",
      "Epoch 00614: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2866e-04 - val_loss: 0.0122\n",
      "Epoch 615/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0588e-04\n",
      "Epoch 00615: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.2533e-04 - val_loss: 0.0122\n",
      "Epoch 616/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5990e-04\n",
      "Epoch 00616: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.9050e-04 - val_loss: 0.0122\n",
      "Epoch 617/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8955e-04\n",
      "Epoch 00617: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.9894e-04 - val_loss: 0.0122\n",
      "Epoch 618/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1874e-04\n",
      "Epoch 00618: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.5672e-04 - val_loss: 0.0121\n",
      "Epoch 619/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8135e-04\n",
      "Epoch 00619: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.8989e-04 - val_loss: 0.0122\n",
      "Epoch 620/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9727e-04\n",
      "Epoch 00620: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4633e-04 - val_loss: 0.0121\n",
      "Epoch 621/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9128e-04\n",
      "Epoch 00621: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0923e-04 - val_loss: 0.0122\n",
      "Epoch 622/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1470e-04\n",
      "Epoch 00622: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7613e-04 - val_loss: 0.0121\n",
      "Epoch 623/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2770e-04\n",
      "Epoch 00623: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6992e-04 - val_loss: 0.0123\n",
      "Epoch 624/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7034e-04\n",
      "Epoch 00624: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4970e-04 - val_loss: 0.0120\n",
      "Epoch 625/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9793e-04\n",
      "Epoch 00625: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5830e-04 - val_loss: 0.0124\n",
      "Epoch 626/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4694e-04\n",
      "Epoch 00626: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.2372e-04 - val_loss: 0.0120\n",
      "Epoch 627/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3811e-04\n",
      "Epoch 00627: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6282e-04 - val_loss: 0.0124\n",
      "Epoch 628/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3447e-04\n",
      "Epoch 00628: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2158e-04 - val_loss: 0.0119\n",
      "Epoch 629/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1901e-04\n",
      "Epoch 00629: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.3156e-04 - val_loss: 0.0124\n",
      "Epoch 630/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9359e-04\n",
      "Epoch 00630: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.9543e-04 - val_loss: 0.0123\n",
      "Epoch 631/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7628e-04\n",
      "Epoch 00631: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.3772e-04 - val_loss: 0.0125\n",
      "Epoch 632/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0204e-04\n",
      "Epoch 00632: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5412e-04 - val_loss: 0.0127\n",
      "Epoch 633/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1908e-04\n",
      "Epoch 00633: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8145e-04 - val_loss: 0.0123\n",
      "Epoch 634/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00634: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0125\n",
      "Epoch 635/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0588e-04\n",
      "Epoch 00635: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8885e-04 - val_loss: 0.0125\n",
      "Epoch 636/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00636: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0124\n",
      "Epoch 637/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0534e-04\n",
      "Epoch 00637: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3607e-04 - val_loss: 0.0123\n",
      "Epoch 638/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00638: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0121\n",
      "Epoch 639/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00639: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0115\n",
      "Epoch 640/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00640: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0120\n",
      "Epoch 641/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00641: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0103\n",
      "Epoch 642/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00642: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0114\n",
      "Epoch 643/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00643: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0109\n",
      "Epoch 644/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6679e-04\n",
      "Epoch 00644: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0118\n",
      "Epoch 645/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00645: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0118\n",
      "Epoch 646/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0061e-04\n",
      "Epoch 00646: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8824e-04 - val_loss: 0.0117\n",
      "Epoch 647/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1453e-04\n",
      "Epoch 00647: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7729e-04 - val_loss: 0.0121\n",
      "Epoch 648/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2648e-04\n",
      "Epoch 00648: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5391e-04 - val_loss: 0.0121\n",
      "Epoch 649/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8551e-04\n",
      "Epoch 00649: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4645e-04 - val_loss: 0.0120\n",
      "Epoch 650/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2134e-04\n",
      "Epoch 00650: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4378e-04 - val_loss: 0.0121\n",
      "Epoch 651/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7932e-04\n",
      "Epoch 00651: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5059e-04 - val_loss: 0.0121\n",
      "Epoch 652/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8443e-04\n",
      "Epoch 00652: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4454e-04 - val_loss: 0.0125\n",
      "Epoch 653/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6142e-04\n",
      "Epoch 00653: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.3519e-04 - val_loss: 0.0119\n",
      "Epoch 654/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2963e-04\n",
      "Epoch 00654: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8091e-04 - val_loss: 0.0124\n",
      "Epoch 655/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3000e-04\n",
      "Epoch 00655: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8105e-04 - val_loss: 0.0119\n",
      "Epoch 656/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7727e-04\n",
      "Epoch 00656: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0336e-04 - val_loss: 0.0122\n",
      "Epoch 657/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8007e-04\n",
      "Epoch 00657: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2335e-04 - val_loss: 0.0119\n",
      "Epoch 658/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5780e-04\n",
      "Epoch 00658: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6415e-04 - val_loss: 0.0122\n",
      "Epoch 659/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3839e-04\n",
      "Epoch 00659: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7843e-04 - val_loss: 0.0119\n",
      "Epoch 660/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4067e-04\n",
      "Epoch 00660: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3185e-04 - val_loss: 0.0122\n",
      "Epoch 661/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1215e-04\n",
      "Epoch 00661: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5294e-04 - val_loss: 0.0119\n",
      "Epoch 662/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3317e-04\n",
      "Epoch 00662: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1715e-04 - val_loss: 0.0122\n",
      "Epoch 663/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9682e-04\n",
      "Epoch 00663: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3837e-04 - val_loss: 0.0119\n",
      "Epoch 664/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2767e-04\n",
      "Epoch 00664: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0822e-04 - val_loss: 0.0122\n",
      "Epoch 665/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9276e-04\n",
      "Epoch 00665: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3377e-04 - val_loss: 0.0119\n",
      "Epoch 666/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2532e-04\n",
      "Epoch 00666: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0492e-04 - val_loss: 0.0122\n",
      "Epoch 667/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9737e-04\n",
      "Epoch 00667: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.3755e-04 - val_loss: 0.0119\n",
      "Epoch 668/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2713e-04\n",
      "Epoch 00668: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0831e-04 - val_loss: 0.0122\n",
      "Epoch 669/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1049e-04\n",
      "Epoch 00669: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4970e-04 - val_loss: 0.0120\n",
      "Epoch 670/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3380e-04\n",
      "Epoch 00670: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1906e-04 - val_loss: 0.0122\n",
      "Epoch 671/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3234e-04\n",
      "Epoch 00671: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7100e-04 - val_loss: 0.0120\n",
      "Epoch 672/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4506e-04\n",
      "Epoch 00672: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3756e-04 - val_loss: 0.0123\n",
      "Epoch 673/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5636e-04\n",
      "Epoch 00673: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9572e-04 - val_loss: 0.0120\n",
      "Epoch 674/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5464e-04\n",
      "Epoch 00674: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5627e-04 - val_loss: 0.0123\n",
      "Epoch 675/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7209e-04\n",
      "Epoch 00675: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.1224e-04 - val_loss: 0.0119\n",
      "Epoch 676/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5586e-04\n",
      "Epoch 00676: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6326e-04 - val_loss: 0.0123\n",
      "Epoch 677/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7709e-04\n",
      "Epoch 00677: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.1603e-04 - val_loss: 0.0120\n",
      "Epoch 678/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5215e-04\n",
      "Epoch 00678: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5963e-04 - val_loss: 0.0122\n",
      "Epoch 679/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7949e-04\n",
      "Epoch 00679: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.1562e-04 - val_loss: 0.0120\n",
      "Epoch 680/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5244e-04\n",
      "Epoch 00680: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5840e-04 - val_loss: 0.0122\n",
      "Epoch 681/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8398e-04\n",
      "Epoch 00681: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.1718e-04 - val_loss: 0.0121\n",
      "Epoch 682/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.5977e-04\n",
      "Epoch 00682: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5977e-04 - val_loss: 0.0121\n",
      "Epoch 683/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8782e-04\n",
      "Epoch 00683: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2078e-04 - val_loss: 0.0121\n",
      "Epoch 684/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5203e-04\n",
      "Epoch 00684: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6226e-04 - val_loss: 0.0120\n",
      "Epoch 685/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9933e-04\n",
      "Epoch 00685: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.3517e-04 - val_loss: 0.0122\n",
      "Epoch 686/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6159e-04\n",
      "Epoch 00686: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8206e-04 - val_loss: 0.0120\n",
      "Epoch 687/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.2973e-04\n",
      "Epoch 00687: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6914e-04 - val_loss: 0.0123\n",
      "Epoch 688/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8868e-04\n",
      "Epoch 00688: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2000e-04 - val_loss: 0.0120\n",
      "Epoch 689/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7543e-04\n",
      "Epoch 00689: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.1486e-04 - val_loss: 0.0123\n",
      "Epoch 690/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3996e-04\n",
      "Epoch 00690: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7119e-04 - val_loss: 0.0121\n",
      "Epoch 691/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4032e-04\n",
      "Epoch 00691: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7901e-04 - val_loss: 0.0123\n",
      "Epoch 692/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4314e-04\n",
      "Epoch 00692: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7607e-04 - val_loss: 0.0125\n",
      "Epoch 693/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2009e-04\n",
      "Epoch 00693: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7252e-04 - val_loss: 0.0121\n",
      "Epoch 694/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3634e-04\n",
      "Epoch 00694: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.9864e-04 - val_loss: 0.0127\n",
      "Epoch 695/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6621e-04\n",
      "Epoch 00695: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.5881e-04 - val_loss: 0.0115\n",
      "Epoch 696/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1892e-04\n",
      "Epoch 00696: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.6305e-04 - val_loss: 0.0126\n",
      "Epoch 697/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5674e-04\n",
      "Epoch 00697: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.9576e-04 - val_loss: 0.0117\n",
      "Epoch 698/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3023e-04\n",
      "Epoch 00698: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0998e-04 - val_loss: 0.0121\n",
      "Epoch 699/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8193e-04\n",
      "Epoch 00699: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0810e-04 - val_loss: 0.0120\n",
      "Epoch 700/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3651e-04\n",
      "Epoch 00700: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4380e-04 - val_loss: 0.0120\n",
      "Epoch 701/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2469e-04\n",
      "Epoch 00701: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4751e-04 - val_loss: 0.0119\n",
      "Epoch 702/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5822e-04\n",
      "Epoch 00702: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.9093e-04 - val_loss: 0.0121\n",
      "Epoch 703/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5184e-04\n",
      "Epoch 00703: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.6725e-04 - val_loss: 0.0120\n",
      "Epoch 704/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0851e-04\n",
      "Epoch 00704: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2262e-04 - val_loss: 0.0122\n",
      "Epoch 705/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7039e-04\n",
      "Epoch 00705: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.9314e-04 - val_loss: 0.0120\n",
      "Epoch 706/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4946e-04\n",
      "Epoch 00706: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5331e-04 - val_loss: 0.0123\n",
      "Epoch 707/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4250e-04\n",
      "Epoch 00707: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9636e-04 - val_loss: 0.0119\n",
      "Epoch 708/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3161e-04\n",
      "Epoch 00708: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3084e-04 - val_loss: 0.0125\n",
      "Epoch 709/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7541e-04\n",
      "Epoch 00709: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3044e-04 - val_loss: 0.0119\n",
      "Epoch 710/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0947e-04\n",
      "Epoch 00710: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8925e-04 - val_loss: 0.0125\n",
      "Epoch 711/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5720e-04\n",
      "Epoch 00711: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9800e-04 - val_loss: 0.0121\n",
      "Epoch 712/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9473e-04\n",
      "Epoch 00712: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6188e-04 - val_loss: 0.0123\n",
      "Epoch 713/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8274e-04\n",
      "Epoch 00713: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.1933e-04 - val_loss: 0.0122\n",
      "Epoch 714/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3129e-04\n",
      "Epoch 00714: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9729e-04 - val_loss: 0.0122\n",
      "Epoch 715/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5299e-04\n",
      "Epoch 00715: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8945e-04 - val_loss: 0.0122\n",
      "Epoch 716/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0375e-04\n",
      "Epoch 00716: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8580e-04 - val_loss: 0.0121\n",
      "Epoch 717/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3119e-04\n",
      "Epoch 00717: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7839e-04 - val_loss: 0.0122\n",
      "Epoch 718/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4993e-04\n",
      "Epoch 00718: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5063e-04 - val_loss: 0.0120\n",
      "Epoch 719/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6780e-04\n",
      "Epoch 00719: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2399e-04 - val_loss: 0.0122\n",
      "Epoch 720/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5992e-04\n",
      "Epoch 00720: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5267e-04 - val_loss: 0.0119\n",
      "Epoch 721/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3751e-04\n",
      "Epoch 00721: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8432e-04 - val_loss: 0.0123\n",
      "Epoch 722/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3819e-04\n",
      "Epoch 00722: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0556e-04 - val_loss: 0.0120\n",
      "Epoch 723/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5183e-04\n",
      "Epoch 00723: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9836e-04 - val_loss: 0.0124\n",
      "Epoch 724/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2845e-04\n",
      "Epoch 00724: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8183e-04 - val_loss: 0.0123\n",
      "Epoch 725/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9894e-04\n",
      "Epoch 00725: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6987e-04 - val_loss: 0.0123\n",
      "Epoch 726/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0619e-04\n",
      "Epoch 00726: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5965e-04 - val_loss: 0.0127\n",
      "Epoch 727/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7878e-04\n",
      "Epoch 00727: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0272e-04 - val_loss: 0.0121\n",
      "Epoch 728/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6503e-04\n",
      "Epoch 00728: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0897e-04 - val_loss: 0.0130\n",
      "Epoch 729/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2202e-04\n",
      "Epoch 00729: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.7369e-04 - val_loss: 0.0120\n",
      "Epoch 730/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00730: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0131\n",
      "Epoch 731/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00731: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0128\n",
      "Epoch 732/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031    \n",
      "Epoch 00732: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0147\n",
      "Epoch 733/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043    \n",
      "Epoch 00733: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0143\n",
      "Epoch 734/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00734: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0175\n",
      "Epoch 735/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0070\n",
      "Epoch 00735: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0157\n",
      "Epoch 736/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042\n",
      "Epoch 00736: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0134\n",
      "Epoch 737/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00737: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0144\n",
      "Epoch 738/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00738: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0111\n",
      "Epoch 739/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00739: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0116\n",
      "Epoch 740/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0173e-04\n",
      "Epoch 00740: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0131\n",
      "Epoch 741/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9327e-04\n",
      "Epoch 00741: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0113\n",
      "Epoch 742/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9497e-04\n",
      "Epoch 00742: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.7453e-04 - val_loss: 0.0122\n",
      "Epoch 743/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4365e-04\n",
      "Epoch 00743: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0212e-04 - val_loss: 0.0117\n",
      "Epoch 744/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7305e-04\n",
      "Epoch 00744: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.4703e-04 - val_loss: 0.0116\n",
      "Epoch 745/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.8709e-04\n",
      "Epoch 00745: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.8709e-04 - val_loss: 0.0117\n",
      "Epoch 746/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6593e-04\n",
      "Epoch 00746: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2393e-04 - val_loss: 0.0119\n",
      "Epoch 747/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5342e-04\n",
      "Epoch 00747: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0359e-04 - val_loss: 0.0117\n",
      "Epoch 748/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3993e-04\n",
      "Epoch 00748: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9041e-04 - val_loss: 0.0118\n",
      "Epoch 749/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5177e-04\n",
      "Epoch 00749: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9390e-04 - val_loss: 0.0118\n",
      "Epoch 750/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2432e-04\n",
      "Epoch 00750: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7321e-04 - val_loss: 0.0119\n",
      "Epoch 751/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2523e-04\n",
      "Epoch 00751: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6655e-04 - val_loss: 0.0118\n",
      "Epoch 752/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1327e-04\n",
      "Epoch 00752: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5684e-04 - val_loss: 0.0119\n",
      "Epoch 753/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1888e-04- ETA: 0s - loss: 2.9120e-0\n",
      "Epoch 00753: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5752e-04 - val_loss: 0.0119\n",
      "Epoch 754/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0240e-04\n",
      "Epoch 00754: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4561e-04 - val_loss: 0.0119\n",
      "Epoch 755/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0580e-04\n",
      "Epoch 00755: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4335e-04 - val_loss: 0.0119\n",
      "Epoch 756/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9339e-04\n",
      "Epoch 00756: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3430e-04 - val_loss: 0.0119\n",
      "Epoch 757/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9970e-04\n",
      "Epoch 00757: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3589e-04 - val_loss: 0.0120\n",
      "Epoch 758/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8583e-04\n",
      "Epoch 00758: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2666e-04 - val_loss: 0.0120\n",
      "Epoch 759/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9221e-04\n",
      "Epoch 00759: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2779e-04 - val_loss: 0.0120\n",
      "Epoch 760/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7795e-04\n",
      "Epoch 00760: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.1821e-04 - val_loss: 0.0120\n",
      "Epoch 761/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8814e-04\n",
      "Epoch 00761: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2260e-04 - val_loss: 0.0121\n",
      "Epoch 762/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7172e-04\n",
      "Epoch 00762: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.1235e-04 - val_loss: 0.0121\n",
      "Epoch 763/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8581e-04\n",
      "Epoch 00763: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.1956e-04 - val_loss: 0.0121\n",
      "Epoch 764/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6545e-04\n",
      "Epoch 00764: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0691e-04 - val_loss: 0.0121\n",
      "Epoch 765/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8747e-04\n",
      "Epoch 00765: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2000e-04 - val_loss: 0.0122\n",
      "Epoch 766/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6094e-04\n",
      "Epoch 00766: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0421e-04 - val_loss: 0.0121\n",
      "Epoch 767/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9698e-04\n",
      "Epoch 00767: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2827e-04 - val_loss: 0.0123\n",
      "Epoch 768/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6106e-04\n",
      "Epoch 00768: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0834e-04 - val_loss: 0.0121\n",
      "Epoch 769/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2276e-04\n",
      "Epoch 00769: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5241e-04 - val_loss: 0.0123\n",
      "Epoch 770/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7537e-04\n",
      "Epoch 00770: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3144e-04 - val_loss: 0.0121\n",
      "Epoch 771/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8151e-04\n",
      "Epoch 00771: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0840e-04 - val_loss: 0.0124\n",
      "Epoch 772/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2116e-04\n",
      "Epoch 00772: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9785e-04 - val_loss: 0.0121\n",
      "Epoch 773/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7102e-04\n",
      "Epoch 00773: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9476e-04 - val_loss: 0.0125\n",
      "Epoch 774/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7998e-04\n",
      "Epoch 00774: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8848e-04 - val_loss: 0.0122\n",
      "Epoch 775/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.2629e-04\n",
      "Epoch 00775: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5418e-04 - val_loss: 0.0124\n",
      "Epoch 776/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8555e-04\n",
      "Epoch 00776: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0427e-04 - val_loss: 0.0124\n",
      "Epoch 777/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9524e-04\n",
      "Epoch 00777: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2908e-04 - val_loss: 0.0123\n",
      "Epoch 778/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4727e-04\n",
      "Epoch 00778: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5050e-04 - val_loss: 0.0126\n",
      "Epoch 779/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1887e-04\n",
      "Epoch 00779: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5233e-04 - val_loss: 0.0122\n",
      "Epoch 780/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0470e-04\n",
      "Epoch 00780: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8708e-04 - val_loss: 0.0126\n",
      "Epoch 781/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6179e-04\n",
      "Epoch 00781: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9188e-04 - val_loss: 0.0121\n",
      "Epoch 782/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7793e-04\n",
      "Epoch 00782: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4305e-04 - val_loss: 0.0125\n",
      "Epoch 783/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2911e-04\n",
      "Epoch 00783: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5617e-04 - val_loss: 0.0121\n",
      "Epoch 784/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6244e-04\n",
      "Epoch 00784: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.1737e-04 - val_loss: 0.0125\n",
      "Epoch 785/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0982e-04\n",
      "Epoch 00785: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3518e-04 - val_loss: 0.0122\n",
      "Epoch 786/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5206e-04\n",
      "Epoch 00786: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0171e-04 - val_loss: 0.0124\n",
      "Epoch 787/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0170e-04\n",
      "Epoch 00787: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2577e-04 - val_loss: 0.0123\n",
      "Epoch 788/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.9616e-04\n",
      "Epoch 00788: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9404e-04 - val_loss: 0.0124\n",
      "Epoch 789/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.5220e-04\n",
      "Epoch 00789: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2868e-04 - val_loss: 0.0123\n",
      "Epoch 790/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9820e-04\n",
      "Epoch 00790: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9820e-04 - val_loss: 0.0124\n",
      "Epoch 791/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.5504e-04\n",
      "Epoch 00791: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.5253e-04 - val_loss: 0.0123\n",
      "Epoch 792/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.5251e-04\n",
      "Epoch 00792: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.3139e-04 - val_loss: 0.0123\n",
      "Epoch 793/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9457e-04\n",
      "Epoch 00793: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.0438e-04 - val_loss: 0.0123\n",
      "Epoch 794/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2983e-04\n",
      "Epoch 00794: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9517e-04 - val_loss: 0.0123\n",
      "Epoch 795/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4309e-04\n",
      "Epoch 00795: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4917e-04 - val_loss: 0.0121\n",
      "Epoch 796/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3933e-04\n",
      "Epoch 00796: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0842e-04 - val_loss: 0.0123\n",
      "Epoch 797/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2986e-04\n",
      "Epoch 00797: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4310e-04 - val_loss: 0.0121\n",
      "Epoch 798/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2555e-04\n",
      "Epoch 00798: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8654e-04 - val_loss: 0.0124\n",
      "Epoch 799/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8574e-04\n",
      "Epoch 00799: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0495e-04 - val_loss: 0.0122\n",
      "Epoch 800/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0407e-04\n",
      "Epoch 00800: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5917e-04 - val_loss: 0.0124\n",
      "Epoch 801/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5341e-04\n",
      "Epoch 00801: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7629e-04 - val_loss: 0.0122\n",
      "Epoch 802/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8651e-04\n",
      "Epoch 00802: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.4070e-04 - val_loss: 0.0124\n",
      "Epoch 803/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.6430e-04\n",
      "Epoch 00803: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.6430e-04 - val_loss: 0.0122\n",
      "Epoch 804/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8001e-04\n",
      "Epoch 00804: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 4.3730e-04 - val_loss: 0.0124\n",
      "Epoch 805/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.7582e-04\n",
      "Epoch 00805: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.6395e-04 - val_loss: 0.0122\n",
      "Epoch 806/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7907e-04\n",
      "Epoch 00806: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.4011e-04 - val_loss: 0.0125\n",
      "Epoch 807/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3397e-04\n",
      "Epoch 00807: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6909e-04 - val_loss: 0.0123\n",
      "Epoch 808/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8001e-04\n",
      "Epoch 00808: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.4319e-04 - val_loss: 0.0125\n",
      "Epoch 809/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3639e-04\n",
      "Epoch 00809: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.7090e-04 - val_loss: 0.0123\n",
      "Epoch 810/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7889e-04\n",
      "Epoch 00810: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.4102e-04 - val_loss: 0.0125\n",
      "Epoch 811/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4098e-04\n",
      "Epoch 00811: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.7147e-04 - val_loss: 0.0123\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.3921e-04\n",
      "Epoch 00812: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.3921e-04 - val_loss: 0.0125\n",
      "Epoch 813/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5713e-04\n",
      "Epoch 00813: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8243e-04 - val_loss: 0.0124\n",
      "Epoch 814/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9062e-04\n",
      "Epoch 00814: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5249e-04 - val_loss: 0.0125\n",
      "Epoch 815/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0161e-04\n",
      "Epoch 00815: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2220e-04 - val_loss: 0.0125\n",
      "Epoch 816/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2952e-04\n",
      "Epoch 00816: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0436e-04 - val_loss: 0.0125\n",
      "Epoch 817/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9185e-04\n",
      "Epoch 00817: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.1055e-04 - val_loss: 0.0125\n",
      "Epoch 818/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.0534e-04\n",
      "Epoch 00818: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.1350e-04 - val_loss: 0.0125\n",
      "Epoch 819/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1837e-04\n",
      "Epoch 00819: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.4562e-04 - val_loss: 0.0126\n",
      "Epoch 820/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8224e-04\n",
      "Epoch 00820: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4028e-04 - val_loss: 0.0128\n",
      "Epoch 821/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1086e-04\n",
      "Epoch 00821: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.5652e-04 - val_loss: 0.0127\n",
      "Epoch 822/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1287e-04\n",
      "Epoch 00822: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7566e-04 - val_loss: 0.0129\n",
      "Epoch 823/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5844e-04\n",
      "Epoch 00823: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.0765e-04 - val_loss: 0.0125\n",
      "Epoch 824/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.5258e-04\n",
      "Epoch 00824: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5258e-04 - val_loss: 0.0129\n",
      "Epoch 825/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1367e-04\n",
      "Epoch 00825: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.6014e-04 - val_loss: 0.0121\n",
      "Epoch 826/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7716e-04\n",
      "Epoch 00826: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.8770e-04 - val_loss: 0.0127\n",
      "Epoch 827/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4602e-04\n",
      "Epoch 00827: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.0271e-04 - val_loss: 0.0117\n",
      "Epoch 828/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4599e-04\n",
      "Epoch 00828: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.3228e-04 - val_loss: 0.0127\n",
      "Epoch 829/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5871e-04\n",
      "Epoch 00829: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9938e-04 - val_loss: 0.0118\n",
      "Epoch 830/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7815e-04\n",
      "Epoch 00830: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.2245e-04 - val_loss: 0.0125\n",
      "Epoch 831/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9111e-04\n",
      "Epoch 00831: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.1208e-04 - val_loss: 0.0121\n",
      "Epoch 832/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.3804e-04\n",
      "Epoch 00832: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.6917e-04 - val_loss: 0.0124\n",
      "Epoch 833/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6244e-04\n",
      "Epoch 00833: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.8001e-04 - val_loss: 0.0123\n",
      "Epoch 834/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2823e-04\n",
      "Epoch 00834: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.5743e-04 - val_loss: 0.0124\n",
      "Epoch 835/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5673e-04\n",
      "Epoch 00835: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.7305e-04 - val_loss: 0.0124\n",
      "Epoch 836/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.7287e-04\n",
      "Epoch 00836: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.7066e-04 - val_loss: 0.0124\n",
      "Epoch 837/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8126e-04\n",
      "Epoch 00837: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.9447e-04 - val_loss: 0.0124\n",
      "Epoch 838/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1714e-04\n",
      "Epoch 00838: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.4183e-04 - val_loss: 0.0125\n",
      "Epoch 839/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8422e-04\n",
      "Epoch 00839: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0095e-04 - val_loss: 0.0124\n",
      "Epoch 840/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.2516e-04\n",
      "Epoch 00840: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4011e-04 - val_loss: 0.0125\n",
      "Epoch 841/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0917e-04\n",
      "Epoch 00841: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7305e-04 - val_loss: 0.0122\n",
      "Epoch 842/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4748e-04\n",
      "Epoch 00842: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.9027e-04 - val_loss: 0.0124\n",
      "Epoch 843/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0932e-04\n",
      "Epoch 00843: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.7097e-04 - val_loss: 0.0122\n",
      "Epoch 844/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5704e-04\n",
      "Epoch 00844: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2584e-04 - val_loss: 0.0125\n",
      "Epoch 845/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9728e-04\n",
      "Epoch 00845: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4156e-04 - val_loss: 0.0122\n",
      "Epoch 846/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4439e-04\n",
      "Epoch 00846: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2340e-04 - val_loss: 0.0124\n",
      "Epoch 847/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9416e-04\n",
      "Epoch 00847: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3290e-04 - val_loss: 0.0122\n",
      "Epoch 848/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1942e-04\n",
      "Epoch 00848: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8732e-04 - val_loss: 0.0126\n",
      "Epoch 849/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6539e-04\n",
      "Epoch 00849: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9463e-04 - val_loss: 0.0124\n",
      "Epoch 850/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.5367e-04\n",
      "Epoch 00850: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.5265e-04 - val_loss: 0.0127\n",
      "Epoch 851/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4096e-04\n",
      "Epoch 00851: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7210e-04 - val_loss: 0.0126\n",
      "Epoch 852/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8301e-04\n",
      "Epoch 00852: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4309e-04 - val_loss: 0.0127\n",
      "Epoch 853/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.6159e-0 - ETA: 0s - loss: 4.9374e-04\n",
      "Epoch 00853: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.9163e-04 - val_loss: 0.0128\n",
      "Epoch 854/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1709e-04\n",
      "Epoch 00854: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.8077e-04 - val_loss: 0.0126\n",
      "Epoch 855/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8263e-04\n",
      "Epoch 00855: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9274e-04 - val_loss: 0.0129\n",
      "Epoch 856/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.4277e-0 - ETA: 0s - loss: 5.1047e-04\n",
      "Epoch 00856: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0974e-04 - val_loss: 0.0125\n",
      "Epoch 857/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0666e-04\n",
      "Epoch 00857: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0844e-04 - val_loss: 0.0125\n",
      "Epoch 858/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7123e-04\n",
      "Epoch 00858: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.7133e-04 - val_loss: 0.0126\n",
      "Epoch 859/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.1488e-04\n",
      "Epoch 00859: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.1488e-04 - val_loss: 0.0124\n",
      "Epoch 860/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4050e-04\n",
      "Epoch 00860: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1460e-04 - val_loss: 0.0127\n",
      "Epoch 861/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7810e-04\n",
      "Epoch 00861: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0035e-04 - val_loss: 0.0124\n",
      "Epoch 862/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4333e-04\n",
      "Epoch 00862: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.3534e-04 - val_loss: 0.0127\n",
      "Epoch 863/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3018e-04\n",
      "Epoch 00863: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0602e-04 - val_loss: 0.0121\n",
      "Epoch 864/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6827e-04\n",
      "Epoch 00864: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0255e-04 - val_loss: 0.0129\n",
      "Epoch 865/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2447e-04\n",
      "Epoch 00865: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.8829e-04 - val_loss: 0.0120\n",
      "Epoch 866/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3358e-04\n",
      "Epoch 00866: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1369e-04 - val_loss: 0.0128\n",
      "Epoch 867/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1539e-04\n",
      "Epoch 00867: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.2955e-04 - val_loss: 0.0122\n",
      "Epoch 868/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7542e-04\n",
      "Epoch 00868: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3626e-04 - val_loss: 0.0125\n",
      "Epoch 869/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5510e-04\n",
      "Epoch 00869: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6930e-04 - val_loss: 0.0123\n",
      "Epoch 870/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5702e-04\n",
      "Epoch 00870: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.0618e-04 - val_loss: 0.0125\n",
      "Epoch 871/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1581e-04\n",
      "Epoch 00871: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3862e-04 - val_loss: 0.0125\n",
      "Epoch 872/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7361e-04\n",
      "Epoch 00872: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2066e-04 - val_loss: 0.0126\n",
      "Epoch 873/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1791e-04\n",
      "Epoch 00873: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4322e-04 - val_loss: 0.0126\n",
      "Epoch 874/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8314e-04\n",
      "Epoch 00874: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3185e-04 - val_loss: 0.0126\n",
      "Epoch 875/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3139e-04\n",
      "Epoch 00875: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.5687e-04 - val_loss: 0.0126\n",
      "Epoch 876/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8648e-04\n",
      "Epoch 00876: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3471e-04 - val_loss: 0.0125\n",
      "Epoch 877/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4261e-04\n",
      "Epoch 00877: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6780e-04 - val_loss: 0.0127\n",
      "Epoch 878/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9102e-04\n",
      "Epoch 00878: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3481e-04 - val_loss: 0.0125\n",
      "Epoch 879/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4634e-04\n",
      "Epoch 00879: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.7045e-04 - val_loss: 0.0127\n",
      "Epoch 880/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9371e-04\n",
      "Epoch 00880: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3124e-04 - val_loss: 0.0126\n",
      "Epoch 881/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.6152e-04\n",
      "Epoch 00881: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.6152e-04 - val_loss: 0.0127\n",
      "Epoch 882/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9635e-04\n",
      "Epoch 00882: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2875e-04 - val_loss: 0.0126\n",
      "Epoch 883/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2190e-04\n",
      "Epoch 00883: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.4861e-04 - val_loss: 0.0127\n",
      "Epoch 884/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1299e-04- ETA: 0s - loss: 2.5450e-0\n",
      "Epoch 00884: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.4281e-04 - val_loss: 0.0128\n",
      "Epoch 885/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.5944e-04\n",
      "Epoch 00885: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.5944e-04 - val_loss: 0.0128\n",
      "Epoch 886/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6467e-04\n",
      "Epoch 00886: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9542e-04 - val_loss: 0.0130\n",
      "Epoch 887/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.2480e-04\n",
      "Epoch 00887: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.2480e-04 - val_loss: 0.0129\n",
      "Epoch 888/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5697e-04\n",
      "Epoch 00888: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.9061e-04 - val_loss: 0.0134\n",
      "Epoch 889/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.2533e-04\n",
      "Epoch 00889: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.2533e-04 - val_loss: 0.0130\n",
      "Epoch 890/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2073e-04\n",
      "Epoch 00890: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.4651e-04 - val_loss: 0.0137\n",
      "Epoch 891/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.9336e-04\n",
      "Epoch 00891: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.1632e-04 - val_loss: 0.0130\n",
      "Epoch 892/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00892: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0136\n",
      "Epoch 893/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00893: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0012 - val_loss: 0.0135\n",
      "Epoch 894/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00894: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0141\n",
      "Epoch 895/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00895: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0136\n",
      "Epoch 896/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00896: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0043 - val_loss: 0.0131\n",
      "Epoch 897/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0052- ETA: 0s - loss: 0.00\n",
      "Epoch 00897: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0052 - val_loss: 0.0133\n",
      "Epoch 898/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00898: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0048 - val_loss: 0.0114\n",
      "Epoch 899/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00899: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0114\n",
      "Epoch 900/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.7901e-04\n",
      "Epoch 00900: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.5180e-04 - val_loss: 0.0123\n",
      "Epoch 901/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.7090e-04\n",
      "Epoch 00901: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.7143e-04 - val_loss: 0.0116\n",
      "Epoch 902/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.2084e-04\n",
      "Epoch 00902: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.1930e-04 - val_loss: 0.0117\n",
      "Epoch 903/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8932e-04\n",
      "Epoch 00903: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2254e-04 - val_loss: 0.0112\n",
      "Epoch 904/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0398e-04\n",
      "Epoch 00904: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.6227e-04 - val_loss: 0.0119\n",
      "Epoch 905/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4065e-04\n",
      "Epoch 00905: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6398e-04 - val_loss: 0.0113\n",
      "Epoch 906/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.5663e-04\n",
      "Epoch 00906: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.5693e-04 - val_loss: 0.0118\n",
      "Epoch 907/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6956e-04\n",
      "Epoch 00907: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 4.7628e-04 - val_loss: 0.0114\n",
      "Epoch 908/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5608e-04\n",
      "Epoch 00908: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0779e-04 - val_loss: 0.0120\n",
      "Epoch 909/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1088e-04\n",
      "Epoch 00909: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.1738e-04 - val_loss: 0.0113\n",
      "Epoch 910/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2595e-04\n",
      "Epoch 00910: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.6102e-04 - val_loss: 0.0119\n",
      "Epoch 911/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5914e-04\n",
      "Epoch 00911: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6789e-04 - val_loss: 0.0115\n",
      "Epoch 912/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1025e-04\n",
      "Epoch 00912: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3770e-04 - val_loss: 0.0118\n",
      "Epoch 913/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4218e-04\n",
      "Epoch 00913: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.5081e-04 - val_loss: 0.0116\n",
      "Epoch 914/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0498e-04\n",
      "Epoch 00914: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.2853e-04 - val_loss: 0.0118\n",
      "Epoch 915/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 3.6194e-04\n",
      "Epoch 00915: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.3972e-04 - val_loss: 0.0117\n",
      "Epoch 916/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9833e-04\n",
      "Epoch 00916: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.2103e-04 - val_loss: 0.0118\n",
      "Epoch 917/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2136e-04\n",
      "Epoch 00917: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3259e-04 - val_loss: 0.0117\n",
      "Epoch 918/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9529e-04\n",
      "Epoch 00918: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1691e-04 - val_loss: 0.0118\n",
      "Epoch 919/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1884e-04\n",
      "Epoch 00919: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.3082e-04 - val_loss: 0.0118\n",
      "Epoch 920/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9259e-04\n",
      "Epoch 00920: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.1463e-04 - val_loss: 0.0119\n",
      "Epoch 921/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1647e-04\n",
      "Epoch 00921: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2851e-04 - val_loss: 0.0118\n",
      "Epoch 922/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9054e-04\n",
      "Epoch 00922: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.1256e-04 - val_loss: 0.0119\n",
      "Epoch 923/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1972e-04\n",
      "Epoch 00923: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3140e-04 - val_loss: 0.0119\n",
      "Epoch 924/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.1629e-04\n",
      "Epoch 00924: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1440e-04 - val_loss: 0.0119\n",
      "Epoch 925/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2431e-04\n",
      "Epoch 00925: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3563e-04 - val_loss: 0.0119\n",
      "Epoch 926/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9311e-04\n",
      "Epoch 00926: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.1795e-04 - val_loss: 0.0119\n",
      "Epoch 927/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.4639e-04\n",
      "Epoch 00927: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.4437e-04 - val_loss: 0.0120\n",
      "Epoch 928/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.2779e-04\n",
      "Epoch 00928: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.2588e-04 - val_loss: 0.0120\n",
      "Epoch 929/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.5657e-04- ETA: 0s - loss: 2.5948e-\n",
      "Epoch 00929: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 3.5455e-04 - val_loss: 0.0120\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.3498e-04- ETA: 0s - loss: 2.2530e-\n",
      "Epoch 00930: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 3.3498e-04 - val_loss: 0.0120\n",
      "Epoch 931/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.6330e-04\n",
      "Epoch 00931: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 3.6330e-04 - val_loss: 0.0120\n",
      "Epoch 932/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.4195e-04\n",
      "Epoch 00932: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.4195e-04 - val_loss: 0.0120\n",
      "Epoch 933/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5626e-04\n",
      "Epoch 00933: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6921e-04 - val_loss: 0.0120\n",
      "Epoch 934/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0707e-04\n",
      "Epoch 00934: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.4777e-04 - val_loss: 0.0121\n",
      "Epoch 935/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 3.8680e-04- ETA: 0s - loss: 1.1842e\n",
      "Epoch 00935: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.7494e-04 - val_loss: 0.0120\n",
      "Epoch 936/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1010e-04\n",
      "Epoch 00936: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.5536e-04 - val_loss: 0.0122\n",
      "Epoch 937/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6411e-04\n",
      "Epoch 00937: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.8439e-04 - val_loss: 0.0120\n",
      "Epoch 938/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1591e-04\n",
      "Epoch 00938: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6603e-04 - val_loss: 0.0123\n",
      "Epoch 939/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7418e-04\n",
      "Epoch 00939: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.9695e-04 - val_loss: 0.0121\n",
      "Epoch 940/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2322e-04\n",
      "Epoch 00940: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.7742e-04 - val_loss: 0.0124\n",
      "Epoch 941/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1007e-04\n",
      "Epoch 00941: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.1007e-04 - val_loss: 0.0121\n",
      "Epoch 942/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.8743e-04\n",
      "Epoch 00942: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.8743e-04 - val_loss: 0.0124\n",
      "Epoch 943/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0047e-04\n",
      "Epoch 00943: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2239e-04 - val_loss: 0.0122\n",
      "Epoch 944/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.3648e-04\n",
      "Epoch 00944: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.9590e-04 - val_loss: 0.0125\n",
      "Epoch 945/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1134e-04\n",
      "Epoch 00945: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3251e-04 - val_loss: 0.0122\n",
      "Epoch 946/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.0310e-04\n",
      "Epoch 00946: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.0169e-04 - val_loss: 0.0125\n",
      "Epoch 947/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.3867e-04\n",
      "Epoch 00947: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.3693e-04 - val_loss: 0.0122\n",
      "Epoch 948/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4160e-04\n",
      "Epoch 00948: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.0239e-04 - val_loss: 0.0126\n",
      "Epoch 949/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.3328e-04\n",
      "Epoch 00949: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.3328e-04 - val_loss: 0.0123\n",
      "Epoch 950/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9738e-04\n",
      "Epoch 00950: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 3.9738e-04 - val_loss: 0.0126\n",
      "Epoch 951/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.2333e-04\n",
      "Epoch 00951: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.2333e-04 - val_loss: 0.0123\n",
      "Epoch 952/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.3664e-04\n",
      "Epoch 00952: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.8899e-04 - val_loss: 0.0127\n",
      "Epoch 953/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1220e-04\n",
      "Epoch 00953: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.1220e-04 - val_loss: 0.0124\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.8296e-04\n",
      "Epoch 00954: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 3.8296e-04 - val_loss: 0.0128\n",
      "Epoch 955/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.0748e-04\n",
      "Epoch 00955: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.0748e-04 - val_loss: 0.0125\n",
      "Epoch 956/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.8911e-04\n",
      "Epoch 00956: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.8911e-04 - val_loss: 0.0128\n",
      "Epoch 957/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1944e-04\n",
      "Epoch 00957: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.1944e-04 - val_loss: 0.0125\n",
      "Epoch 958/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.1727e-04\n",
      "Epoch 00958: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.1727e-04 - val_loss: 0.0129\n",
      "Epoch 959/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.6354e-04\n",
      "Epoch 00959: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.5008e-04 - val_loss: 0.0125\n",
      "Epoch 960/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.5058e-04\n",
      "Epoch 00960: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5058e-04 - val_loss: 0.0130\n",
      "Epoch 961/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2864e-04\n",
      "Epoch 00961: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5832e-04 - val_loss: 0.0125\n",
      "Epoch 962/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9009e-04\n",
      "Epoch 00962: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.3851e-04 - val_loss: 0.0130\n",
      "Epoch 963/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.2587e-04\n",
      "Epoch 00963: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.2587e-04 - val_loss: 0.0127\n",
      "Epoch 964/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4994e-04\n",
      "Epoch 00964: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.9333e-04 - val_loss: 0.0130\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9668e-04\n",
      "Epoch 00965: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9668e-04 - val_loss: 0.0129\n",
      "Epoch 966/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2124e-04\n",
      "Epoch 00966: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.5783e-04 - val_loss: 0.0129\n",
      "Epoch 967/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.8115e-04\n",
      "Epoch 00967: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7953e-04 - val_loss: 0.0131\n",
      "Epoch 968/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0590e-04\n",
      "Epoch 00968: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3967e-04 - val_loss: 0.0128\n",
      "Epoch 969/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.7486e-04\n",
      "Epoch 00969: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.7321e-04 - val_loss: 0.0132\n",
      "Epoch 970/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9992e-04\n",
      "Epoch 00970: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3481e-04 - val_loss: 0.0128\n",
      "Epoch 971/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5466e-04\n",
      "Epoch 00971: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.7256e-04 - val_loss: 0.0134\n",
      "Epoch 972/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9657e-04\n",
      "Epoch 00972: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3294e-04 - val_loss: 0.0128\n",
      "Epoch 973/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5039e-04\n",
      "Epoch 00973: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.6996e-04 - val_loss: 0.0135\n",
      "Epoch 974/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9056e-04\n",
      "Epoch 00974: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.2569e-04 - val_loss: 0.0128\n",
      "Epoch 975/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4438e-04\n",
      "Epoch 00975: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.6398e-04 - val_loss: 0.0135\n",
      "Epoch 976/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.8586e-04\n",
      "Epoch 00976: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1814e-04 - val_loss: 0.0129\n",
      "Epoch 977/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4135e-04\n",
      "Epoch 00977: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6179e-04 - val_loss: 0.0136\n",
      "Epoch 978/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9038e-04\n",
      "Epoch 00978: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2161e-04 - val_loss: 0.0129\n",
      "Epoch 979/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4815e-04\n",
      "Epoch 00979: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7216e-04 - val_loss: 0.0136\n",
      "Epoch 980/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0848e-04\n",
      "Epoch 00980: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.4264e-04 - val_loss: 0.0129\n",
      "Epoch 981/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9925e-04\n",
      "Epoch 00981: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9925e-04 - val_loss: 0.0135\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.7955e-04\n",
      "Epoch 00982: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7955e-04 - val_loss: 0.0130\n",
      "Epoch 983/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0186e-04\n",
      "Epoch 00983: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.4031e-04 - val_loss: 0.0134\n",
      "Epoch 984/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7467e-04\n",
      "Epoch 00984: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.2335e-04 - val_loss: 0.0131\n",
      "Epoch 985/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.7859e-04\n",
      "Epoch 00985: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.8630e-04 - val_loss: 0.0133\n",
      "Epoch 986/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.6649e-04\n",
      "Epoch 00986: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.6404e-04 - val_loss: 0.0133\n",
      "Epoch 987/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6339e-04\n",
      "Epoch 00987: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.2684e-04 - val_loss: 0.0133\n",
      "Epoch 988/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.5259e-04\n",
      "Epoch 00988: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.9236e-04 - val_loss: 0.0134\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.5057e-04\n",
      "Epoch 00989: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.5057e-04 - val_loss: 0.0133\n",
      "Epoch 990/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0966e-04\n",
      "Epoch 00990: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.8924e-04 - val_loss: 0.0133\n",
      "Epoch 991/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.3544e-04\n",
      "Epoch 00991: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.3436e-04 - val_loss: 0.0132\n",
      "Epoch 992/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.1680e-04\n",
      "Epoch 00992: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.3377e-04 - val_loss: 0.0131\n",
      "Epoch 993/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.9103e-04\n",
      "Epoch 00993: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.8953e-04 - val_loss: 0.0130\n",
      "Epoch 994/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2646e-04\n",
      "Epoch 00994: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.7369e-04 - val_loss: 0.0131\n",
      "Epoch 995/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.2524e-04\n",
      "Epoch 00995: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.1930e-04 - val_loss: 0.0131\n",
      "Epoch 996/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.5041e-04\n",
      "Epoch 00996: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.4914e-04 - val_loss: 0.0133\n",
      "Epoch 997/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4763e-04\n",
      "Epoch 00997: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.6796e-04 - val_loss: 0.0132\n",
      "Epoch 998/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.5007e-04\n",
      "Epoch 00998: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.5007e-04 - val_loss: 0.0135\n",
      "Epoch 999/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.5618e-04\n",
      "Epoch 00999: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.5445e-04 - val_loss: 0.0133\n",
      "Epoch 1000/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.5457e-04\n",
      "Epoch 01000: val_loss did not improve from 0.00974\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 3.5285e-04 - val_loss: 0.0137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b4f6648b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "#Adding the first LSTM layer and some Dropout regularisation\n",
    "model_lstm.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "model_lstm.add(LSTM(units = 50, return_sequences = True))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "model_lstm.add(LSTM(units = 50, return_sequences = True))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "model_lstm.add(LSTM(units = 50))\n",
    "\n",
    "# Adding the output layer\n",
    "model_lstm.add(Dense(units = n_steps_out))\n",
    "\n",
    "# Compiling the RNN\n",
    "model_lstm.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "mc = ModelCheckpoint('LSTM_infected_only_GRU_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "#mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model_lstm.fit(X_train, y_train, epochs = 1000, batch_size = 32, validation_data=(X_test, y_test), verbose=1, \n",
    "               shuffle=False, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optimum-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = model_lstm.predict(X_test)\n",
    "y_pred_lstm = sc.inverse_transform(y_pred_lstm) #revert scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atomic-communications",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "integrated-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "incorporated-calcium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 4, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fitting-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshape = sc.inverse_transform(y_test.reshape(len(y_test), 4))\n",
    "#y_test_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "under-carroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(18, 4), dpi=80)\n",
    "\n",
    "plt.plot(y_test_reshape[:,0], label='observed')\n",
    "plt.plot(y_pred_lstm[:,0], label='predicted')\n",
    "plt.title('LSTM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-andrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-egypt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "imperial-playback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Infected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>15997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2021-09-05</td>\n",
       "      <td>12890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>8223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2021-09-07</td>\n",
       "      <td>10586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2021-09-08</td>\n",
       "      <td>12384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>10378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>8869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>8793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>7204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>4161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>6262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>6799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>5692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>5091.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Infected\n",
       "597 2021-09-04   15997.0\n",
       "598 2021-09-05   12890.0\n",
       "599 2021-09-06    8223.0\n",
       "600 2021-09-07   10586.0\n",
       "601 2021-09-08   12384.0\n",
       "602 2021-09-09   10378.0\n",
       "603 2021-09-10    8869.0\n",
       "604 2021-09-11    8793.0\n",
       "605 2021-09-12    7204.0\n",
       "606 2021-09-13    4161.0\n",
       "607 2021-09-14    6262.0\n",
       "608 2021-09-15    6799.0\n",
       "609 2021-09-16    5692.0\n",
       "610 2021-09-17    5091.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-suspension",
   "metadata": {},
   "source": [
    "### Rescaling input before feeding to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "committed-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([8793.0,7204.0,4161.0,6262, 6799, 5692, 5091, 4692, 3395, 2219, 1758, 3229, 3598, 2085])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "seeing-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "#x_input = np.array(df['Infected'][-14:]) # the lastest 14 days\n",
    "x_input = sc.fit_transform(x_input.reshape(len(x_input), 1))\n",
    "x_input = x_input.reshape((1, n_steps_in, 1))\n",
    "print(x_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deluxe-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model_lstm.predict(x_input)\n",
    "y_pred2 = sc.inverse_transform(y_pred2) #revert scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sexual-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "arctic-spokesman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b488295520>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred2[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "racial-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_raw = np.array([8793.0,7204.0,4161.0,6262, 6799, 5692, 5091, 4692, 3395, 2219, 1758, 3229, 3598, 2085])\n",
    "len(x_input_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "crude-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = pd.date_range(start='2021-09-11', end='2021-09-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "failing-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b4f6648640>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_x_input = len(x_input_raw)\n",
    "plt.plot(range(0,len_x_input),x_input_raw)\n",
    "plt.plot(range(len_x_input-1, len_x_input+n_steps_out-1), y_pred2[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fewer-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3048.613 , 2844.3098, 1977.6079, 2460.8892], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_pred2[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-tender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-radar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-bridal",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-master",
   "metadata": {},
   "source": [
    "#### Redo everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "brown-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 2)\n",
      "Date        datetime64[ns]\n",
      "Infected           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Infected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Infected\n",
       "0 2020-01-16       1.0\n",
       "1 2020-01-17       0.0\n",
       "2 2020-01-18       0.0\n",
       "3 2020-01-19       0.0\n",
       "4 2020-01-20       0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../seir/cov_datasets/pcr_positive_daily_Sep18.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "written-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df['Infected'][:500].values.astype(int)\n",
    "test_set = df['Infected'][500:].values.astype(int)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set.reshape(len(training_set), 1))\n",
    "testing_set_scaled = sc.fit_transform(test_set.reshape(len(test_set), 1))\n",
    "\n",
    "\n",
    "# Creating a data structure with 5 time-steps and 2 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "quiet-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n",
      "(111, 1)\n"
     ]
    }
   ],
   "source": [
    "print(training_set_scaled.shape)\n",
    "print(testing_set_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gothic-kernel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "611-594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compatible-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq(sequence, n_steps_in, n_steps_out):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(sequence)):\n",
    "        end_idx = i + n_steps_in\n",
    "        steps_out_idx = end_idx + n_steps_out\n",
    "        \n",
    "        #check if we reach end of arr or not\n",
    "        if (steps_out_idx > len(sequence)):\n",
    "            break\n",
    "        seq_x = sequence[i:end_idx]\n",
    "        seq_y = sequence[end_idx:steps_out_idx]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "reported-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 14\n",
    "n_steps_out = 4\n",
    "\n",
    "X_train , y_train = split_seq(training_set_scaled, n_steps_in, n_steps_out)\n",
    "X_test , y_test = split_seq(testing_set_scaled, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "injured-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 14, 1) (483, 4, 1)\n",
      "(94, 14, 1) (94, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sapphire-foster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train.shape[1],X_train.shape[2])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "appropriate-electronics",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0208  \n",
      "Epoch 00001: val_loss improved from inf to 0.04671, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0208 - val_loss: 0.0467\n",
      "Epoch 2/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0411\n",
      "Epoch 00002: val_loss improved from 0.04671 to 0.03670, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0411 - val_loss: 0.0367\n",
      "Epoch 3/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0134\n",
      "Epoch 00003: val_loss improved from 0.03670 to 0.03386, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0134 - val_loss: 0.0339\n",
      "Epoch 4/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0171\n",
      "Epoch 00004: val_loss improved from 0.03386 to 0.02780, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0199 - val_loss: 0.0278\n",
      "Epoch 5/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0121\n",
      "Epoch 00005: val_loss improved from 0.02780 to 0.02573, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0121 - val_loss: 0.0257\n",
      "Epoch 6/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0094  \n",
      "Epoch 00006: val_loss improved from 0.02573 to 0.02313, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0109 - val_loss: 0.0231\n",
      "Epoch 7/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00007: val_loss did not improve from 0.02313\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0232\n",
      "Epoch 8/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0073   \n",
      "Epoch 00008: val_loss improved from 0.02313 to 0.02101, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.0085 - val_loss: 0.0210\n",
      "Epoch 9/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0075\n",
      "Epoch 00009: val_loss did not improve from 0.02101\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0075 - val_loss: 0.0213\n",
      "Epoch 10/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0075   \n",
      "Epoch 00010: val_loss improved from 0.02101 to 0.01939, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.0075 - val_loss: 0.0194\n",
      "Epoch 11/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0072\n",
      "Epoch 00011: val_loss did not improve from 0.01939\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0197\n",
      "Epoch 12/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0072   \n",
      "Epoch 00012: val_loss improved from 0.01939 to 0.01836, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0072 - val_loss: 0.0184\n",
      "Epoch 13/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0073  \n",
      "Epoch 00013: val_loss improved from 0.01836 to 0.01832, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 14/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0061   \n",
      "Epoch 00014: val_loss improved from 0.01832 to 0.01790, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0073 - val_loss: 0.0179\n",
      "Epoch 15/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0073   \n",
      "Epoch 00015: val_loss improved from 0.01790 to 0.01748, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0073 - val_loss: 0.0175\n",
      "Epoch 16/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0068   \n",
      "Epoch 00016: val_loss did not improve from 0.01748\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0068 - val_loss: 0.0176\n",
      "Epoch 17/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0065   \n",
      "Epoch 00017: val_loss improved from 0.01748 to 0.01662, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0065 - val_loss: 0.0166\n",
      "Epoch 18/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0063   \n",
      "Epoch 00018: val_loss did not improve from 0.01662\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.0167\n",
      "Epoch 19/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0049    \n",
      "Epoch 00019: val_loss improved from 0.01662 to 0.01571, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0060 - val_loss: 0.0157\n",
      "Epoch 20/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0061   \n",
      "Epoch 00020: val_loss did not improve from 0.01571\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0158\n",
      "Epoch 21/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0059   \n",
      "Epoch 00021: val_loss improved from 0.01571 to 0.01497, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0150\n",
      "Epoch 22/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0060   \n",
      "Epoch 00022: val_loss did not improve from 0.01497\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0150\n",
      "Epoch 23/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0059   \n",
      "Epoch 00023: val_loss improved from 0.01497 to 0.01418, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0059 - val_loss: 0.0142\n",
      "Epoch 24/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0061   \n",
      "Epoch 00024: val_loss did not improve from 0.01418\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0145\n",
      "Epoch 25/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00025: val_loss improved from 0.01418 to 0.01367, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0063 - val_loss: 0.0137\n",
      "Epoch 26/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0069   \n",
      "Epoch 00026: val_loss did not improve from 0.01367\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0069 - val_loss: 0.0150\n",
      "Epoch 27/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0054    \n",
      "Epoch 00027: val_loss did not improve from 0.01367\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 28/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0074   \n",
      "Epoch 00028: val_loss did not improve from 0.01367\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.0162\n",
      "Epoch 29/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0067  \n",
      "Epoch 00029: val_loss did not improve from 0.01367\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0067 - val_loss: 0.0139\n",
      "Epoch 30/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0061  \n",
      "Epoch 00030: val_loss did not improve from 0.01367\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0061 - val_loss: 0.0141\n",
      "Epoch 31/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0059   \n",
      "Epoch 00031: val_loss improved from 0.01367 to 0.01269, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 32/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0057   \n",
      "Epoch 00032: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0057 - val_loss: 0.0139\n",
      "Epoch 33/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0059   \n",
      "Epoch 00033: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0059 - val_loss: 0.0129\n",
      "Epoch 34/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0062  \n",
      "Epoch 00034: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0062 - val_loss: 0.0153\n",
      "Epoch 35/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00035: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0144\n",
      "Epoch 36/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0068\n",
      "Epoch 00036: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0068 - val_loss: 0.0167\n",
      "Epoch 37/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0073\n",
      "Epoch 00037: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0142\n",
      "Epoch 38/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0078\n",
      "Epoch 00038: val_loss did not improve from 0.01269\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 39/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00039: val_loss improved from 0.01269 to 0.01253, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0078 - val_loss: 0.0125\n",
      "Epoch 40/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0074  \n",
      "Epoch 00040: val_loss did not improve from 0.01253\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0074 - val_loss: 0.0157\n",
      "Epoch 41/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.006 - ETA: 0s - loss: 0.0078\n",
      "Epoch 00041: val_loss did not improve from 0.01253\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0078 - val_loss: 0.0140\n",
      "Epoch 42/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0054   \n",
      "Epoch 00042: val_loss did not improve from 0.01253\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0157\n",
      "Epoch 43/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00043: val_loss did not improve from 0.01253\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0064 - val_loss: 0.0130\n",
      "Epoch 44/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00044: val_loss did not improve from 0.01253\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0061 - val_loss: 0.0148\n",
      "Epoch 45/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00045: val_loss improved from 0.01253 to 0.01225, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0062 - val_loss: 0.0123\n",
      "Epoch 46/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00046: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0063 - val_loss: 0.0165\n",
      "Epoch 47/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0065\n",
      "Epoch 00047: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0065 - val_loss: 0.0129\n",
      "Epoch 48/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0059\n",
      "Epoch 00048: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0068 - val_loss: 0.0181\n",
      "Epoch 49/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0063- ETA: 0s - loss: 0.006\n",
      "Epoch 00049: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0075 - val_loss: 0.0149\n",
      "Epoch 50/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0087\n",
      "Epoch 00050: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0226\n",
      "Epoch 51/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0092\n",
      "Epoch 00051: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0092 - val_loss: 0.0183\n",
      "Epoch 52/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0102\n",
      "Epoch 00052: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0210\n",
      "Epoch 53/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00053: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0077 - val_loss: 0.0154\n",
      "Epoch 54/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0063\n",
      "Epoch 00054: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0149\n",
      "Epoch 55/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047    \n",
      "Epoch 00055: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0060 - val_loss: 0.0143\n",
      "Epoch 56/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0058   \n",
      "Epoch 00056: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0125\n",
      "Epoch 57/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044   \n",
      "Epoch 00057: val_loss did not improve from 0.01225\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0145\n",
      "Epoch 58/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00058: val_loss improved from 0.01225 to 0.01220, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0061 - val_loss: 0.0122\n",
      "Epoch 59/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00059: val_loss did not improve from 0.01220\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0057 - val_loss: 0.0132\n",
      "Epoch 60/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0060\n",
      "Epoch 00060: val_loss improved from 0.01220 to 0.01192, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0060 - val_loss: 0.0119\n",
      "Epoch 61/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0043   \n",
      "Epoch 00061: val_loss did not improve from 0.01192\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0054 - val_loss: 0.0122\n",
      "Epoch 62/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0046   \n",
      "Epoch 00062: val_loss improved from 0.01192 to 0.01153, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0058 - val_loss: 0.0115\n",
      "Epoch 63/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00063: val_loss did not improve from 0.01153\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0118\n",
      "Epoch 64/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0057  \n",
      "Epoch 00064: val_loss improved from 0.01153 to 0.01144, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0057 - val_loss: 0.0114\n",
      "Epoch 65/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0052   \n",
      "Epoch 00065: val_loss improved from 0.01144 to 0.01133, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0052 - val_loss: 0.0113\n",
      "Epoch 66/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0043   \n",
      "Epoch 00066: val_loss improved from 0.01133 to 0.01091, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0055 - val_loss: 0.0109\n",
      "Epoch 67/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0051    - ETA: 0s - loss: 0.004\n",
      "Epoch 00067: val_loss did not improve from 0.01091\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0051 - val_loss: 0.0111\n",
      "Epoch 68/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039    \n",
      "Epoch 00068: val_loss improved from 0.01091 to 0.01055, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 69/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00069: val_loss improved from 0.01055 to 0.01028, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 70/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0051   \n",
      "Epoch 00070: val_loss improved from 0.01028 to 0.01006, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.0051 - val_loss: 0.0101\n",
      "Epoch 71/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00071: val_loss did not improve from 0.01006\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 72/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00072: val_loss improved from 0.01006 to 0.00913, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0049 - val_loss: 0.0091\n",
      "Epoch 73/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00073: val_loss improved from 0.00913 to 0.00909, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0047 - val_loss: 0.0091\n",
      "Epoch 74/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00074: val_loss did not improve from 0.00909\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0051 - val_loss: 0.0097\n",
      "Epoch 75/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00075: val_loss improved from 0.00909 to 0.00847, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0085\n",
      "Epoch 76/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035    \n",
      "Epoch 00076: val_loss improved from 0.00847 to 0.00781, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 77/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0038   \n",
      "Epoch 00077: val_loss did not improve from 0.00781\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0049 - val_loss: 0.0092\n",
      "Epoch 78/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0049   \n",
      "Epoch 00078: val_loss did not improve from 0.00781\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0087\n",
      "Epoch 79/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00079: val_loss improved from 0.00781 to 0.00708, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 80/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0047   \n",
      "Epoch 00080: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0080\n",
      "Epoch 81/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038    \n",
      "Epoch 00081: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0103\n",
      "Epoch 82/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00082: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 83/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0043   \n",
      "Epoch 00083: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0043 - val_loss: 0.0072\n",
      "Epoch 84/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0047   \n",
      "Epoch 00084: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 85/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00085: val_loss did not improve from 0.00708\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.0086\n",
      "Epoch 86/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031    \n",
      "Epoch 00086: val_loss improved from 0.00708 to 0.00684, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 87/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0041   \n",
      "Epoch 00087: val_loss did not improve from 0.00684\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0075\n",
      "Epoch 88/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00088: val_loss did not improve from 0.00684\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0079\n",
      "Epoch 89/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0033   \n",
      "Epoch 00089: val_loss did not improve from 0.00684\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0043 - val_loss: 0.0084\n",
      "Epoch 90/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0044   \n",
      "Epoch 00090: val_loss improved from 0.00684 to 0.00677, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 91/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00091: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 92/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00092: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 93/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0047   \n",
      "Epoch 00093: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 94/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00094: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 95/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033   \n",
      "Epoch 00095: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 96/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034  \n",
      "Epoch 00096: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0045 - val_loss: 0.0078\n",
      "Epoch 97/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0032   \n",
      "Epoch 00097: val_loss did not improve from 0.00677\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0042 - val_loss: 0.0077\n",
      "Epoch 98/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032    \n",
      "Epoch 00098: val_loss improved from 0.00677 to 0.00651, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 99/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0040   \n",
      "Epoch 00099: val_loss did not improve from 0.00651\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 100/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0040   \n",
      "Epoch 00100: val_loss did not improve from 0.00651\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 101/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00101: val_loss did not improve from 0.00651\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.0038 - val_loss: 0.0075\n",
      "Epoch 102/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0038   \n",
      "Epoch 00102: val_loss improved from 0.00651 to 0.00645, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 103/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0036   \n",
      "Epoch 00103: val_loss did not improve from 0.00645\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 104/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00104: val_loss improved from 0.00645 to 0.00643, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 105/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00105: val_loss did not improve from 0.00643\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 106/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00106: val_loss did not improve from 0.00643\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0065\n",
      "Epoch 107/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00107: val_loss did not improve from 0.00643\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0034 - val_loss: 0.0066\n",
      "Epoch 108/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0034   \n",
      "Epoch 00108: val_loss did not improve from 0.00643\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0065\n",
      "Epoch 109/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00109: val_loss did not improve from 0.00643\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 110/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00110: val_loss improved from 0.00643 to 0.00636, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 111/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00111: val_loss did not improve from 0.00636\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 112/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00112: val_loss improved from 0.00636 to 0.00619, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 113/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0034   \n",
      "Epoch 00113: val_loss did not improve from 0.00619\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0063\n",
      "Epoch 114/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0034   \n",
      "Epoch 00114: val_loss did not improve from 0.00619\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 115/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00115: val_loss did not improve from 0.00619\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 116/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0036   \n",
      "Epoch 00116: val_loss did not improve from 0.00619\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 117/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00117: val_loss did not improve from 0.00619\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 118/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0037   \n",
      "Epoch 00118: val_loss improved from 0.00619 to 0.00606, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 119/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00119: val_loss did not improve from 0.00606\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 120/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00120: val_loss improved from 0.00606 to 0.00595, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 121/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0036   \n",
      "Epoch 00121: val_loss did not improve from 0.00595\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 122/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0033   \n",
      "Epoch 00122: val_loss did not improve from 0.00595\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 123/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00123: val_loss did not improve from 0.00595\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 124/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0032   \n",
      "Epoch 00124: val_loss did not improve from 0.00595\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 125/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00125: val_loss improved from 0.00595 to 0.00581, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 126/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036    \n",
      "Epoch 00126: val_loss did not improve from 0.00581\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0103\n",
      "Epoch 127/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00127: val_loss did not improve from 0.00581\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 128/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00128: val_loss improved from 0.00581 to 0.00505, saving model to GRU_infected_only_GRU_LSTM.h5\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 129/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00129: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0066\n",
      "Epoch 130/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00130: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 131/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00131: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0097\n",
      "Epoch 132/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00132: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0069\n",
      "Epoch 133/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00133: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0084\n",
      "Epoch 134/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00134: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 135/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00135: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 136/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00136: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0086\n",
      "Epoch 137/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00137: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 138/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00138: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 139/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00139: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 140/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00140: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0034 - val_loss: 0.0078\n",
      "Epoch 141/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00141: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 142/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00142: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0115\n",
      "Epoch 143/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0041\n",
      "Epoch 00143: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 144/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0055\n",
      "Epoch 00144: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.0105\n",
      "Epoch 145/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00145: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 146/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0040\n",
      "Epoch 00146: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 147/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033   \n",
      "Epoch 00147: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0040 - val_loss: 0.0103\n",
      "Epoch 148/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0033    - ETA: 0s - loss: 7.3306e-\n",
      "Epoch 00148: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 149/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00149: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.0089\n",
      "Epoch 150/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0035\n",
      "Epoch 00150: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0080\n",
      "Epoch 151/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00151: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 152/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037    \n",
      "Epoch 00152: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0042 - val_loss: 0.0080\n",
      "Epoch 153/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0034    \n",
      "Epoch 00153: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 154/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0033    \n",
      "Epoch 00154: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 155/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00155: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0092\n",
      "Epoch 156/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00156: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 157/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00157: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 158/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00158: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 159/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00159: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 160/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00160: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0075\n",
      "Epoch 161/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030    \n",
      "Epoch 00161: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 162/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00162: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0092\n",
      "Epoch 163/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00163: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0037 - val_loss: 0.0066\n",
      "Epoch 164/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0038\n",
      "Epoch 00164: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0090\n",
      "Epoch 165/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00165: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 166/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00166: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0133\n",
      "Epoch 167/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00167: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0056 - val_loss: 0.0075\n",
      "Epoch 168/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0073\n",
      "Epoch 00168: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 169/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00169: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0091\n",
      "Epoch 170/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00170: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0073\n",
      "Epoch 171/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00171: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0062\n",
      "Epoch 172/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00172: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Epoch 173/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00173: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.0069\n",
      "Epoch 174/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00174: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0061\n",
      "Epoch 175/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00175: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 176/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00176: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0031 - val_loss: 0.0066\n",
      "Epoch 177/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00177: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0111\n",
      "Epoch 178/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0042   \n",
      "Epoch 00178: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 179/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00179: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0064 - val_loss: 0.0118\n",
      "Epoch 180/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00180: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 181/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0054\n",
      "Epoch 00181: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0056 - val_loss: 0.0113\n",
      "Epoch 182/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036\n",
      "Epoch 00182: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0041 - val_loss: 0.0114\n",
      "Epoch 183/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0039\n",
      "Epoch 00183: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0087\n",
      "Epoch 184/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00184: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 185/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00185: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 186/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00186: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 187/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00187: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 188/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00188: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 189/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00189: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 190/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00190: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 191/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00191: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 192/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00192: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0022 - val_loss: 0.0067\n",
      "Epoch 193/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00193: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0059\n",
      "Epoch 194/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029    \n",
      "Epoch 00194: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0032 - val_loss: 0.0092\n",
      "Epoch 195/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0044    \n",
      "Epoch 00195: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0076\n",
      "Epoch 196/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00196: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 197/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00197: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 198/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0093\n",
      "Epoch 00198: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0096 - val_loss: 0.0078\n",
      "Epoch 199/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047    \n",
      "Epoch 00199: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 200/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045    \n",
      "Epoch 00200: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0058 - val_loss: 0.0124\n",
      "Epoch 201/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00201: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0060 - val_loss: 0.0106\n",
      "Epoch 202/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0051    \n",
      "Epoch 00202: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0068 - val_loss: 0.0126\n",
      "Epoch 203/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0045\n",
      "Epoch 00203: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0126\n",
      "Epoch 204/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0047\n",
      "Epoch 00204: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0061 - val_loss: 0.0138\n",
      "Epoch 205/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0043\n",
      "Epoch 00205: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0050 - val_loss: 0.0100\n",
      "Epoch 206/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0036   \n",
      "Epoch 00206: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0108\n",
      "Epoch 207/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0037\n",
      "Epoch 00207: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0042 - val_loss: 0.0098\n",
      "Epoch 208/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0037 \n",
      "Epoch 00208: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.0101\n",
      "Epoch 209/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0034\n",
      "Epoch 00209: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0034 - val_loss: 0.0089\n",
      "Epoch 210/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0024    - ETA: 0s - loss: 0.0030\n",
      "Epoch 00210: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0088\n",
      "Epoch 211/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00211: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0029 - val_loss: 0.0081\n",
      "Epoch 212/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00212: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 213/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0026   \n",
      "Epoch 00213: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 214/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00214: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0074\n",
      "Epoch 215/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00215: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 216/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00216: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0069\n",
      "Epoch 217/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00217: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0069\n",
      "Epoch 218/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00218: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 219/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00219: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 220/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023    \n",
      "Epoch 00220: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 221/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00221: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0073\n",
      "Epoch 222/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00222: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 223/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00223: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0076\n",
      "Epoch 224/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00224: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 225/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00225: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0078\n",
      "Epoch 226/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028    \n",
      "Epoch 00226: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0079\n",
      "Epoch 227/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00227: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0078\n",
      "Epoch 228/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00228: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0079\n",
      "Epoch 229/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00229: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 230/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00230: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 231/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00231: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0078\n",
      "Epoch 232/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00232: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0079\n",
      "Epoch 233/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00233: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 234/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00234: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0080\n",
      "Epoch 235/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00235: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0079\n",
      "Epoch 236/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00236: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0080\n",
      "Epoch 237/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00237: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0080\n",
      "Epoch 238/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00238: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0027 - val_loss: 0.0081\n",
      "Epoch 239/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00239: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0082\n",
      "Epoch 240/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00240: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0082\n",
      "Epoch 241/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00241: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0083\n",
      "Epoch 242/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00242: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0083\n",
      "Epoch 243/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00243: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0084\n",
      "Epoch 244/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025    \n",
      "Epoch 00244: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0082\n",
      "Epoch 245/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00245: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0085\n",
      "Epoch 246/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024    \n",
      "Epoch 00246: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0081\n",
      "Epoch 247/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00247: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0085\n",
      "Epoch 248/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021    \n",
      "Epoch 00248: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0025 - val_loss: 0.0078\n",
      "Epoch 249/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00249: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 250/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00250: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 251/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00251: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0084\n",
      "Epoch 252/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00252: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 253/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00253: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.0085\n",
      "Epoch 254/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00254: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 255/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00255: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0087\n",
      "Epoch 256/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00256: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 257/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022    \n",
      "Epoch 00257: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0089\n",
      "Epoch 258/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00258: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 259/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00259: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 260/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026    \n",
      "Epoch 00260: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0030 - val_loss: 0.0090\n",
      "Epoch 261/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00261: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0094\n",
      "Epoch 262/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0029   \n",
      "Epoch 00262: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0029 - val_loss: 0.0096\n",
      "Epoch 263/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00263: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0093\n",
      "Epoch 264/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0025   \n",
      "Epoch 00264: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0091\n",
      "Epoch 265/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00265: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 266/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0025   \n",
      "Epoch 00266: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0095\n",
      "Epoch 267/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00267: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0022 - val_loss: 0.0096\n",
      "Epoch 268/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00268: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0081\n",
      "Epoch 269/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0023\n",
      "Epoch 00269: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0087\n",
      "Epoch 270/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00270: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0086\n",
      "Epoch 271/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00271: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0089\n",
      "Epoch 272/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00272: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0087\n",
      "Epoch 273/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00273: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0086\n",
      "Epoch 274/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00274: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 275/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0019   \n",
      "Epoch 00275: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0086\n",
      "Epoch 276/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00276: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0087\n",
      "Epoch 277/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00277: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0087\n",
      "Epoch 278/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00278: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 279/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00279: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0088\n",
      "Epoch 280/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00280: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0086\n",
      "Epoch 281/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00281: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0091\n",
      "Epoch 282/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00282: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 283/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00283: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0093\n",
      "Epoch 284/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00284: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0086\n",
      "Epoch 285/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00285: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0092\n",
      "Epoch 286/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00286: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 287/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00287: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0088\n",
      "Epoch 288/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00288: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0089\n",
      "Epoch 289/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00289: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.0091\n",
      "Epoch 290/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0022   \n",
      "Epoch 00290: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 291/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00291: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0101\n",
      "Epoch 292/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0027   \n",
      "Epoch 00292: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0029 - val_loss: 0.0089\n",
      "Epoch 293/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00293: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.0108\n",
      "Epoch 294/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00294: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.0090\n",
      "Epoch 295/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00295: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0100\n",
      "Epoch 296/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031   \n",
      "Epoch 00296: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0031 - val_loss: 0.0092\n",
      "Epoch 297/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0031\n",
      "Epoch 00297: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0112\n",
      "Epoch 298/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024  \n",
      "Epoch 00298: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0026 - val_loss: 0.0088\n",
      "Epoch 299/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0027\n",
      "Epoch 00299: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0083\n",
      "Epoch 300/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00300: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0090\n",
      "Epoch 301/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00301: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0093\n",
      "Epoch 302/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00302: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0089\n",
      "Epoch 303/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00303: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0095\n",
      "Epoch 304/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00304: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 305/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00305: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0094\n",
      "Epoch 306/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00306: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0089\n",
      "Epoch 307/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00307: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0094\n",
      "Epoch 308/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00308: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0089\n",
      "Epoch 309/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00309: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0095\n",
      "Epoch 310/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00310: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0089\n",
      "Epoch 311/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00311: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0095\n",
      "Epoch 312/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00312: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0089\n",
      "Epoch 313/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00313: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0096\n",
      "Epoch 314/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00314: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0087\n",
      "Epoch 315/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00315: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0095\n",
      "Epoch 316/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00316: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 317/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00317: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0095\n",
      "Epoch 318/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00318: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0084\n",
      "Epoch 319/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00319: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 320/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00320: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0078\n",
      "Epoch 321/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00321: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 322/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00322: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 323/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00323: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0017 - val_loss: 0.0091\n",
      "Epoch 324/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00324: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 325/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00325: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0084\n",
      "Epoch 326/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00326: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 327/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00327: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0080\n",
      "Epoch 328/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011    - ETA: 0s - loss: 0.0011\n",
      "Epoch 00328: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 329/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.7257e-04\n",
      "Epoch 00329: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.7257e-04 - val_loss: 0.0080\n",
      "Epoch 330/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00330: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 331/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.1798e-04\n",
      "Epoch 00331: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.1497e-04 - val_loss: 0.0082\n",
      "Epoch 332/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3701e-04\n",
      "Epoch 00332: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 333/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0689e-04\n",
      "Epoch 00333: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8389e-04 - val_loss: 0.0083\n",
      "Epoch 334/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0085e-04\n",
      "Epoch 00334: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0086\n",
      "Epoch 335/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3113e-04\n",
      "Epoch 00335: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5681e-04 - val_loss: 0.0084\n",
      "Epoch 336/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00336: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0088\n",
      "Epoch 337/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00337: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 338/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00338: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0090\n",
      "Epoch 339/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00339: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0096\n",
      "Epoch 340/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00340: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0100\n",
      "Epoch 341/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00341: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0102\n",
      "Epoch 342/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00342: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0105\n",
      "Epoch 343/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00343: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0109\n",
      "Epoch 344/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00344: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0113\n",
      "Epoch 345/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00345: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0099\n",
      "Epoch 346/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0030\n",
      "Epoch 00346: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0090\n",
      "Epoch 347/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018    \n",
      "Epoch 00347: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0101\n",
      "Epoch 348/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00348: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0019 - val_loss: 0.0087\n",
      "Epoch 349/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00349: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0084\n",
      "Epoch 350/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00350: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0085\n",
      "Epoch 351/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1638e-04\n",
      "Epoch 00351: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0082\n",
      "Epoch 352/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1658e-04\n",
      "Epoch 00352: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3279e-04 - val_loss: 0.0086\n",
      "Epoch 353/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0780e-04\n",
      "Epoch 00353: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.1597e-04 - val_loss: 0.0078\n",
      "Epoch 354/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6093e-04\n",
      "Epoch 00354: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0090\n",
      "Epoch 355/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.1979e-04\n",
      "Epoch 00355: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.1979e-04 - val_loss: 0.0079\n",
      "Epoch 356/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00356: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0094\n",
      "Epoch 357/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00357: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0081\n",
      "Epoch 358/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00358: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0095\n",
      "Epoch 359/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6199e-04\n",
      "Epoch 00359: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.6690e-04 - val_loss: 0.0083\n",
      "Epoch 360/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00360: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 361/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5078e-04\n",
      "Epoch 00361: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.5489e-04 - val_loss: 0.0084\n",
      "Epoch 362/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00362: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0090\n",
      "Epoch 363/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00363: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0084\n",
      "Epoch 364/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015   \n",
      "Epoch 00364: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0091\n",
      "Epoch 365/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00365: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0090\n",
      "Epoch 366/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00366: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.0105\n",
      "Epoch 367/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020    \n",
      "Epoch 00367: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0101\n",
      "Epoch 368/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00368: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0106\n",
      "Epoch 369/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0025 \n",
      "Epoch 00369: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0106\n",
      "Epoch 370/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0026\n",
      "Epoch 00370: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0099\n",
      "Epoch 371/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00371: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0109\n",
      "Epoch 372/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00372: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0090\n",
      "Epoch 373/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00373: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0097\n",
      "Epoch 374/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00374: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0019 - val_loss: 0.0108\n",
      "Epoch 375/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00375: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0092\n",
      "Epoch 376/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00376: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0093\n",
      "Epoch 377/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00377: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 378/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00378: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0097\n",
      "Epoch 379/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00379: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 380/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00380: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0014 - val_loss: 0.0097\n",
      "Epoch 381/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00381: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 382/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00382: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0014 - val_loss: 0.0096\n",
      "Epoch 383/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00383: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 384/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00384: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0092\n",
      "Epoch 385/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8187e-04\n",
      "Epoch 00385: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3893e-04 - val_loss: 0.0089\n",
      "Epoch 386/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3452e-04\n",
      "Epoch 00386: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 387/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.5179e-04\n",
      "Epoch 00387: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.5179e-04 - val_loss: 0.0088\n",
      "Epoch 388/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.0263e-04\n",
      "Epoch 00388: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.9877e-04 - val_loss: 0.0082\n",
      "Epoch 389/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.9236e-04\n",
      "Epoch 00389: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.8806e-04 - val_loss: 0.0091\n",
      "Epoch 390/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2633e-04\n",
      "Epoch 00390: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.1701e-04 - val_loss: 0.0082\n",
      "Epoch 391/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00391: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0096\n",
      "Epoch 392/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3713e-04\n",
      "Epoch 00392: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0085\n",
      "Epoch 393/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00393: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0102\n",
      "Epoch 394/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00394: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0088\n",
      "Epoch 395/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00395: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0018 - val_loss: 0.0102\n",
      "Epoch 396/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00396: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0090\n",
      "Epoch 397/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00397: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0090\n",
      "Epoch 398/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00398: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 399/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00399: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0097\n",
      "Epoch 400/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00400: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0017 - val_loss: 0.0104\n",
      "Epoch 401/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00401: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.0118\n",
      "Epoch 402/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018\n",
      "Epoch 00402: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0020 - val_loss: 0.0097\n",
      "Epoch 403/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00403: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0028 - val_loss: 0.0107\n",
      "Epoch 404/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00404: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0105\n",
      "Epoch 405/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00405: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0080\n",
      "Epoch 406/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0626e-04\n",
      "Epoch 00406: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.4924e-04 - val_loss: 0.0095\n",
      "Epoch 407/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4100e-04\n",
      "Epoch 00407: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.7878e-04 - val_loss: 0.0087\n",
      "Epoch 408/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8182e-04\n",
      "Epoch 00408: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.3645e-04 - val_loss: 0.0085\n",
      "Epoch 409/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00409: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 410/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00410: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 411/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00411: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0103\n",
      "Epoch 412/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00412: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0096\n",
      "Epoch 413/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00413: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0102\n",
      "Epoch 414/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00414: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0094\n",
      "Epoch 415/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00415: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 416/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016   \n",
      "Epoch 00416: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0104\n",
      "Epoch 417/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00417: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0096\n",
      "Epoch 418/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00418: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0098\n",
      "Epoch 419/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00419: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0105\n",
      "Epoch 420/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00420: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 421/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00421: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0092\n",
      "Epoch 422/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00422: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 423/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00423: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0090\n",
      "Epoch 424/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0942e-04\n",
      "Epoch 00424: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8913e-04 - val_loss: 0.0088\n",
      "Epoch 425/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.4746e-04\n",
      "Epoch 00425: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0092\n",
      "Epoch 426/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6507e-04\n",
      "Epoch 00426: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.7480e-04 - val_loss: 0.0088\n",
      "Epoch 427/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9787e-04\n",
      "Epoch 00427: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 428/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5435e-04\n",
      "Epoch 00428: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.7847e-04 - val_loss: 0.0090\n",
      "Epoch 429/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00429: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 430/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6289e-04\n",
      "Epoch 00430: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 431/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00431: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0102\n",
      "Epoch 432/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00432: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 433/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00433: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0101\n",
      "Epoch 434/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00434: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 435/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00435: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0100\n",
      "Epoch 436/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00436: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0096\n",
      "Epoch 437/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00437: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0098\n",
      "Epoch 438/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00438: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0096\n",
      "Epoch 439/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00439: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0094\n",
      "Epoch 440/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00440: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0094\n",
      "Epoch 441/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00441: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0093\n",
      "Epoch 442/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00442: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0092\n",
      "Epoch 443/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00443: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0094\n",
      "Epoch 444/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00444: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0088\n",
      "Epoch 445/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00445: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0095\n",
      "Epoch 446/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8951e-04\n",
      "Epoch 00446: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0086\n",
      "Epoch 447/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00447: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 448/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00448: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0085\n",
      "Epoch 449/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00449: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 450/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00450: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 451/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0016\n",
      "Epoch 00451: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0016 - val_loss: 0.0104\n",
      "Epoch 452/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017   \n",
      "Epoch 00452: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0089\n",
      "Epoch 453/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00453: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0021 - val_loss: 0.0100\n",
      "Epoch 454/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0025  \n",
      "Epoch 00454: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.0098\n",
      "Epoch 455/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 00455: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.0102\n",
      "Epoch 456/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00456: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0026 - val_loss: 0.0102\n",
      "Epoch 457/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025\n",
      "Epoch 00457: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0025 - val_loss: 0.0118\n",
      "Epoch 458/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0025  \n",
      "Epoch 00458: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0122\n",
      "Epoch 459/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0029\n",
      "Epoch 00459: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0108\n",
      "Epoch 460/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00460: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0101\n",
      "Epoch 461/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00461: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0121\n",
      "Epoch 462/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00462: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0091\n",
      "Epoch 463/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00463: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0088\n",
      "Epoch 464/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8762e-04\n",
      "Epoch 00464: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.9356e-04 - val_loss: 0.0091\n",
      "Epoch 465/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8203e-04\n",
      "Epoch 00465: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.4702e-04 - val_loss: 0.0090\n",
      "Epoch 466/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1418e-04\n",
      "Epoch 00466: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.4268e-04 - val_loss: 0.0094\n",
      "Epoch 467/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7076e-04\n",
      "Epoch 00467: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0099\n",
      "Epoch 468/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4487e-04\n",
      "Epoch 00468: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.3440e-04 - val_loss: 0.0094\n",
      "Epoch 469/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00469: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 470/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.8541e-04\n",
      "Epoch 00470: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.8309e-04 - val_loss: 0.0090\n",
      "Epoch 471/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00471: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 472/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.1611e-04\n",
      "Epoch 00472: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.9609e-04 - val_loss: 0.0091\n",
      "Epoch 473/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00473: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 474/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.9201e-04\n",
      "Epoch 00474: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.5816e-04 - val_loss: 0.0092\n",
      "Epoch 475/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00475: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0091\n",
      "Epoch 476/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5040e-04\n",
      "Epoch 00476: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.9984e-04 - val_loss: 0.0091\n",
      "Epoch 477/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6797e-04\n",
      "Epoch 00477: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.5896e-04 - val_loss: 0.0092\n",
      "Epoch 478/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1031e-04\n",
      "Epoch 00478: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.5038e-04 - val_loss: 0.0091\n",
      "Epoch 479/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6281e-04\n",
      "Epoch 00479: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.4138e-04 - val_loss: 0.0094\n",
      "Epoch 480/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3012e-04\n",
      "Epoch 00480: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.6297e-04 - val_loss: 0.0091\n",
      "Epoch 481/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00481: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.8793e-04 - val_loss: 0.0096\n",
      "Epoch 482/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0758e-04\n",
      "Epoch 00482: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.4025e-04 - val_loss: 0.0092\n",
      "Epoch 483/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00483: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 484/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00484: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0091\n",
      "Epoch 485/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00485: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 486/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00486: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 487/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00487: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0101\n",
      "Epoch 488/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00488: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 489/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00489: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 490/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00490: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 491/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00491: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 492/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00492: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 493/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00493: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 494/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00494: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 495/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00495: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 496/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00496: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 497/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00497: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 498/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00498: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 499/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00499: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 500/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00500: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0099\n",
      "Epoch 501/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00501: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 502/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00502: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 503/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00503: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 504/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2324e-0 - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00504: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0095\n",
      "Epoch 505/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00505: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 506/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6969e-04\n",
      "Epoch 00506: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0097\n",
      "Epoch 507/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00507: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 508/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5332e-04\n",
      "Epoch 00508: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0095\n",
      "Epoch 509/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9516e-04\n",
      "Epoch 00509: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0099\n",
      "Epoch 510/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4015e-04\n",
      "Epoch 00510: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.1895e-04 - val_loss: 0.0093\n",
      "Epoch 511/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0431e-04\n",
      "Epoch 00511: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.8309e-04 - val_loss: 0.0091\n",
      "Epoch 512/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1162e-04\n",
      "Epoch 00512: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.9631e-04 - val_loss: 0.0092\n",
      "Epoch 513/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.8450e-04\n",
      "Epoch 00513: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.4149e-04 - val_loss: 0.0087\n",
      "Epoch 514/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5176e-04\n",
      "Epoch 00514: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.2712e-04 - val_loss: 0.0092\n",
      "Epoch 515/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7421e-04\n",
      "Epoch 00515: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.6498e-04 - val_loss: 0.0087\n",
      "Epoch 516/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.8233e-04\n",
      "Epoch 00516: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.8233e-04 - val_loss: 0.0092\n",
      "Epoch 517/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9045e-04\n",
      "Epoch 00517: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6923e-04 - val_loss: 0.0087\n",
      "Epoch 518/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8147e-04\n",
      "Epoch 00518: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.0122e-04 - val_loss: 0.0096\n",
      "Epoch 519/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3291e-04\n",
      "Epoch 00519: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.3953e-04 - val_loss: 0.0088\n",
      "Epoch 520/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9700e-04\n",
      "Epoch 00520: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0100\n",
      "Epoch 521/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2532e-04\n",
      "Epoch 00521: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 522/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00522: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0097\n",
      "Epoch 523/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00523: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 524/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00524: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0013 - val_loss: 0.0094\n",
      "Epoch 525/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00525: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 526/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00526: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0101\n",
      "Epoch 527/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00527: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0104\n",
      "Epoch 528/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00528: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0015 - val_loss: 0.0098\n",
      "Epoch 529/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00529: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 530/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00530: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 531/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00531: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 532/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00532: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0100\n",
      "Epoch 533/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2093e-04\n",
      "Epoch 00533: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.7798e-04 - val_loss: 0.0091\n",
      "Epoch 534/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8616e-04\n",
      "Epoch 00534: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.6820e-04 - val_loss: 0.0102\n",
      "Epoch 535/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4847e-04\n",
      "Epoch 00535: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.7423e-04 - val_loss: 0.0092\n",
      "Epoch 536/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00536: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0093\n",
      "Epoch 537/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6399e-04\n",
      "Epoch 00537: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.2998e-04 - val_loss: 0.0092\n",
      "Epoch 538/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6042e-04\n",
      "Epoch 00538: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.5953e-04 - val_loss: 0.0097\n",
      "Epoch 539/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7583e-04\n",
      "Epoch 00539: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.2045e-04 - val_loss: 0.0095\n",
      "Epoch 540/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00540: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0101\n",
      "Epoch 541/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00541: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 542/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00542: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 543/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00543: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0096\n",
      "Epoch 544/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00544: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 545/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00545: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 546/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00546: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 547/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00547: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 548/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00548: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0107\n",
      "Epoch 549/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00549: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 550/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00550: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0088\n",
      "Epoch 551/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3774e-04\n",
      "Epoch 00551: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 552/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00552: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 553/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5121e-04\n",
      "Epoch 00553: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0101\n",
      "Epoch 554/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.8781e-04\n",
      "Epoch 00554: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.8781e-04 - val_loss: 0.0091\n",
      "Epoch 555/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3470e-04\n",
      "Epoch 00555: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.0131e-04 - val_loss: 0.0094\n",
      "Epoch 556/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3337e-04\n",
      "Epoch 00556: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.8058e-04 - val_loss: 0.0095\n",
      "Epoch 557/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.8304e-04\n",
      "Epoch 00557: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6816e-04 - val_loss: 0.0092\n",
      "Epoch 558/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5586e-04\n",
      "Epoch 00558: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0225e-04 - val_loss: 0.0094\n",
      "Epoch 559/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.8026e-04\n",
      "Epoch 00559: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.8026e-04 - val_loss: 0.0090\n",
      "Epoch 560/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1507e-04\n",
      "Epoch 00560: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.6306e-04 - val_loss: 0.0088\n",
      "Epoch 561/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9912e-04\n",
      "Epoch 00561: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4980e-04 - val_loss: 0.0091\n",
      "Epoch 562/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0502e-04\n",
      "Epoch 00562: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.4065e-04 - val_loss: 0.0091\n",
      "Epoch 563/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.7312e-04\n",
      "Epoch 00563: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2554e-04 - val_loss: 0.0091\n",
      "Epoch 564/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2121e-04\n",
      "Epoch 00564: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.2297e-04 - val_loss: 0.0095\n",
      "Epoch 565/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9535e-04\n",
      "Epoch 00565: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8.3358e-04 - val_loss: 0.0091\n",
      "Epoch 566/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00566: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.9700e-04 - val_loss: 0.0099\n",
      "Epoch 567/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5033e-04\n",
      "Epoch 00567: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.8892e-04 - val_loss: 0.0092\n",
      "Epoch 568/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00568: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 569/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00569: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 570/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00570: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 571/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.6505e-04\n",
      "Epoch 00571: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0091\n",
      "Epoch 572/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00572: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0099\n",
      "Epoch 573/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00573: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 574/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00574: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 575/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00575: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 576/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00576: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 577/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00577: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 578/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00578: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 579/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00579: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 580/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014\n",
      "Epoch 00580: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0103\n",
      "Epoch 581/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00581: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 582/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00582: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 583/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00583: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0101\n",
      "Epoch 584/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00584: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 585/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00585: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 586/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00586: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 587/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.1790e-04\n",
      "Epoch 00587: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0106\n",
      "Epoch 588/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00588: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 589/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6464e-04\n",
      "Epoch 00589: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.3778e-04 - val_loss: 0.0093\n",
      "Epoch 590/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00590: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0107\n",
      "Epoch 591/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6353e-04\n",
      "Epoch 00591: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1738e-04 - val_loss: 0.0093\n",
      "Epoch 592/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5251e-04\n",
      "Epoch 00592: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0081\n",
      "Epoch 593/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3489e-04\n",
      "Epoch 00593: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7.1424e-04 - val_loss: 0.0092\n",
      "Epoch 594/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.0813e-04\n",
      "Epoch 00594: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.4420e-04 - val_loss: 0.0085\n",
      "Epoch 595/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2509e-04\n",
      "Epoch 00595: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.7434e-04 - val_loss: 0.0090\n",
      "Epoch 596/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8875e-04\n",
      "Epoch 00596: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.1028e-04 - val_loss: 0.0091\n",
      "Epoch 597/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1122e-04\n",
      "Epoch 00597: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.6637e-04 - val_loss: 0.0092\n",
      "Epoch 598/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6872e-04\n",
      "Epoch 00598: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8200e-04 - val_loss: 0.0091\n",
      "Epoch 599/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6843e-04\n",
      "Epoch 00599: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1034e-04 - val_loss: 0.0090\n",
      "Epoch 600/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1597e-04\n",
      "Epoch 00600: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3816e-04 - val_loss: 0.0088\n",
      "Epoch 601/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3489e-04\n",
      "Epoch 00601: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.7532e-04 - val_loss: 0.0090\n",
      "Epoch 602/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4996e-04\n",
      "Epoch 00602: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.8383e-04 - val_loss: 0.0086\n",
      "Epoch 603/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1787e-04\n",
      "Epoch 00603: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.5320e-04 - val_loss: 0.0090\n",
      "Epoch 604/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0003e-04\n",
      "Epoch 00604: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3560e-04 - val_loss: 0.0086\n",
      "Epoch 605/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3028e-04\n",
      "Epoch 00605: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.5812e-04 - val_loss: 0.0091\n",
      "Epoch 606/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.9903e-04\n",
      "Epoch 00606: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3601e-04 - val_loss: 0.0087\n",
      "Epoch 607/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8205e-04\n",
      "Epoch 00607: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1353e-04 - val_loss: 0.0092\n",
      "Epoch 608/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3893e-04\n",
      "Epoch 00608: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9428e-04 - val_loss: 0.0088\n",
      "Epoch 609/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5835e-04\n",
      "Epoch 00609: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.0220e-04 - val_loss: 0.0094\n",
      "Epoch 610/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7730e-04\n",
      "Epoch 00610: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.5357e-04 - val_loss: 0.0088\n",
      "Epoch 611/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1218e-04\n",
      "Epoch 00611: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.4376e-04 - val_loss: 0.0095\n",
      "Epoch 612/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1254e-04\n",
      "Epoch 00612: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6780e-04 - val_loss: 0.0087\n",
      "Epoch 613/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6693e-04\n",
      "Epoch 00613: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.7222e-04 - val_loss: 0.0095\n",
      "Epoch 614/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9707e-04\n",
      "Epoch 00614: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6.3414e-04 - val_loss: 0.0088\n",
      "Epoch 615/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7267e-04\n",
      "Epoch 00615: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.6440e-04 - val_loss: 0.0093\n",
      "Epoch 616/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5591e-04\n",
      "Epoch 00616: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.8415e-04 - val_loss: 0.0093\n",
      "Epoch 617/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00617: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.8648e-04 - val_loss: 0.0099\n",
      "Epoch 618/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00618: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 619/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00619: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0015 - val_loss: 0.0109\n",
      "Epoch 620/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014   \n",
      "Epoch 00620: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0105\n",
      "Epoch 621/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00621: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0020 - val_loss: 0.0116\n",
      "Epoch 622/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00622: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0103\n",
      "Epoch 623/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0028\n",
      "Epoch 00623: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 624/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00624: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0103\n",
      "Epoch 625/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00625: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0015 - val_loss: 0.0103\n",
      "Epoch 626/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2298e-0 - ETA: 0s - loss: 9.6704e-04\n",
      "Epoch 00626: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0092\n",
      "Epoch 627/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00627: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0014 - val_loss: 0.0067\n",
      "Epoch 628/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012   \n",
      "Epoch 00628: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 629/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00629: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0094\n",
      "Epoch 630/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00630: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0093\n",
      "Epoch 631/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.9849e-04\n",
      "Epoch 00631: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0098\n",
      "Epoch 632/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00632: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0085\n",
      "Epoch 633/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00633: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0107\n",
      "Epoch 634/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00634: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0014 - val_loss: 0.0099\n",
      "Epoch 635/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5110e-04\n",
      "Epoch 00635: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0114\n",
      "Epoch 636/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00636: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 637/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2649e-04\n",
      "Epoch 00637: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.8767e-04 - val_loss: 0.0097\n",
      "Epoch 638/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.6179e-04\n",
      "Epoch 00638: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.6075e-04 - val_loss: 0.0087\n",
      "Epoch 639/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.7118e-04- ETA: 0s - loss: 5.0342e\n",
      "Epoch 00639: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 7.6887e-04 - val_loss: 0.0098\n",
      "Epoch 640/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.1146e-04\n",
      "Epoch 00640: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.8612e-04 - val_loss: 0.0100\n",
      "Epoch 641/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.8055e-04\n",
      "Epoch 00641: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.7717e-04 - val_loss: 0.0096\n",
      "Epoch 642/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.7574e-04\n",
      "Epoch 00642: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 8.7574e-04 - val_loss: 0.0091\n",
      "Epoch 643/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.9438e-04\n",
      "Epoch 00643: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.9438e-04 - val_loss: 0.0094\n",
      "Epoch 644/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.1710e-04\n",
      "Epoch 00644: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.1351e-04 - val_loss: 0.0091\n",
      "Epoch 645/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.0150e-04\n",
      "Epoch 00645: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.0150e-04 - val_loss: 0.0092\n",
      "Epoch 646/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.6392e-04\n",
      "Epoch 00646: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 6.4173e-04 - val_loss: 0.0092\n",
      "Epoch 647/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.5460e-04\n",
      "Epoch 00647: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 5.5460e-04 - val_loss: 0.0092\n",
      "Epoch 648/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.9849e-04\n",
      "Epoch 00648: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 5.9849e-04 - val_loss: 0.0092\n",
      "Epoch 649/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0779e-04\n",
      "Epoch 00649: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 5.1939e-04 - val_loss: 0.0092\n",
      "Epoch 650/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.6657e-04\n",
      "Epoch 00650: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.6383e-04 - val_loss: 0.0092\n",
      "Epoch 651/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.9142e-04\n",
      "Epoch 00651: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.9142e-04 - val_loss: 0.0092\n",
      "Epoch 652/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.4129e-04\n",
      "Epoch 00652: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.3868e-04 - val_loss: 0.0092\n",
      "Epoch 653/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6019e-04\n",
      "Epoch 00653: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.7160e-04 - val_loss: 0.0092\n",
      "Epoch 654/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2333e-04\n",
      "Epoch 00654: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.2287e-04 - val_loss: 0.0092\n",
      "Epoch 655/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.5914e-04\n",
      "Epoch 00655: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.5914e-04 - val_loss: 0.0092\n",
      "Epoch 656/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1517e-04\n",
      "Epoch 00656: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1458e-04 - val_loss: 0.0092\n",
      "Epoch 657/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4224e-04\n",
      "Epoch 00657: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5283e-04 - val_loss: 0.0092\n",
      "Epoch 658/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1308e-04\n",
      "Epoch 00658: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1220e-04 - val_loss: 0.0092\n",
      "Epoch 659/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4054e-04\n",
      "Epoch 00659: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.5114e-04 - val_loss: 0.0093\n",
      "Epoch 660/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1470e-04\n",
      "Epoch 00660: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1362e-04 - val_loss: 0.0093\n",
      "Epoch 661/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4078e-04\n",
      "Epoch 00661: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5175e-04 - val_loss: 0.0093\n",
      "Epoch 662/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1634e-04\n",
      "Epoch 00662: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1550e-04 - val_loss: 0.0093\n",
      "Epoch 663/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.5312e-04\n",
      "Epoch 00663: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.5111e-04 - val_loss: 0.0093\n",
      "Epoch 664/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1229e-04\n",
      "Epoch 00664: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1269e-04 - val_loss: 0.0093\n",
      "Epoch 665/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3119e-04\n",
      "Epoch 00665: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.4445e-04 - val_loss: 0.0094\n",
      "Epoch 666/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.9859e-04- ETA: 0s - loss: 4.9518e-0\n",
      "Epoch 00666: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 4.9859e-04 - val_loss: 0.0093\n",
      "Epoch 667/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.4046e-04\n",
      "Epoch 00667: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.2830e-04 - val_loss: 0.0093\n",
      "Epoch 668/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.7083e-04\n",
      "Epoch 00668: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.6917e-04 - val_loss: 0.0092\n",
      "Epoch 669/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.1051e-04\n",
      "Epoch 00669: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 4.0912e-04 - val_loss: 0.0093\n",
      "Epoch 670/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.3711e-04\n",
      "Epoch 00670: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 4.3562e-04 - val_loss: 0.0091\n",
      "Epoch 671/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.2076e-04\n",
      "Epoch 00671: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.2076e-04 - val_loss: 0.0092\n",
      "Epoch 672/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.4259e-04\n",
      "Epoch 00672: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.4706e-04 - val_loss: 0.0090\n",
      "Epoch 673/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.2679e-04\n",
      "Epoch 00673: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.2467e-04 - val_loss: 0.0093\n",
      "Epoch 674/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.7619e-04\n",
      "Epoch 00674: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 5.7619e-04 - val_loss: 0.0092\n",
      "Epoch 675/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8893e-04\n",
      "Epoch 00675: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 7.2527e-04 - val_loss: 0.0096\n",
      "Epoch 676/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.7324e-04\n",
      "Epoch 00676: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.7324e-04 - val_loss: 0.0094\n",
      "Epoch 677/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.0107e-04\n",
      "Epoch 00677: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.2748e-04 - val_loss: 0.0096\n",
      "Epoch 678/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.1252e-04\n",
      "Epoch 00678: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.6665e-04 - val_loss: 0.0098\n",
      "Epoch 679/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2627e-04\n",
      "Epoch 00679: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.4292e-04 - val_loss: 0.0093\n",
      "Epoch 680/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.5820e-04\n",
      "Epoch 00680: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.5820e-04 - val_loss: 0.0099\n",
      "Epoch 681/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 9.7111e-04\n",
      "Epoch 00681: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.6686e-04 - val_loss: 0.0101\n",
      "Epoch 682/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 9.5523e-04\n",
      "Epoch 00682: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9.2399e-04 - val_loss: 0.0099\n",
      "Epoch 683/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00683: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0011 - val_loss: 0.0094\n",
      "Epoch 684/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.1327e-04\n",
      "Epoch 00684: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.1856e-04 - val_loss: 0.0091\n",
      "Epoch 685/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00685: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0103\n",
      "Epoch 686/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0709e-04\n",
      "Epoch 00686: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.2590e-04 - val_loss: 0.0093\n",
      "Epoch 687/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 7.0248e-04\n",
      "Epoch 00687: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 7.0764e-04 - val_loss: 0.0093\n",
      "Epoch 688/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.9660e-04\n",
      "Epoch 00688: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.9813e-04 - val_loss: 0.0093\n",
      "Epoch 689/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.1280e-04\n",
      "Epoch 00689: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.1248e-04 - val_loss: 0.0087\n",
      "Epoch 690/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 6.5728e-04\n",
      "Epoch 00690: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 6.6330e-04 - val_loss: 0.0093\n",
      "Epoch 691/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3239e-04\n",
      "Epoch 00691: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.3840e-04 - val_loss: 0.0101\n",
      "Epoch 692/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013    \n",
      "Epoch 00692: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0015 - val_loss: 0.0110\n",
      "Epoch 693/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0021\n",
      "Epoch 00693: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0114\n",
      "Epoch 694/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0024   \n",
      "Epoch 00694: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0128\n",
      "Epoch 695/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0032\n",
      "Epoch 00695: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0032 - val_loss: 0.0115\n",
      "Epoch 696/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0018   \n",
      "Epoch 00696: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0018 - val_loss: 0.0096\n",
      "Epoch 697/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.4731e-04\n",
      "Epoch 00697: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0079\n",
      "Epoch 698/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.2676e-04\n",
      "Epoch 00698: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.2676e-04 - val_loss: 0.0089\n",
      "Epoch 699/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6039e-04\n",
      "Epoch 00699: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.1489e-04 - val_loss: 0.0081\n",
      "Epoch 700/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2069e-04\n",
      "Epoch 00700: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7122e-04 - val_loss: 0.0086\n",
      "Epoch 701/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2747e-04\n",
      "Epoch 00701: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.6370e-04 - val_loss: 0.0086\n",
      "Epoch 702/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.6377e-04- ETA: 0s - loss: 9.0843e\n",
      "Epoch 00702: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.5417e-04 - val_loss: 0.0086\n",
      "Epoch 703/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.7336e-04\n",
      "Epoch 00703: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.7336e-04 - val_loss: 0.0087\n",
      "Epoch 704/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.0476e-04\n",
      "Epoch 00704: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 7.0476e-04 - val_loss: 0.0095\n",
      "Epoch 705/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.2005e-04\n",
      "Epoch 00705: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 8.2005e-04 - val_loss: 0.0100\n",
      "Epoch 706/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0011   \n",
      "Epoch 00706: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0011 - val_loss: 0.0099\n",
      "Epoch 707/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7682e-04\n",
      "Epoch 00707: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0111\n",
      "Epoch 708/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00708: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0012 - val_loss: 0.0084\n",
      "Epoch 709/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.2851e-04\n",
      "Epoch 00709: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.2851e-04 - val_loss: 0.0097\n",
      "Epoch 710/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012    \n",
      "Epoch 00710: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 711/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4276e-04\n",
      "Epoch 00711: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.9103e-04 - val_loss: 0.0112\n",
      "Epoch 712/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00712: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 713/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3962e-04\n",
      "Epoch 00713: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2356e-04 - val_loss: 0.0092\n",
      "Epoch 714/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0847e-04\n",
      "Epoch 00714: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.9026e-04 - val_loss: 0.0094\n",
      "Epoch 715/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6288e-04\n",
      "Epoch 00715: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6642e-04 - val_loss: 0.0094\n",
      "Epoch 716/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5304e-04\n",
      "Epoch 00716: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6915e-04 - val_loss: 0.0087\n",
      "Epoch 717/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.3469e-04\n",
      "Epoch 00717: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.4307e-04 - val_loss: 0.0090\n",
      "Epoch 718/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6929e-04\n",
      "Epoch 00718: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.7255e-04 - val_loss: 0.0089\n",
      "Epoch 719/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1835e-04\n",
      "Epoch 00719: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.2427e-04 - val_loss: 0.0090\n",
      "Epoch 720/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6595e-04\n",
      "Epoch 00720: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.6791e-04 - val_loss: 0.0090\n",
      "Epoch 721/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.1585e-04\n",
      "Epoch 00721: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.2024e-04 - val_loss: 0.0090\n",
      "Epoch 722/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.4906e-04\n",
      "Epoch 00722: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.5381e-04 - val_loss: 0.0090\n",
      "Epoch 723/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0961e-04\n",
      "Epoch 00723: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1558e-04 - val_loss: 0.0090\n",
      "Epoch 724/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2914e-04\n",
      "Epoch 00724: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3.3729e-04 - val_loss: 0.0089\n",
      "Epoch 725/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0983e-04\n",
      "Epoch 00725: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.1932e-04 - val_loss: 0.0090\n",
      "Epoch 726/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2421e-04\n",
      "Epoch 00726: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3672e-04 - val_loss: 0.0089\n",
      "Epoch 727/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.2317e-04\n",
      "Epoch 00727: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.3892e-04 - val_loss: 0.0090\n",
      "Epoch 728/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.6358e-04\n",
      "Epoch 00728: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.6167e-04 - val_loss: 0.0089\n",
      "Epoch 729/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5105e-04\n",
      "Epoch 00729: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.7895e-04 - val_loss: 0.0090\n",
      "Epoch 730/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.7485e-04\n",
      "Epoch 00730: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.1187e-04 - val_loss: 0.0089\n",
      "Epoch 731/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8695e-04\n",
      "Epoch 00731: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.3462e-04 - val_loss: 0.0090\n",
      "Epoch 732/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.0944e-04\n",
      "Epoch 00732: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.6842e-04 - val_loss: 0.0089\n",
      "Epoch 733/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.1373e-04\n",
      "Epoch 00733: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.7945e-04 - val_loss: 0.0091\n",
      "Epoch 734/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3394e-04\n",
      "Epoch 00734: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0611e-04 - val_loss: 0.0089\n",
      "Epoch 735/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2705e-04\n",
      "Epoch 00735: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9637e-04 - val_loss: 0.0093\n",
      "Epoch 736/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6375e-04\n",
      "Epoch 00736: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3230e-04 - val_loss: 0.0089\n",
      "Epoch 737/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.0207e-04\n",
      "Epoch 00737: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0207e-04 - val_loss: 0.0095\n",
      "Epoch 738/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9460e-04\n",
      "Epoch 00738: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5138e-04 - val_loss: 0.0090\n",
      "Epoch 739/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3909e-04\n",
      "Epoch 00739: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9697e-04 - val_loss: 0.0096\n",
      "Epoch 740/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1228e-04\n",
      "Epoch 00740: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.5471e-04 - val_loss: 0.0091\n",
      "Epoch 741/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3877e-04\n",
      "Epoch 00741: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8732e-04 - val_loss: 0.0097\n",
      "Epoch 742/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5025e-04\n",
      "Epoch 00742: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.8039e-04 - val_loss: 0.0092\n",
      "Epoch 743/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.1858e-04\n",
      "Epoch 00743: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.1858e-04 - val_loss: 0.0098\n",
      "Epoch 744/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.8539e-04\n",
      "Epoch 00744: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.8539e-04 - val_loss: 0.0094\n",
      "Epoch 745/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4983e-0 - ETA: 0s - loss: 5.8572e-04\n",
      "Epoch 00745: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.2870e-04 - val_loss: 0.0100\n",
      "Epoch 746/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7016e-04\n",
      "Epoch 00746: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.7747e-04 - val_loss: 0.0095\n",
      "Epoch 747/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.0861e-04\n",
      "Epoch 00747: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8.0861e-04 - val_loss: 0.0102\n",
      "Epoch 748/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00748: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 749/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.8641e-04\n",
      "Epoch 00749: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0010 - val_loss: 0.0103\n",
      "Epoch 750/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00750: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0093\n",
      "Epoch 751/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00751: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0099\n",
      "Epoch 752/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00752: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0101\n",
      "Epoch 753/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.7337e-04\n",
      "Epoch 00753: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.1886e-04 - val_loss: 0.0101\n",
      "Epoch 754/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2454e-04\n",
      "Epoch 00754: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.3287e-04 - val_loss: 0.0088\n",
      "Epoch 755/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5397e-04\n",
      "Epoch 00755: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9278e-04 - val_loss: 0.0087\n",
      "Epoch 756/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4310e-04\n",
      "Epoch 00756: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6544e-04 - val_loss: 0.0087\n",
      "Epoch 757/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9026e-04\n",
      "Epoch 00757: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.1918e-04 - val_loss: 0.0095\n",
      "Epoch 758/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4764e-04\n",
      "Epoch 00758: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0411e-04 - val_loss: 0.0087\n",
      "Epoch 759/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.9653e-04\n",
      "Epoch 00759: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.9393e-04 - val_loss: 0.0103\n",
      "Epoch 760/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 7.2370e-04\n",
      "Epoch 00760: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.2074e-04 - val_loss: 0.0092\n",
      "Epoch 761/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011\n",
      "Epoch 00761: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0010 - val_loss: 0.0094\n",
      "Epoch 762/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0010    \n",
      "Epoch 00762: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0010 - val_loss: 0.0097\n",
      "Epoch 763/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0013\n",
      "Epoch 00763: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0012 - val_loss: 0.0100\n",
      "Epoch 764/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0013   \n",
      "Epoch 00764: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0013 - val_loss: 0.0102\n",
      "Epoch 765/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0019\n",
      "Epoch 00765: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0018 - val_loss: 0.0100\n",
      "Epoch 766/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015    \n",
      "Epoch 00766: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0016 - val_loss: 0.0108\n",
      "Epoch 767/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017\n",
      "Epoch 00767: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0106\n",
      "Epoch 768/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00768: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0013 - val_loss: 0.0128\n",
      "Epoch 769/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0020\n",
      "Epoch 00769: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0111\n",
      "Epoch 770/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0020   \n",
      "Epoch 00770: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0106\n",
      "Epoch 771/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0022\n",
      "Epoch 00771: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0112\n",
      "Epoch 772/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0014    \n",
      "Epoch 00772: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0016 - val_loss: 0.0123\n",
      "Epoch 773/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0015\n",
      "Epoch 00773: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0016 - val_loss: 0.0095\n",
      "Epoch 774/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2755e-04\n",
      "Epoch 00774: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.0213e-04 - val_loss: 0.0092\n",
      "Epoch 775/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8472e-04\n",
      "Epoch 00775: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.6846e-04 - val_loss: 0.0084\n",
      "Epoch 776/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.7939e-04\n",
      "Epoch 00776: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.7939e-04 - val_loss: 0.0099\n",
      "Epoch 777/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6290e-04\n",
      "Epoch 00777: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.9160e-04 - val_loss: 0.0098\n",
      "Epoch 778/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.7849e-04\n",
      "Epoch 00778: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0110\n",
      "Epoch 779/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.2790e-04\n",
      "Epoch 00779: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.2790e-04 - val_loss: 0.0100\n",
      "Epoch 780/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00780: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 781/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4916e-04\n",
      "Epoch 00781: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.7386e-04 - val_loss: 0.0092\n",
      "Epoch 782/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3948e-04\n",
      "Epoch 00782: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.2041e-04 - val_loss: 0.0099\n",
      "Epoch 783/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0447e-04\n",
      "Epoch 00783: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.6279e-04 - val_loss: 0.0099\n",
      "Epoch 784/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.0661e-04\n",
      "Epoch 00784: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.6297e-04 - val_loss: 0.0096\n",
      "Epoch 785/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1834e-04\n",
      "Epoch 00785: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.1864e-04 - val_loss: 0.0095\n",
      "Epoch 786/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4278e-04\n",
      "Epoch 00786: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.1814e-04 - val_loss: 0.0092\n",
      "Epoch 787/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2474e-04\n",
      "Epoch 00787: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.4111e-04 - val_loss: 0.0096\n",
      "Epoch 788/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6955e-04\n",
      "Epoch 00788: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6099e-04 - val_loss: 0.0091\n",
      "Epoch 789/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0413e-04\n",
      "Epoch 00789: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.2788e-04 - val_loss: 0.0096\n",
      "Epoch 790/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6499e-04\n",
      "Epoch 00790: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5883e-04 - val_loss: 0.0092\n",
      "Epoch 791/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0890e-04\n",
      "Epoch 00791: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.3450e-04 - val_loss: 0.0097\n",
      "Epoch 792/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7195e-04\n",
      "Epoch 00792: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6741e-04 - val_loss: 0.0092\n",
      "Epoch 793/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1390e-04\n",
      "Epoch 00793: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.4062e-04 - val_loss: 0.0097\n",
      "Epoch 794/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7512e-04\n",
      "Epoch 00794: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7179e-04 - val_loss: 0.0093\n",
      "Epoch 795/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1398e-04\n",
      "Epoch 00795: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4066e-04 - val_loss: 0.0096\n",
      "Epoch 796/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7288e-04\n",
      "Epoch 00796: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.6906e-04 - val_loss: 0.0093\n",
      "Epoch 797/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0780e-04\n",
      "Epoch 00797: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3184e-04 - val_loss: 0.0096\n",
      "Epoch 798/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6529e-04\n",
      "Epoch 00798: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.5911e-04 - val_loss: 0.0093\n",
      "Epoch 799/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9658e-04\n",
      "Epoch 00799: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1594e-04 - val_loss: 0.0096\n",
      "Epoch 800/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5461e-04\n",
      "Epoch 00800: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4525e-04 - val_loss: 0.0093\n",
      "Epoch 801/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8509e-04\n",
      "Epoch 00801: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9966e-04 - val_loss: 0.0096\n",
      "Epoch 802/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.5438e-04\n",
      "Epoch 00802: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 5.3405e-04 - val_loss: 0.0093\n",
      "Epoch 803/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7931e-04\n",
      "Epoch 00803: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 4.9048e-04 - val_loss: 0.0096\n",
      "Epoch 804/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.3179e-04\n",
      "Epoch 00804: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.3179e-04 - val_loss: 0.0094\n",
      "Epoch 805/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.9390e-04\n",
      "Epoch 00805: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 4.9390e-04 - val_loss: 0.0096\n",
      "Epoch 806/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6005e-04\n",
      "Epoch 00806: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 5.4313e-04 - val_loss: 0.0094\n",
      "Epoch 807/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.3489e-04\n",
      "Epoch 00807: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 5.1421e-04 - val_loss: 0.0096\n",
      "Epoch 808/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.9773e-04\n",
      "Epoch 00808: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.7199e-04 - val_loss: 0.0094\n",
      "Epoch 809/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 5.5874e-04\n",
      "Epoch 00809: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.5614e-04 - val_loss: 0.0097\n",
      "Epoch 810/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.2521e-04\n",
      "Epoch 00810: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.2235e-04 - val_loss: 0.0095\n",
      "Epoch 811/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.2780e-04\n",
      "Epoch 00811: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.2503e-04 - val_loss: 0.0097\n",
      "Epoch 812/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.9681e-04\n",
      "Epoch 00812: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.9681e-04 - val_loss: 0.0096\n",
      "Epoch 813/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9131e-04\n",
      "Epoch 00813: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.2239e-04 - val_loss: 0.0098\n",
      "Epoch 814/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.9029e-04\n",
      "Epoch 00814: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7.9029e-04 - val_loss: 0.0097\n",
      "Epoch 815/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 8.3280e-04\n",
      "Epoch 00815: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.3280e-04 - val_loss: 0.0098\n",
      "Epoch 816/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0209e-04\n",
      "Epoch 00816: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7836e-04 - val_loss: 0.0098\n",
      "Epoch 817/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5402e-04\n",
      "Epoch 00817: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1273e-04 - val_loss: 0.0098\n",
      "Epoch 818/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.3695e-04\n",
      "Epoch 00818: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.1906e-04 - val_loss: 0.0098\n",
      "Epoch 819/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6124e-04\n",
      "Epoch 00819: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2581e-04 - val_loss: 0.0097\n",
      "Epoch 820/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0968e-04\n",
      "Epoch 00820: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.9918e-04 - val_loss: 0.0098\n",
      "Epoch 821/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3516e-04\n",
      "Epoch 00821: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0596e-04 - val_loss: 0.0098\n",
      "Epoch 822/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7996e-04\n",
      "Epoch 00822: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.7991e-04 - val_loss: 0.0098\n",
      "Epoch 823/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.5056e-04\n",
      "Epoch 00823: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3730e-04 - val_loss: 0.0100\n",
      "Epoch 824/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7856e-04\n",
      "Epoch 00824: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9.0168e-04 - val_loss: 0.0095\n",
      "Epoch 825/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.4778e-04\n",
      "Epoch 00825: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.7504e-04 - val_loss: 0.0104\n",
      "Epoch 826/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.2514e-04\n",
      "Epoch 00826: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6376e-04 - val_loss: 0.0096\n",
      "Epoch 827/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3406e-04\n",
      "Epoch 00827: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.5239e-04 - val_loss: 0.0104\n",
      "Epoch 828/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3491e-04\n",
      "Epoch 00828: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.5421e-04 - val_loss: 0.0094\n",
      "Epoch 829/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1380e-04\n",
      "Epoch 00829: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8353e-04 - val_loss: 0.0100\n",
      "Epoch 830/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9775e-04\n",
      "Epoch 00830: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.2068e-04 - val_loss: 0.0090\n",
      "Epoch 831/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3480e-04\n",
      "Epoch 00831: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9176e-04 - val_loss: 0.0100\n",
      "Epoch 832/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7013e-04\n",
      "Epoch 00832: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7247e-04 - val_loss: 0.0094\n",
      "Epoch 833/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.9699e-04\n",
      "Epoch 00833: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4070e-04 - val_loss: 0.0099\n",
      "Epoch 834/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4379e-04\n",
      "Epoch 00834: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.4338e-04 - val_loss: 0.0094\n",
      "Epoch 835/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.1181e-04\n",
      "Epoch 00835: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1181e-04 - val_loss: 0.0098\n",
      "Epoch 836/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2298e-04\n",
      "Epoch 00836: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2186e-04 - val_loss: 0.0094\n",
      "Epoch 837/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6441e-04\n",
      "Epoch 00837: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9233e-04 - val_loss: 0.0098\n",
      "Epoch 838/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0752e-04\n",
      "Epoch 00838: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0539e-04 - val_loss: 0.0094\n",
      "Epoch 839/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5345e-04\n",
      "Epoch 00839: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8074e-04 - val_loss: 0.0098\n",
      "Epoch 840/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0470e-04\n",
      "Epoch 00840: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0091e-04 - val_loss: 0.0095\n",
      "Epoch 841/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5632e-04\n",
      "Epoch 00841: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.8218e-04 - val_loss: 0.0099\n",
      "Epoch 842/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1971e-04\n",
      "Epoch 00842: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1182e-04 - val_loss: 0.0096\n",
      "Epoch 843/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6895e-04\n",
      "Epoch 00843: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.9329e-04 - val_loss: 0.0099\n",
      "Epoch 844/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.3068e-04\n",
      "Epoch 00844: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.3068e-04 - val_loss: 0.0096\n",
      "Epoch 845/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.0986e-04\n",
      "Epoch 00845: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.0986e-04 - val_loss: 0.0099\n",
      "Epoch 846/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6812e-04\n",
      "Epoch 00846: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5259e-04 - val_loss: 0.0097\n",
      "Epoch 847/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0325e-04\n",
      "Epoch 00847: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.2445e-04 - val_loss: 0.0099\n",
      "Epoch 848/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.6561e-04\n",
      "Epoch 00848: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6561e-04 - val_loss: 0.0098\n",
      "Epoch 849/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1096e-04\n",
      "Epoch 00849: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.3103e-04 - val_loss: 0.0099\n",
      "Epoch 850/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8452e-04\n",
      "Epoch 00850: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6824e-04 - val_loss: 0.0098\n",
      "Epoch 851/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.1403e-04\n",
      "Epoch 00851: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3395e-04 - val_loss: 0.0099\n",
      "Epoch 852/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8099e-04\n",
      "Epoch 00852: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5.6870e-04 - val_loss: 0.0098\n",
      "Epoch 853/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2762e-04\n",
      "Epoch 00853: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.4999e-04 - val_loss: 0.0098\n",
      "Epoch 854/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8542e-04\n",
      "Epoch 00854: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8111e-04 - val_loss: 0.0096\n",
      "Epoch 855/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4736e-04\n",
      "Epoch 00855: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.7935e-04 - val_loss: 0.0098\n",
      "Epoch 856/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8579e-04\n",
      "Epoch 00856: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9106e-04 - val_loss: 0.0096\n",
      "Epoch 857/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7421e-04\n",
      "Epoch 00857: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.2009e-04 - val_loss: 0.0101\n",
      "Epoch 858/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4581e-04\n",
      "Epoch 00858: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4584e-04 - val_loss: 0.0100\n",
      "Epoch 859/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4638e-04\n",
      "Epoch 00859: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8689e-04 - val_loss: 0.0099\n",
      "Epoch 860/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2909e-04\n",
      "Epoch 00860: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.3195e-04 - val_loss: 0.0097\n",
      "Epoch 861/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0239e-04\n",
      "Epoch 00861: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.7676e-04 - val_loss: 0.0104\n",
      "Epoch 862/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.3994e-04\n",
      "Epoch 00862: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.4035e-04 - val_loss: 0.0110\n",
      "Epoch 863/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6725e-04\n",
      "Epoch 00863: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.3319e-04 - val_loss: 0.0097\n",
      "Epoch 864/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.2670e-04\n",
      "Epoch 00864: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.7833e-04 - val_loss: 0.0083\n",
      "Epoch 865/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.4125e-04\n",
      "Epoch 00865: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.2384e-04 - val_loss: 0.0112\n",
      "Epoch 866/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6043e-04\n",
      "Epoch 00866: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9.5702e-04 - val_loss: 0.0099\n",
      "Epoch 867/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.7271e-04\n",
      "Epoch 00867: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.5423e-04 - val_loss: 0.0112\n",
      "Epoch 868/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5230e-04\n",
      "Epoch 00868: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6588e-04 - val_loss: 0.0100\n",
      "Epoch 869/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0140e-04\n",
      "Epoch 00869: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.4692e-04 - val_loss: 0.0096\n",
      "Epoch 870/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4856e-04\n",
      "Epoch 00870: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9231e-04 - val_loss: 0.0087\n",
      "Epoch 871/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4933e-04\n",
      "Epoch 00871: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.8684e-04 - val_loss: 0.0097\n",
      "Epoch 872/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.2901e-04\n",
      "Epoch 00872: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.5357e-04 - val_loss: 0.0093\n",
      "Epoch 873/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 4.6440e-04\n",
      "Epoch 00873: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.6322e-04 - val_loss: 0.0099\n",
      "Epoch 874/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.1732e-04\n",
      "Epoch 00874: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.1732e-04 - val_loss: 0.0098\n",
      "Epoch 875/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0295e-04\n",
      "Epoch 00875: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3472e-04 - val_loss: 0.0100\n",
      "Epoch 876/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.7839e-04\n",
      "Epoch 00876: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.7178e-04 - val_loss: 0.0096\n",
      "Epoch 877/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6485e-04\n",
      "Epoch 00877: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0285e-04 - val_loss: 0.0098\n",
      "Epoch 878/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5468e-04\n",
      "Epoch 00878: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5851e-04 - val_loss: 0.0097\n",
      "Epoch 879/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9984e-04\n",
      "Epoch 00879: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.5824e-04 - val_loss: 0.0100\n",
      "Epoch 880/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.9568e-04\n",
      "Epoch 00880: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4042e-04 - val_loss: 0.0091\n",
      "Epoch 881/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2720e-04\n",
      "Epoch 00881: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0964e-04 - val_loss: 0.0102\n",
      "Epoch 882/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8908e-04\n",
      "Epoch 00882: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9184e-04 - val_loss: 0.0100\n",
      "Epoch 883/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.0050e-04\n",
      "Epoch 00883: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.3736e-04 - val_loss: 0.0100\n",
      "Epoch 884/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 5.6966e-04\n",
      "Epoch 00884: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5.6285e-04 - val_loss: 0.0096\n",
      "Epoch 885/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.8446e-04\n",
      "Epoch 00885: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.1241e-04 - val_loss: 0.0101\n",
      "Epoch 886/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6931e-04\n",
      "Epoch 00886: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.5902e-04 - val_loss: 0.0097\n",
      "Epoch 887/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.3309e-04\n",
      "Epoch 00887: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.5029e-04 - val_loss: 0.0100\n",
      "Epoch 888/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.2091e-04\n",
      "Epoch 00888: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.8536e-04 - val_loss: 0.0098\n",
      "Epoch 889/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.4159e-04\n",
      "Epoch 00889: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.7666e-04 - val_loss: 0.0104\n",
      "Epoch 890/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.3139e-04\n",
      "Epoch 00890: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.4254e-04 - val_loss: 0.0097\n",
      "Epoch 891/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.2448e-04\n",
      "Epoch 00891: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0289e-04 - val_loss: 0.0102\n",
      "Epoch 892/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.8519e-04\n",
      "Epoch 00892: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.6895e-04 - val_loss: 0.0102\n",
      "Epoch 893/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.5254e-04\n",
      "Epoch 00893: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.1518e-04 - val_loss: 0.0107\n",
      "Epoch 894/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.7368e-04\n",
      "Epoch 00894: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0530e-04 - val_loss: 0.0095\n",
      "Epoch 895/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2747e-04\n",
      "Epoch 00895: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.0634e-04 - val_loss: 0.0102\n",
      "Epoch 896/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.1834e-04\n",
      "Epoch 00896: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.4144e-04 - val_loss: 0.0098\n",
      "Epoch 897/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.4775e-04\n",
      "Epoch 00897: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.9780e-04 - val_loss: 0.0102\n",
      "Epoch 898/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5409e-04\n",
      "Epoch 00898: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8780e-04 - val_loss: 0.0086\n",
      "Epoch 899/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.2974e-04\n",
      "Epoch 00899: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.8417e-04 - val_loss: 0.0097\n",
      "Epoch 900/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.9911e-04\n",
      "Epoch 00900: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.2667e-04 - val_loss: 0.0100\n",
      "Epoch 901/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.5720e-04\n",
      "Epoch 00901: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.0511e-04 - val_loss: 0.0114\n",
      "Epoch 902/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.0646e-04\n",
      "Epoch 00902: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.1725e-04 - val_loss: 0.0101\n",
      "Epoch 903/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.6965e-04\n",
      "Epoch 00903: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8.0260e-04 - val_loss: 0.0109\n",
      "Epoch 904/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5529e-04\n",
      "Epoch 00904: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9.2592e-04 - val_loss: 0.0101\n",
      "Epoch 905/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 6.5824e-04\n",
      "Epoch 00905: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.5597e-04 - val_loss: 0.0106\n",
      "Epoch 906/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6475e-04\n",
      "Epoch 00906: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6.0580e-04 - val_loss: 0.0085\n",
      "Epoch 907/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.5835e-04\n",
      "Epoch 00907: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5.0804e-04 - val_loss: 0.0099\n",
      "Epoch 908/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.6365e-04\n",
      "Epoch 00908: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.0242e-04 - val_loss: 0.0097\n",
      "Epoch 909/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 4.0472e-0 - ETA: 0s - loss: 4.4779e-04\n",
      "Epoch 00909: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 5.0210e-04 - val_loss: 0.0110\n",
      "Epoch 910/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.4730e-04- ETA: 0s - loss: 2.5763e\n",
      "Epoch 00910: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 4.8496e-04 - val_loss: 0.0101\n",
      "Epoch 911/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.9685e-04\n",
      "Epoch 00911: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 3.9631e-04 - val_loss: 0.0101\n",
      "Epoch 912/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3148e-04\n",
      "Epoch 00912: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.3125e-04 - val_loss: 0.0100\n",
      "Epoch 913/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.8815e-04\n",
      "Epoch 00913: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4.0685e-04 - val_loss: 0.0098\n",
      "Epoch 914/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.3149e-04\n",
      "Epoch 00914: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3.4983e-04 - val_loss: 0.0095\n",
      "Epoch 915/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.7728e-04\n",
      "Epoch 00915: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2.8629e-04 - val_loss: 0.0098\n",
      "Epoch 916/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 3.0153e-04\n",
      "Epoch 00916: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 2.8981e-04 - val_loss: 0.0097\n",
      "Epoch 917/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.7194e-04\n",
      "Epoch 00917: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.7194e-04 - val_loss: 0.0097\n",
      "Epoch 918/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.0122e-04\n",
      "Epoch 00918: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 3.0122e-04 - val_loss: 0.0097\n",
      "Epoch 919/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8586e-04\n",
      "Epoch 00919: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.8586e-04 - val_loss: 0.0098\n",
      "Epoch 920/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.3127e-04\n",
      "Epoch 00920: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 3.3127e-04 - val_loss: 0.0097\n",
      "Epoch 921/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 3.3435e-04\n",
      "Epoch 00921: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.2366e-04 - val_loss: 0.0098\n",
      "Epoch 922/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.9721e-04\n",
      "Epoch 00922: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.9721e-04 - val_loss: 0.0097\n",
      "Epoch 923/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.9960e-04\n",
      "Epoch 00923: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 3.9802e-04 - val_loss: 0.0100\n",
      "Epoch 924/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.0142e-04\n",
      "Epoch 00924: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5.0142e-04 - val_loss: 0.0098\n",
      "Epoch 925/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.1985e-04\n",
      "Epoch 00925: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 5.1985e-04 - val_loss: 0.0101\n",
      "Epoch 926/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.5213e-04\n",
      "Epoch 00926: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 6.5213e-04 - val_loss: 0.0099\n",
      "Epoch 927/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0562e-04\n",
      "Epoch 00927: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 6.9745e-04 - val_loss: 0.0101\n",
      "Epoch 928/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 8.8591e-04\n",
      "Epoch 00928: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.8142e-04 - val_loss: 0.0100\n",
      "Epoch 929/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.1163e-04\n",
      "Epoch 00929: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 9.1598e-04 - val_loss: 0.0101\n",
      "Epoch 930/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.9532e-04\n",
      "Epoch 00930: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 9.9532e-04 - val_loss: 0.0103\n",
      "Epoch 931/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.9435e-04\n",
      "Epoch 00931: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8.4095e-04 - val_loss: 0.0104\n",
      "Epoch 932/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 8.3716e-04\n",
      "Epoch 00932: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 8.0721e-04 - val_loss: 0.0100\n",
      "Epoch 933/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.2253e-04\n",
      "Epoch 00933: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.2253e-04 - val_loss: 0.0097\n",
      "Epoch 934/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.2525e-04\n",
      "Epoch 00934: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6.2525e-04 - val_loss: 0.0099\n",
      "Epoch 935/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.5385e-04\n",
      "Epoch 00935: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.5385e-04 - val_loss: 0.0114\n",
      "Epoch 936/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.3188e-04\n",
      "Epoch 00936: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.5633e-04 - val_loss: 0.0101\n",
      "Epoch 937/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.8501e-04\n",
      "Epoch 00937: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.4764e-04 - val_loss: 0.0103\n",
      "Epoch 938/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.1236e-04\n",
      "Epoch 00938: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.1393e-04 - val_loss: 0.0099\n",
      "Epoch 939/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6589e-04\n",
      "Epoch 00939: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.3491e-04 - val_loss: 0.0099\n",
      "Epoch 940/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.6894e-04\n",
      "Epoch 00940: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.1257e-04 - val_loss: 0.0084\n",
      "Epoch 941/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.6117e-04\n",
      "Epoch 00941: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6.3316e-04 - val_loss: 0.0102\n",
      "Epoch 942/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 7.0370e-04\n",
      "Epoch 00942: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.2169e-04 - val_loss: 0.0100\n",
      "Epoch 943/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.6062e-04\n",
      "Epoch 00943: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6062e-04 - val_loss: 0.0097\n",
      "Epoch 944/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.7470e-04\n",
      "Epoch 00944: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.9586e-04 - val_loss: 0.0089\n",
      "Epoch 945/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.5480e-04\n",
      "Epoch 00945: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.6111e-04 - val_loss: 0.0097\n",
      "Epoch 946/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 3.0640e-04\n",
      "Epoch 00946: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 3.0490e-04 - val_loss: 0.0096\n",
      "Epoch 947/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.8063e-04\n",
      "Epoch 00947: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.8230e-04 - val_loss: 0.0095\n",
      "Epoch 948/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9750e-04\n",
      "Epoch 00948: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.1314e-04 - val_loss: 0.0099\n",
      "Epoch 949/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.6176e-04\n",
      "Epoch 00949: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7529e-04 - val_loss: 0.0096\n",
      "Epoch 950/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 4.3804e-04\n",
      "Epoch 00950: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4.7264e-04 - val_loss: 0.0103\n",
      "Epoch 951/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 5.5391e-04\n",
      "Epoch 00951: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5.6858e-04 - val_loss: 0.0098\n",
      "Epoch 952/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 6.8355e-04\n",
      "Epoch 00952: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 7.3387e-04 - val_loss: 0.0107\n",
      "Epoch 953/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 8.6629e-04\n",
      "Epoch 00953: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8.5413e-04 - val_loss: 0.0101\n",
      "Epoch 954/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0010   \n",
      "Epoch 00954: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0010 - val_loss: 0.0106\n",
      "Epoch 955/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00955: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0099\n",
      "Epoch 956/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00956: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0111\n",
      "Epoch 957/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0012\n",
      "Epoch 00957: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0012 - val_loss: 0.0102\n",
      "Epoch 958/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 9.5819e-04\n",
      "Epoch 00958: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0011 - val_loss: 0.0104\n",
      "Epoch 959/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0016    \n",
      "Epoch 00959: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 960/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0017    \n",
      "Epoch 00960: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0119\n",
      "Epoch 961/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00961: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.0123\n",
      "Epoch 962/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 0.0027    \n",
      "Epoch 00962: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0028 - val_loss: 0.0123\n",
      "Epoch 963/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 0.0023   \n",
      "Epoch 00963: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.0023 - val_loss: 0.0124\n",
      "Epoch 964/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.0011    \n",
      "Epoch 00964: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.0013 - val_loss: 0.0141\n",
      "Epoch 965/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 9.0565e-04\n",
      "Epoch 00965: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9.0565e-04 - val_loss: 0.0104\n",
      "Epoch 966/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.1467e-04\n",
      "Epoch 00966: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.1467e-04 - val_loss: 0.0104\n",
      "Epoch 967/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 6.2642e-04\n",
      "Epoch 00967: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 6.2642e-04 - val_loss: 0.0097\n",
      "Epoch 968/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 4.0734e-04\n",
      "Epoch 00968: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4.0734e-04 - val_loss: 0.0101\n",
      "Epoch 969/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.7602e-04\n",
      "Epoch 00969: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.7602e-04 - val_loss: 0.0095\n",
      "Epoch 970/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 3.0541e-04\n",
      "Epoch 00970: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.1026e-04 - val_loss: 0.0099\n",
      "Epoch 971/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 3.2118e-04\n",
      "Epoch 00971: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3.1436e-04 - val_loss: 0.0095\n",
      "Epoch 972/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.8092e-04\n",
      "Epoch 00972: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.8472e-04 - val_loss: 0.0099\n",
      "Epoch 973/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.9669e-04\n",
      "Epoch 00973: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.9544e-04 - val_loss: 0.0096\n",
      "Epoch 974/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.6669e-04\n",
      "Epoch 00974: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.7008e-04 - val_loss: 0.0099\n",
      "Epoch 975/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.7989e-04\n",
      "Epoch 00975: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.7935e-04 - val_loss: 0.0096\n",
      "Epoch 976/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.5256e-04\n",
      "Epoch 00976: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.5597e-04 - val_loss: 0.0099\n",
      "Epoch 977/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.6346e-04\n",
      "Epoch 00977: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.6306e-04 - val_loss: 0.0096\n",
      "Epoch 978/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.3929e-04\n",
      "Epoch 00978: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.4224e-04 - val_loss: 0.0099\n",
      "Epoch 979/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.4872e-04\n",
      "Epoch 00979: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.4804e-04 - val_loss: 0.0096\n",
      "Epoch 980/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.2816e-04\n",
      "Epoch 00980: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.3034e-04 - val_loss: 0.0099\n",
      "Epoch 981/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 2.3674e-04\n",
      "Epoch 00981: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.3548e-04 - val_loss: 0.0097\n",
      "Epoch 982/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2074e-04\n",
      "Epoch 00982: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.2074e-04 - val_loss: 0.0098\n",
      "Epoch 983/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.2668e-04\n",
      "Epoch 00983: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.2546e-04 - val_loss: 0.0097\n",
      "Epoch 984/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1325e-04\n",
      "Epoch 00984: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.1325e-04 - val_loss: 0.0098\n",
      "Epoch 985/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1769e-04\n",
      "Epoch 00985: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.1769e-04 - val_loss: 0.0097\n",
      "Epoch 986/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 2.0642e-04\n",
      "Epoch 00986: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.0750e-04 - val_loss: 0.0098\n",
      "Epoch 987/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.1190e-04\n",
      "Epoch 00987: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.1190e-04 - val_loss: 0.0097\n",
      "Epoch 988/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0320e-04\n",
      "Epoch 00988: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2.0320e-04 - val_loss: 0.0098\n",
      "Epoch 989/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0791e-04\n",
      "Epoch 00989: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 2.0791e-04 - val_loss: 0.0097\n",
      "Epoch 990/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0014e-04\n",
      "Epoch 00990: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 2.0014e-04 - val_loss: 0.0098\n",
      "Epoch 991/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 2.1611e-04\n",
      "Epoch 00991: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.0564e-04 - val_loss: 0.0097\n",
      "Epoch 992/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 1.9604e-04\n",
      "Epoch 00992: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1.9832e-04 - val_loss: 0.0098\n",
      "Epoch 993/1000\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 2.1502e-04\n",
      "Epoch 00993: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.0509e-04 - val_loss: 0.0097\n",
      "Epoch 994/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 1.9898e-04\n",
      "Epoch 00994: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.9788e-04 - val_loss: 0.0098\n",
      "Epoch 995/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0639e-04\n",
      "Epoch 00995: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.0639e-04 - val_loss: 0.0096\n",
      "Epoch 996/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.9907e-04\n",
      "Epoch 00996: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1.9907e-04 - val_loss: 0.0098\n",
      "Epoch 997/1000\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0979e-04\n",
      "Epoch 00997: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.0979e-04 - val_loss: 0.0096\n",
      "Epoch 998/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 2.0326e-04\n",
      "Epoch 00998: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2.0219e-04 - val_loss: 0.0098\n",
      "Epoch 999/1000\n",
      "15/16 [===========================>..] - ETA: 0s - loss: 2.1672e-04\n",
      "Epoch 00999: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.1561e-04 - val_loss: 0.0096\n",
      "Epoch 1000/1000\n",
      "13/16 [=======================>......] - ETA: 0s - loss: 1.9933e-04\n",
      "Epoch 01000: val_loss did not improve from 0.00505\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.0751e-04 - val_loss: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b48f893d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru = Sequential()\n",
    "\n",
    "model_gru.add(GRU(units = 50, return_sequences = True, input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "model_gru.add(GRU(units = 50, return_sequences = True))\n",
    "\n",
    "model_gru.add(GRU(units = 50, return_sequences = True))\n",
    "\n",
    "model_gru.add(GRU(units = 50))\n",
    "\n",
    "# Adding the output layer\n",
    "model_gru.add(Dense(units = n_steps_out))\n",
    "\n",
    "# Compiling the RNN\n",
    "model_gru.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "mc = ModelCheckpoint('GRU_infected_only_GRU_LSTM.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "model_gru.fit(X_train, y_train, epochs = 1000, batch_size = 32, validation_data=(X_test, y_test), verbose=1, \n",
    "              shuffle=False, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "important-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = model_gru.predict(X_test)\n",
    "y_pred_gru = sc.inverse_transform(y_pred_gru) #revert scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bottom-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshape = sc.inverse_transform(y_test.reshape(len(y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "lyric-thought",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(18, 4), dpi=80)\n",
    "\n",
    "plt.plot(y_test_reshape[:,0], label='observed')\n",
    "plt.plot(y_pred_gru[:,0], label='predicted')\n",
    "plt.title('LSTM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-potter",
   "metadata": {},
   "source": [
    "### Rescaling input before feeding to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "lesser-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.array([8793.0,7204.0,4161.0,6262, 6799, 5692, 5091, 4692, 3395, 2219, 1758, 3229, 3598, 2085])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "future-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "#x_input = np.array(df['Infected'][-14:]) # the lastest 14 days\n",
    "x_input = sc.fit_transform(x_input.reshape(len(x_input), 1))\n",
    "x_input = x_input.reshape((1, n_steps_in, 1))\n",
    "print(x_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "civic-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2_gru = model_gru.predict(x_input)\n",
    "y_pred2_gru = sc.inverse_transform(y_pred2_gru) #revert scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "maritime-parade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2_gru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "least-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b49f526880>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkB0lEQVR4nO3de3CVdZ7n8fc3V3LhFhJpSMCgBCV4aSWyzOJlBnVFBHVmuy3LKW3HqaW11JVSq0dXW6q1LKfaXa2x7PZSrU670tvjrVcFaaS8bqHSE2xBSQITYIAMAWICBhJCQvLdP84DHEIgJ3CS51w+r6pTefJ7nufk++PRz3PO77mZuyMiIukhI+wCRERk6Cj0RUTSiEJfRCSNKPRFRNKIQl9EJI1khV1Af4qLi728vDzsMkREksrq1au/c/eS3u0JH/rl5eVUV1eHXYaISFIxsy19tWt4R0QkjSj0RUTSiEJfRCSNKPRFRNKIQl9EJI0o9EVE0ohCX0QkjaRk6Pf0OK//6zb++O2OsEsREUkoCX9x1sn6319uoWnvAS6dUkx+Tsp2U0RkQFLyk35GhrFofiU7Wjt4/pONYZcjIpIwUjL0AarKi7j2/PG88NkmGna3h12OiEhCSNnQB3jg6rMxgyeW1YVdiohIQkjp0B8/Ko87LpvM0rWNrNrUHHY5IiKhS+nQB1hw6RmMHzmMR5fU0N2jh8CLSHpL+dDPy8nkwblTWbe9lTeqt4VdjohIqFI+9AHmnTeOi8pH8+Ty9bR2dIVdjohIaNIi9M2MRfOn0dLeybMf1YddjohIaNIi9AHOKR3JDdMn8MrKzWxq2hd2OSIioUib0Ae4/6qzyM3K5PGltWGXIiISirQK/ZLhudw9ezIf1u3i0w1NYZcjIjLk0ir0AW6dVU75mHweW1JDV3dP2OWIiAypfkPfzCaY2cdmVmtm68zsnqD9MTNba2Zfm9kHZjY+ap0HzazezNab2VVR7dPN7Jtg3jNmZoPTrePLzcrk4Wsqqd+1j9e+7PNh8SIiKSuWT/oHgfvcfSowE7jTzCqBJ939PHf/IbAEeAQgmHcjMA2YA/zazDKD93oOWABUBK85cexLzC6fehqXVBTz9IoNtLR1hlGCiEgo+g19d29096+C6b1ALVDq7q1RixUAhy53vQ74vbsfcPfNQD0ww8zGASPc/Qt3d+BV4Pr4dSV2ZsbP51XS1tnN0ys2hFGCiEgoBjSmb2blwAXAquD3x81sG/C3BJ/0gVIg+tLXhqCtNJju3R6KKWOHc/PM01m8agt1O1r7X0FEJAXEHPpmVgi8BSw89Cnf3R9y9wnAYuCuQ4v2sbqfoL2vv7XAzKrNrLqpafDOsll4RQUj8rJ59L0aIl8+RERSW0yhb2bZRAJ/sbu/3ccivwP+azDdAEyImlcGbA/ay/poP4a7v+juVe5eVVJSEkuJJ2VUfg73XjmFzzc280HNzkH7OyIiiSKWs3cMeAmodfenotoroha7Fjh00/p3gRvNLNfMJhE5YPsnd28E9prZzOA9bwHeiVM/TtpNMyYyZWwhjy+tpaOrO+xyREQGVSyf9GcBNwOzg9MzvzazucA/mtm3ZrYW+C/APQDuvg54HagB/gjc6e6H0vQO4DdEDu5uBJbFtTcnISszg0Xzp7G1pZ2XV24OuxwRkUFliT6WXVVV5dXV1YP+d/7bq9V8Xv8dH9//l5w2Ytig/z0RkcFkZqvdvap3e9pdkXs8D82dSle388vl68MuRURk0Cj0A+XFBdx28STeXN3Amm17wi5HRGRQKPSj3DV7MsWFufzivXU6hVNEUpJCP0phbhY/m3MWX23dw7tr+jybVEQkqSn0e/nRhWWcWzqSJ96vo73zYNjliIjElUK/l4wMY9H8Sna0dvD8JxvDLkdEJK4U+n2oKi/i2vPH88Jnm2jY3R52OSIicaPQP44Hrj4bM3hiWV3/C4uIJAmF/nGMH5XHHZdNZunaRlZtag67HBGRuFDon8CCS89g/MhhPLqkhu4encIpIslPoX8CeTmZPDh3Kuu2t/JG9bb+VxARSXAK/X7MO28cF5WP5snl62nt6Aq7HBGRU6LQ74eZsWj+NFraO3n2o/qwyxEROSUK/RicUzqSG6ZP4JWVm9nUtC/sckRETppCP0b3X3UWuVmZPL60NuxSREROmkI/RiXDc7l79mQ+rNvFpxsG77m9IiKDSaE/ALfOKqd8TD6PLamhq7sn7HJERAZMoT8AuVmZPHxNJfW79vHal1vCLkdEZMAU+gN0+dTTuKSimKdXbKClrTPsckREBkShP0Bmxs/nVdLW2c3TKzaEXY6IyIAo9E/ClLHDuXnm6SxetYW6Ha1hlyMiEjOF/klaeEUFI/KyefS9Gj1aUUSSRr+hb2YTzOxjM6s1s3Vmdk/Q/qSZ1ZnZWjP7g5mNCtrLzWy/mX0dvJ6Peq/pZvaNmdWb2TNmZoPWs0E2Kj+He6+cwucbm/mgZmfY5YiIxCSWT/oHgfvcfSowE7jTzCqBFcA57n4esAF4MGqdje7+w+B1e1T7c8ACoCJ4zYlHJ8Jy04yJTBlbyONLa+no6g67HBGRfvUb+u7e6O5fBdN7gVqg1N0/cPdDD5H9Eig70fuY2ThghLt/4ZHxkFeB60+l+LBlZWawaP40tra08/LKzWGXIyLSrwGN6ZtZOXABsKrXrNuAZVG/TzKzP5vZp2Z2SdBWCjRELdMQtCW1WZOLubJyLL/6qJ5drR1hlyMickIxh76ZFQJvAQvdvTWq/SEiQ0CLg6ZGYKK7XwDcC/zOzEYAfY3f93kE1MwWmFm1mVU3NSX+LQ8emjuVrm7nl8vXh12KiMgJxRT6ZpZNJPAXu/vbUe0/AeYBfxsM2eDuB9y9OZheDWwEphD5ZB89BFQGbO/r77n7i+5e5e5VJSUlA+/VECsvLuC2iyfx5uoG1mzbE3Y5IiLHFcvZOwa8BNS6+1NR7XOAfwCudff2qPYSM8sMps8gcsB2k7s3AnvNbGbwnrcA78S1NyG6a/Zkigtz+cV763QKp4gkrFg+6c8CbgZmR52GORd4FhgOrOh1aualwFozWwO8Cdzu7i3BvDuA3wD1RL4BRB8HSGqFuVn8bM5ZfLV1D++u6fMLjIhI6CzRP5VWVVV5dXV12GXEpKfHue5XK2nae4CP7r+M/JyssEsSkTRlZqvdvap3u67IjaOMDGPR/Ep2tHbw/Ccbwy5HROQYCv04qyov4trzx/PCZ5to2N3e/woiIkNIoT8IHrj6bMzgiWV1YZciInIUhf4gGD8qj9svO5OlaxtZtak57HJERA5T6A+Sn156JuNHDuPRJTV09yT2wXIRSR8K/UGSl5PJg3Onsm57K29Ubwu7HBERQKE/qOadN46Lykfz5PL1tHZ0hV2OiIhCfzCZGYvmT6OlvZNnP6oPuxwREYX+YDundCQ3TJ/AKys3s6lpX9jliEiaU+gPgfuvOovcrEweX1obdikikuYU+kOgZHgud8+ezId1u/h0Q+LfKlpEUpdCf4jcOquc8jH5PLakhq7unrDLEZE0pdAfIrlZmTx8TSX1u/bx2pdbwi5HRNKUQn8IXT71NC6pKObpFRtoaesMuxwRSUMK/SFkZvx8XiVtnd08vWJD2OWISBpS6A+xKWOHc/PM01m8agt1O1r7X0FEJI4U+iFYeEUFI/KyefS9Gj1aUUSGlEI/BKPyc7j3yil8vrGZD2p2hl2OiKQRhX5IbpoxkSljC3l8aS0dXd1hlyMiaUKhH5KszAwWzZ/G1pZ2Xl65OexyRCRNKPRDNGtyMVdWjuVXH9Wzq7Uj7HJEJA0o9EP20NypdHU7v1y+PuxSRCQN9Bv6ZjbBzD42s1ozW2dm9wTtT5pZnZmtNbM/mNmoqHUeNLN6M1tvZldFtU83s2+Cec+YmQ1Kr5JIeXEBt108iTdXN7Bm256wyxGRFBfLJ/2DwH3uPhWYCdxpZpXACuAcdz8P2AA8CBDMuxGYBswBfm1mmcF7PQcsACqC15w49iVp3TV7MsWFufzivXU6hVNEBlW/oe/uje7+VTC9F6gFSt39A3c/GCz2JVAWTF8H/N7dD7j7ZqAemGFm44AR7v6FR5LtVeD6+HYnORXmZvGzOWfx1dY9vLtme9jliEgKG9CYvpmVAxcAq3rNug1YFkyXAtEPhW0I2kqD6d7tAvzowjLOLR3JE+/X0d55sP8VREROQsyhb2aFwFvAQndvjWp/iMgQ0OJDTX2s7ido7+tvLTCzajOrbmpKj/vPZ2QYi+ZXsqO1g+c/2Rh2OSKSomIKfTPLJhL4i9397aj2nwDzgL/1I4PRDcCEqNXLgO1Be1kf7cdw9xfdvcrdq0pKSmLtS9KrKi/i2vPH88Jnm2jY3R52OSKSgmI5e8eAl4Bad38qqn0O8A/Ate4enVDvAjeaWa6ZTSJywPZP7t4I7DWzmcF73gK8E8e+pIQHrj4bM3hiWV3YpYhICorlk/4s4GZgtpl9HbzmAs8Cw4EVQdvzAO6+DngdqAH+CNzp7ofuM3AH8BsiB3c3cuQ4gATGj8rj9svOZOnaRlZtag67HBFJMZbopwhWVVV5dXV12GUMqf2d3Vz+vz5hdEEO7951MZkZaX85g4gMkJmtdveq3u26IjcB5eVk8uDcqazb3sob1dv6X0FEJEYK/QQ177xxXFQ+mieXr6e1oyvsckQkRSj0E5SZsWj+NFraO3n2o/qwyxGRFKHQT2DnlI7khukTeGXlZjY17Qu7HBFJAQr9BHf/VWeRm5XJ40trwy5FRFKAQj/BlQzP5e7Zk/mwbhefbkiPq5NFZPAo9JPArbPKKR+Tz2NLaujq7gm7HBFJYgr9JJCblcnD11RSv2sfr325JexyRCSJKfSTxOVTT+OSimKeXrGBlrbOsMsRkSSl0E8SZsbP51XS1tnN0ys2hF2OiCQphX4SmTJ2ODfPPJ3Fq7ZQt6O1/xVERHpR6CeZhVdUMCIvm0ffq9GjFUVkwBT6SWZUfg73XjmFzzc280HNzrDLEZEko9BPQjfNmMiUsYU8vrSWjq7u/lcQEQko9JNQVmYGi+ZPY2tLOy+v3Bx2OSKSRBT6SWrW5GKurBzLrz6qZ1drR9jliEiSUOgnsYfmTqWr2/nl8vVhlyIiSUKhn8TKiwu47eJJvLm6gTXb9oRdjogkAYV+krtr9mSKC3P5xXvrdAqniPRLoZ/kCnOz+Nmcs/hq6x7eXbM97HJEJMEp9FPAjy4s49zSkTzxfh3tnQfDLkdEEphCPwVkZBiL5leyo7WD5z/ZGHY5IpLA+g19M5tgZh+bWa2ZrTOze4L2Hwe/95hZVdTy5Wa238y+Dl7PR82bbmbfmFm9mT1jZjY43Uo/VeVFXHv+eF74bBMNu9vDLkdEElQsn/QPAve5+1RgJnCnmVUC3wJ/A3zWxzob3f2Hwev2qPbngAVARfCac0rVy1EeuPpszOCJZXVhlyIiCarf0Hf3Rnf/KpjeC9QCpe5e6+4xnyBuZuOAEe7+hUdOM3kVuP7kypa+jB+Vx+2XncnStY2s2tQcdjkikoAGNKZvZuXABcCqfhadZGZ/NrNPzeySoK0UaIhapiFokzj66aVnMn7kMB5dUkN3j07hFJGjxRz6ZlYIvAUsdPcT3cy9EZjo7hcA9wK/M7MRQF/j932mkpktMLNqM6tuatLDwAciLyeTB+dOZd32Vt6o3hZ2OSKSYGIKfTPLJhL4i9397RMt6+4H3L05mF4NbASmEPlkXxa1aBnQ54nl7v6iu1e5e1VJSUksJUqUeeeN46Ly0Ty5fD2tHV1hlyMiCSSWs3cMeAmodfenYli+xMwyg+kziByw3eTujcBeM5sZvOctwDunVL30ycx4ZN40Wto7efaj+rDLEZEEEssn/VnAzcDsqNMw55rZX5tZA/AXwFIzWx4sfymw1szWAG8Ct7t7SzDvDuA3QD2RbwDL4tkZOeLcspHcMH0Cr6zczKamfWGXIyIJwhL9fi1VVVVeXV0ddhlJqWnvAf7qf37Cf5pUxEu3XhR2OSIyhMxstbtX9W7XFbkprGR4LnfPnsyHdbv4dIMOiIuIQj/l3TqrnPIx+Ty2pIau7p6wyxGRkCn0U1xuViYPX1NJ/a59vPbllrDLEZGQKfTTwOVTT+OSimKeXrGBlrbOsMsRkRAp9NOAmfHzeZW0dXbz9IoNYZcjIiFS6KeJKWOHc/PM01m8agt1O050QbWIpDKFfhpZeEUFI/KyefS9Gj1aUSRNKfTTyKj8HO69cgqfb2zmg5qdYZcjIiFQ6KeZm2ZMZMrYQh5fWktHV3fY5YjIEFPop5mszAwemTeNrS3tvLxyc9jliMgQU+inoYsrirmyciy/+qieXa0dYZcjIkNIoZ+mHpo7la5u55fLY374mYikAIV+miovLuC2iyfx5uoG1mzbE3Y5IjJEFPpp7K7ZkykuzOUX763TKZwiaUKhn8YKc7P42Zyz+GrrHt5d0+dDzEQkxSj009yPLizj3NKRPPF+He2dB8MuR0QGmUI/zWVkGIvmV7KjtYPnP9kYdjkiMsgU+kJVeRHXnj+eFz7bRMPu9rDLEZFBpNAXAB64+mzM4IlldWGXIiKDSKEvAIwflcftl53J0rWNrNrUHHY5IjJIFPpy2E8vPZPxI4fx6JIaunt0CqdIKlLoy2F5OZk8OHcq67a38kb1trDLEZFB0G/om9kEM/vYzGrNbJ2Z3RO0/zj4vcfMqnqt86CZ1ZvZejO7Kqp9upl9E8x7xsws/l2SUzHvvHFcVD6aJ5evp7WjK+xyRCTOYvmkfxC4z92nAjOBO82sEvgW+Bvgs+iFg3k3AtOAOcCvzSwzmP0csACoCF5z4tEJiR8z45F502hp7+TZj+rDLkdE4qzf0Hf3Rnf/KpjeC9QCpe5e6+593a3rOuD37n7A3TcD9cAMMxsHjHD3Lzxyzf+rwPXx6ojEz7llI7lh+gReWbmZTU37wi5HROJoQGP6ZlYOXACsOsFipUD0gHBD0FYaTPdulwR0/1VnkZuVyeNLa8MuRUTiKObQN7NC4C1gobuf6MnafY3T+wna+/pbC8ys2syqm5qaYi1R4qhkeC53z57Mh3W7+HSDtoFIqogp9M0sm0jgL3b3t/tZvAGYEPV7GbA9aC/ro/0Y7v6iu1e5e1VJSUksJcoguHVWOeVj8nlsSQ1d3T1hlyMicRDL2TsGvATUuvtTMbznu8CNZpZrZpOIHLD9k7s3AnvNbGbwnrcA75xC7TLIcrMyefiaSup37eO1L7eEXY6IxEEsn/RnATcDs83s6+A118z+2swagL8AlprZcgB3Xwe8DtQAfwTudPdDT+C+A/gNkYO7G4Fl8e2OxNvlU0/jkopinl6xgZa2zrDLEZFTZIn+8Iyqqiqvrq4Ou4y0tmHnXq7+p//HTTMm8tj154RdjojEwMxWu3tV73ZdkSv9mjJ2ODfPPJ3Fq7ZQt+NEx/BFJNEp9CUmC6+oYEReNo++V6NHK4okMYW+xGRUfg73XjmFzzc280HNzrDLEZGTpNCXmN00YyJTxhby+NJaOrq6+19BRBKOQl9ilpWZwSPzprG1pZ2XV24OuxwROQkKfRmQiyuKubJyLL/6qJ5drR1hlyMiA6TQlwF7aO5UurqdXy7v6357IpLIFPoyYOXFBfzdxeW8ubqBNdv2hF2OiAyAQl9Oyl1/NZniwlx+8d46ncIpkkQU+nJShg/L5mdzzuKrrXt4d02f980TkQSk0JeT9qMLyzi3dCRPvF9He+fBsMsRkRgo9OWkZWQYi+ZXsqO1g+c/2Rh2OSISA4W+nJKq8iKuPX88L3y2iYbd7WGXIyL9UOjLKXvg6rMxgyeW1YVdioj0Q6Evp2z8qDxuv+xMlq5tZNWm5rDLEZETUOhLXPz00jMZP3IYjy6pobtHp3CKJCqFvsRFXk4mD86dyrrtrbxRvS3sckTkOBT6EjfzzhvHReWjeXL5elo7usIuR0T6oNCXuDEzHpk3jZb2Tp79qD7sckSkDwp9iatzy0Zyw/QJvLJyM5ua9oVdjoj0otCXuLv/qrPIzcrk8aW1YZciIr0o9CXuSobncvfsyXxYt4tPNzSFXY6IROk39M1sgpl9bGa1ZrbOzO4J2ovMbIWZ/Vvwc3TQXm5m+83s6+D1fNR7TTezb8ys3syeMTMbvK5JmG6dVU75mHweW1JDV3dP2OWISCCWT/oHgfvcfSowE7jTzCqBB4AP3b0C+DD4/ZCN7v7D4HV7VPtzwAKgInjNiUcnJPHkZmXy8DWV1O/ax2tfbgm7HBEJ9Bv67t7o7l8F03uBWqAUuA74bbDYb4HrT/Q+ZjYOGOHuX3jkBuyv9reOJLfLp57GJRXFPL1iAy1tnWGXIyIMcEzfzMqBC4BVwFh3b4TIjgE4LWrRSWb2ZzP71MwuCdpKgYaoZRqCNklRZsbP51XS1tnN0ys2hF2OiDCA0DezQuAtYKG7t55g0UZgortfANwL/M7MRgB9jd/3eb2+mS0ws2ozq25q0oHAZDZl7HBunnk6i1dtoW7Hif6zEZGhEFPom1k2kcBf7O5vB807gyGbQ0M3uwDc/YC7NwfTq4GNwBQin+zLot62DOjzkUvu/qK7V7l7VUlJycB7JQll4RUVjMjL5tH3avRoRZGQxXL2jgEvAbXu/lTUrHeBnwTTPwHeCZYvMbPMYPoMIgdsNwVDQHvNbGbwnrccWkdS26j8HO69cgqfb2zmg5qdYZcjktayYlhmFnAz8I2ZfR20/Q/gH4HXzezvga3Aj4N5lwKPmtlBoBu43d1bgnl3AP8M5AHLgpekgZtmTOS1L7ew6J11fLGxmTEFORQV5lCUn0NRQQ5jCnMoKshlZF42mRk6k1dksFiif92uqqry6urqsMuQOFi9ZTcPvLWWHd93sPdA38/UzbDIN4OiguCVH9k5jCnIYXT+oZ3D0a/crMwh7olI4jOz1e5edUy7Ql/C0Hmwh93tnTTv66SlrZOW9k5a9h04Mt12ZN7u4Pfj3aa/MDeLooIcRhdEdg5Fwc/RUdPRO4nC3Cx0XaCkuuOFfizDOyJxl5OVwdgRwxg7YlhMy/f0ON/v76I52Akc3lm0HaClrYuWtgM0t3Wys7WDusZWmts6OXCw7yuBczIzGF2QTVFB7jE7hOgdxqF5o/JzNOQkKUOhL0khI8MYHYRxLNyd9s7uYMcQfHPotZM41Nawu53mtk72dvQ95GQGo/Kygx1C7ol3GIWRYahh2RpyksSk0JeUZGYU5GZRkJvFhKL8mNbpPNjDnvZDO4fIz91H7Swi7Zu/a2P1lt0nHHIqyMmMHKguyKUoP9hJFEYdp4g+kF2Yw3ANOckQUeiLBHKyMjhtxDBOG8CQU2tH15GdxL4jxx8iw08HaGnvomnfAdbv2BvTkNORg9W5hw9eHzqQHf2NYrSGnOQkKfRFTlJGhjEqPzLmf2YM1xC6O/u7uqOORxx/6Omb3XtiGnIa3ceB6sM7jF7zNOQkoNAXGTJmRn5OFvlFsQ85dXX3HB5iOjLUdOT3yPSBYMhpD7vbO+k+zphTfk7mUWczHdkp5DJ+1DAmFOUzsSifMQU5GmpKYQp9kQSWnXnyQ07RO4ne3yqa9h1gw859NLcdoKPr6CGngpzMwzuA08dEfk4oyuf0MQWUjsojJ0vPXkpmCn2RFBI95ESMt61qO3CQ7Xv2s7Wlna0t7WxpbmdbSzubv2vj0w1NRx2HyDAYNzKPicFOYWKwUzj0GpWfrW8JCU6hL5LmCnKzqBg7nIqxw4+Z19PjNO07ENkhNLezpSWyQ9ja0s6Hdbv4bt+Bo5YfPizrqJ1A9E5h/Kg8sjP1LSFsCn0ROa6MDDt8Ed1F5UXHzG/vPMi2lv1saW5ja7BD2NLSzvqde/mwdhedUY/KzMwwxo8aFuwECg7vDE4fExk+GpmXPZRdS1sKfRE5afk5WZz1g+Gc9YO+vyXs3NvBlub2IzuEYPqDdTto7vU0tZF52Yd3ABOL8jm96MjxhPGj8nSKapwo9EVkUGRkGONG5jFuZB4zzxhzzPy9HV1sazl0LKEt+Lmfdf/xPcu/3cHBqLOQsjKMstF5fR5gnliUz/Bh+pYQK4W+iIRi+LBsKsdnUzl+xDHzunucxu/3Hz6WcOgg89aWdpZ+08ie9q6jli8qyImcYdTH8YQfjBhGhr4lHKbQF5GEk5lhlI3Op2x0Pv/5zGPnf7+/6/AB5egzjr7etoel3zQeda1CTmYGZUV5Rx9gjtop5OekVwymV29FJCWMzMtmZOlIzikdecy8ru4eGvd0HNkhtLQd3kGs3rL7mKuciwtzmXhopzDm6APMJYW5KfctQaEvIiklOzMj8il+zLFXPbtHbtG9Neqg8qEDzP/677t5d832o26il5uVcXjYqK/jCcl4awuFvoikDbMjF6+dVzbqmPmdB3v4j6gL1SI7hDa2tuzny03NtHV2H7X82BG5R65YLipg4pi8w6ekFhcm5u0sFPoiIoGcrAwmFRcwqbjgmHnuTktb55GDylEHmL/Y2Mwf/vwfRD+IMC87M+oWFkcfSygbnRfaYz4V+iIiMTAzxhTmMqYwlwsmjj5mfkdXd+RbQq+zjbY2t7Oy/jv2d3VHvRf8YMSwPg8sTyzKp2gQb3qn0BcRiYNh2ZmcWVLImSWFx8xzd77b13nkeoTm/YcPMH/2b03sbD36dhaFwcN//uWnMxkR52sQFPoiIoPMzCgZnkvJ8Fymn37s7Sz2d3bTsPvoU1Abv9/P8Nz4R3S/72hmE4BXgR8APcCL7v5PZlYE/AtQDvw7cIO77w7WeRD4e6Ab+O/uvjxonw78M5AHvA/c4+7HeeCciEh6yMvJPO5N7+ItllveHQTuc/epwEzgTjOrBB4APnT3CuDD4HeCeTcC04A5wK/N7NARi+eABUBF8JoTx76IiEg/+g19d29096+C6b1ALVAKXAf8Nljst8D1wfR1wO/d/YC7bwbqgRlmNg4Y4e5fBJ/uX41aR0REhsCAbm5tZuXABcAqYKy7N0JkxwCcFixWCmyLWq0haCsNpnu3i4jIEIk59M2sEHgLWOjurSdatI82P0F7X39rgZlVm1l1U1NTrCWKiEg/Ygp9M8smEviL3f3toHlnMGRD8HNX0N4ATIhavQzYHrSX9dF+DHd/0d2r3L2qpCTGZ76JiEi/+g19i1wh8BJQ6+5PRc16F/hJMP0T4J2o9hvNLNfMJhE5YPunYAhor5nNDN7zlqh1RERkCMRyEugs4GbgGzP7Omj7H8A/Aq+b2d8DW4EfA7j7OjN7HaghcubPne5+6FK0Ozhyyuay4CUiIkPEEv00+aqqKq+urg67DBGRpGJmq9296pj2RA99M2sCtpzk6sXAd3EsJ0yp0pdU6QeoL4kqVfpyqv043d2POSia8KF/Ksysuq89XTJKlb6kSj9AfUlUqdKXwerHgM7TFxGR5KbQFxFJI6ke+i+GXUAcpUpfUqUfoL4kqlTpy6D0I6XH9EVE5Gip/klfRESiKPRFRNJISoS+mc0xs/VmVm9mD/Qx38zsmWD+WjO7MIw6+xNDP/7SzL43s6+D1yNh1NkfM3vZzHaZ2bfHmZ8U2wNi6ktSbBOIPBDJzD42s1ozW2dm9/SxTMJvmxj7kRTbxcyGmdmfzGxN0Jdf9LFMfLeJuyf1C8gENgJnADnAGqCy1zJzidzywYg8CGZV2HWfZD/+ElgSdq0x9OVS4ELg2+PMT/jtMYC+JMU2CWodB1wYTA8HNiTp/yux9CMptkvw71wYTGcTuW39zMHcJqnwSX8GUO/um9y9E/g9kQe5RLsOeNUjvgRGHbpDaAKJpR9Jwd0/A1pOsEgybA8gpr4kDT/+A5GiJfy2ibEfSSH4d94X/JodvHqfXRPXbZIKoX+8h7YMdJmwxVrjXwRfBZeZ2bShKS3ukmF7DETSbZNeD0SKllTb5gT9gCTZLmaWGdzMchewwt0HdZvE/1HrQy+Wh7PE/ACXEMVS41dE7qexz8zmAv+XyK2rk00ybI9YJd026eeBSEmzbfrpR9JsF4/chfiHZjYK+IOZnePu0ceQ4rpNUuGT/vEe2jLQZcLWb43u3nroq6C7vw9km1nx0JUYN8mwPWKSbNvE+n4gUrSk2Db99SPZtguAu+8BPgHm9JoV122SCqH/r0CFmU0ysxzgRiIPcon2LnBLcBR8JvC9B8/3TSD99sPMfmBmFkzPILL9moe80lOXDNsjJsm0TYI6+3ogUrSE3zax9CNZtouZlQSf8DGzPOAKoK7XYnHdJkk/vOPuB83sLmA5kTNgXvbIg1xuD+Y/D7xP5Ah4PdAO/F1Y9R5PjP34EXCHmR0E9gM3enB4P5GY2f8hcvZEsZk1AIuIHKBKmu1xSAx9SYptEjjeA5EmQlJtm1j6kSzbZRzwWzPLJLJjet3dlwxmfuk2DCIiaSQVhndERCRGCn0RkTSi0BcRSSMKfRGRNKLQFxFJIwp9EZE0otAXEUkj/x85Qeb4gvAmugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_pred2_gru[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fancy-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_raw = np.array([8793.0,7204.0,4161.0,6262, 6799, 5692, 5091, 4692, 3395, 2219, 1758, 3229, 3598, 2085])\n",
    "len(x_input_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "objective-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = pd.date_range(start='2021-09-11', end='2021-09-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "particular-rainbow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b49f4c68e0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_x_input = len(x_input_raw)\n",
    "plt.plot(range(0,len_x_input),x_input_raw)\n",
    "plt.plot(range(len_x_input-1, len_x_input+n_steps_out-1), y_pred2_gru[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "divine-symbol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2326.2434, 2042.6855, 2029.4324, 2007.5043], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_pred2_gru[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-circuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-failing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-popularity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-survivor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-italic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "failing-beauty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(18, 4), dpi=80)\n",
    "\n",
    "plt.plot(y_test_reshape[:,0], label='observed')\n",
    "plt.plot(y_pred_gru[:,0], label='gru_predicted')\n",
    "plt.plot(y_pred_lstm[:,0], label='lstm_predicted')\n",
    "\n",
    "plt.title('LSTM vs GRU')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "statewide-columbus",
   "metadata": {},
   "source": [
    "gru mean square error (scaled):  0.00505\n",
    "lstm mean square error (scaled): 0.00974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-mortgage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
